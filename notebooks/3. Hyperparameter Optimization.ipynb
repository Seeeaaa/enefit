{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8564d41a-78cf-4436-9f3c-0a83002479b4",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc98bc4f-6cb6-4cf4-9d8e-3ddb51c322ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path().resolve().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa109d03-2ed5-49bb-a248-5cb63aff28ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from optuna.samplers import TPESampler\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from xgboost import DMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44029df-5480-4fc2-bf60-020dec1e0c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loading import load_all_raw_data\n",
    "from utils.preprocessing import process_all_dfs\n",
    "from utils.merging import merge_all_dfs\n",
    "from utils.feature_engineering import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390c843-629b-4539-a5a2-9ab0e6bd2e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\n",
    "    \"display.float_format\",\n",
    "    lambda x: f\"{x:.2e}\" if abs(x) < 0.01 and x != 0 else f\"{x:.2f}\",\n",
    ")\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaadc0f-2ff7-4e14-86af-d08b7903cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = \"../data/raw_data/\"\n",
    "ADDITIONAL_DATA_PATH = \"../data/additional_data/\"\n",
    "\n",
    "SEGMENT_C = [\"county\", \"product_type\", \"is_business\"]\n",
    "CATEGORICAL_C = [\"county\", \"product_type\", \"is_business\", \"is_consumption\"]\n",
    "TARGET_C = [\n",
    "    \"county\",\n",
    "    \"product_type\",\n",
    "    \"is_business\",\n",
    "    \"is_consumption\",\n",
    "    \"datetime\",\n",
    "]\n",
    "RAND = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b008800-bc93-4537-af46-0be6b76438a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dfs = process_all_dfs(\n",
    "    load_all_raw_data(RAW_DATA_PATH, ADDITIONAL_DATA_PATH)\n",
    ")\n",
    "\n",
    "df = merge_all_dfs(processed_dfs, how=\"left\")\n",
    "df = add_dst_flag(df)\n",
    "df = add_cyclic_datetime_features(df, drop_raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a58200c-b23e-4e91-a7ea-42838195e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in [2, 3, 7]:\n",
    "    df = df.merge(\n",
    "        get_lag(processed_dfs[\"train\"][TARGET_C + [\"target\"]], lag=lag),\n",
    "        how=\"left\",\n",
    "        on=TARGET_C,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2660bda6-bf83-4fd7-8b0b-4393d93271e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for window in [24, 24 * 3, 24 * 7, 24 * 14]:\n",
    "    df = df.merge(\n",
    "        get_moving_average(\n",
    "            processed_dfs[\"train\"]\n",
    "            .set_index(\"datetime\")\n",
    "            .sort_index()\n",
    "            .groupby(CATEGORICAL_C, observed=True, as_index=False),\n",
    "            columns=[\"target\"],\n",
    "            window=window,\n",
    "            # ).dropna(),\n",
    "        ),\n",
    "        how=\"left\",\n",
    "        on=TARGET_C,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc71be1-ec2a-4d15-bbc0-b14a35895020",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"t_over_cap\"] = (df[\"2d_lag_target\"] / df[\"installed_capacity\"]).astype(\n",
    "    \"float32\"\n",
    ")\n",
    "df[\"t_over_eic\"] = (df[\"2d_lag_target\"] / df[\"eic_count\"]).astype(\"float32\")\n",
    "df[\"cap_per_eic\"] = (df[\"installed_capacity\"] / df[\"eic_count\"]).astype(\n",
    "    \"float32\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8af1f7-4606-4ff0-9003-831e9c0f8312",
   "metadata": {},
   "source": [
    "# 2. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e96a5-e4b9-4f3c-a5a7-5cf40404e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_TO_DROP = [\"datetime\", \"data_block_id\", \"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e21ea6f-f8ba-4137-944b-ae968efc01ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_MODELS_DIR = Path(\"../models/xgb_baseline\")\n",
    "BASELINE_MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FH = 7  # weekly retraining\n",
    "ITERS = 1000\n",
    "VERBOSE = 0\n",
    "ESR = 50\n",
    "baseline_params = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_depth\": 7,\n",
    "    \"random_state\": RAND,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"objective\": \"reg:absoluteerror\",\n",
    "    \"eval_metric\": \"mae\",\n",
    "    \"tree_method\": \"hist\",  # GPU\n",
    "    \"device\": \"cuda\",  # GPU\n",
    "    \"n_jobs\": -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca6f4e-7e7e-4370-b83c-4843b51f3f0f",
   "metadata": {},
   "source": [
    "## Fixed vs Expanding Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa9b390-7de5-44a4-b073-e5c4807d42f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fix_splits, test_fix_splits = get_split_bounds(\n",
    "    df[\"datetime\"], expanding=False, fh=30\n",
    ")\n",
    "train_exp_splits, test_exp_splits = get_split_bounds(\n",
    "    df[\"datetime\"], expanding=True, fh=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94176ad9-f3d5-40ab-8e34-cf937ac68c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_split(\n",
    "    df: DataFrame, bounds: tuple, to_drop: list\n",
    ") -> tuple[DataFrame, Series]:\n",
    "    \"\"\"\n",
    "    Filters a DataFrame by datetime bounds, drops specified columns,\n",
    "    and splits into features and target.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Input DataFrame containing 'datetime' and 'target' columns.\n",
    "    bounds : tuple\n",
    "        A tuple specifying the datetime range to filter df.\n",
    "    to_drop : list\n",
    "        List of column names to drop from the df.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : DataFrame\n",
    "        DataFrame with specified columns dropped and 'target' removed.\n",
    "    y : Series\n",
    "        Target values corresponding to the 'target' column in the\n",
    "        filtered DataFrame.\n",
    "    \"\"\"\n",
    "    start, end = bounds[0], bounds[1]\n",
    "    subset = df[(df[\"datetime\"] >= start) & (df[\"datetime\"] <= end)].drop(\n",
    "        to_drop, axis=1\n",
    "    )\n",
    "    X, y = subset.drop([\"target\"], axis=1), subset[\"target\"]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05852537-8982-457b-9ddb-9071995ec8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_save(\n",
    "    df: DataFrame,\n",
    "    split: dict,\n",
    "    kind: str,\n",
    "    expanding: bool,\n",
    "    params: dict,\n",
    "    to_drop: list,\n",
    "    models_dir: Path,\n",
    "    i: int,\n",
    "    save: bool = True,\n",
    "    num_boost_round: int = 1000,\n",
    "    early_stopping_rounds: int = 50,\n",
    "    verbose_eval: int = 0,\n",
    "):\n",
    "    exp_prefix = \"fix\" if not expanding else \"exp\"\n",
    "    model_path = models_dir / f\"{kind}_{exp_prefix}_{i}.ubj\"\n",
    "    meta_path = models_dir / f\"{kind}_{exp_prefix}_{i}_meta.json\"\n",
    "\n",
    "    need_to_train = True\n",
    "    if model_path.exists() and meta_path.exists():\n",
    "        try:\n",
    "            with open(meta_path, \"r\", encoding=\"utf-8\") as fin:\n",
    "                meta = json.load(fin)\n",
    "            if (meta.get(\"train_start\") == str(split[\"train\"][0])) and (\n",
    "                meta.get(\"train_end\") == str(split[\"train\"][1])\n",
    "            ):\n",
    "                need_to_train = False\n",
    "                booster = xgb.Booster()\n",
    "                booster.load_model(str(model_path))\n",
    "            else:\n",
    "                need_to_train = True\n",
    "        except Exception:\n",
    "            need_to_train = True\n",
    "\n",
    "    X_test, y_test = drop_split(df, split[\"test\"], to_drop)\n",
    "    dtest = DMatrix(X_test, y_test, enable_categorical=True)\n",
    "    del X_test\n",
    "\n",
    "    if need_to_train:\n",
    "        X_train, y_train = drop_split(df, split[\"train\"], to_drop)\n",
    "        dtrain = DMatrix(X_train, y_train, enable_categorical=True)\n",
    "        del X_train, y_train\n",
    "\n",
    "        evals = [(dtrain, \"train\")]\n",
    "        if \"val\" in kind:\n",
    "            evals.append((dtest, \"val\"))\n",
    "\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=evals,\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "            verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        if save:\n",
    "            booster.save_model(str(model_path))\n",
    "            meta = {\n",
    "                \"train_start\": str(split[\"train\"][0]),\n",
    "                \"train_end\": str(split[\"train\"][1]),\n",
    "                \"kind\": kind,\n",
    "                \"expanding\": str(expanding),\n",
    "            }\n",
    "            with open(meta_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "                json.dump(meta, fout, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return booster, dtest, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d85544-581e-49ad-9533-31b561af7ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_baseline = [\n",
    "    np.empty(len(s))\n",
    "    for s in [\n",
    "        train_fix_splits,\n",
    "        test_fix_splits,\n",
    "        train_exp_splits,\n",
    "        test_exp_splits,\n",
    "    ]\n",
    "]\n",
    "splits_list = [\n",
    "    (\"baseline_val\", False, train_fix_splits),\n",
    "    (\"baseline_test\", False, test_fix_splits),\n",
    "    (\"baseline_val\", True, train_exp_splits),\n",
    "    (\"baseline_test\", True, test_exp_splits),\n",
    "]\n",
    "for i_sample, (kind, expanding, splits) in enumerate(splits_list):\n",
    "    for i, split in enumerate(splits):\n",
    "        booster, dtest, y_test = load_train_save(\n",
    "            df,\n",
    "            split,\n",
    "            kind,\n",
    "            expanding,\n",
    "            baseline_params,\n",
    "            FEATURES_TO_DROP,\n",
    "            BASELINE_MODELS_DIR,\n",
    "            i,\n",
    "            True,\n",
    "            ITERS,\n",
    "            ESR,\n",
    "            VERBOSE,\n",
    "        )\n",
    "\n",
    "        preds = booster.predict(dtest)\n",
    "        mae_baseline[i_sample][i] = MAE(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abbf22a-38ef-4349-a10f-ca403433ac0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE on fixed train data: 59.38811238606771\n",
      "Validation MAE on expanding train data: 58.713759104410805\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation MAE on fixed train data:\", np.mean(mae_baseline[1]))\n",
    "print(\"Validation MAE on expanding train data:\", np.mean(mae_baseline[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e8102a-a542-447e-9e64-28c31f2450bc",
   "metadata": {},
   "source": [
    "Since the MAE on the expanding training data is lower, the full training dataset will be used for the Optuna search without applying a sliding window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f5fce9-4238-4c01-9589-f76c73c778fd",
   "metadata": {},
   "source": [
    "## Single XGBoost Model Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fb4337-278d-4dee-9097-d46d1f8a5038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': (Timestamp('2021-09-01 00:00:00'),\n",
       "   Timestamp('2023-03-31 23:00:00')),\n",
       "  'test': (Timestamp('2023-04-01 00:00:00'),\n",
       "   Timestamp('2023-04-30 23:00:00'))}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_ts = df[\"datetime\"].min()\n",
    "april_test = get_month_splits(start_ts, 19, 1, 1, 1)\n",
    "april_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c6eda-1a26-4eb7-bf2e-c11df35333c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'max_depth': 7,\n",
       " 'random_state': 10,\n",
       " 'subsample': 0.8,\n",
       " 'colsample_bytree': 0.8,\n",
       " 'objective': 'reg:absoluteerror',\n",
       " 'eval_metric': 'mae',\n",
       " 'tree_method': 'hist',\n",
       " 'device': 'cuda',\n",
       " 'n_jobs': -1}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acebfb8-a192-402d-92e5-2bda4b658645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datetime', 'data_block_id', 'date']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES_TO_DROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a50e2c7-ef22-46f3-9570-c58ccdcd8952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../models/xgb_baseline')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASELINE_MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e1eae-8080-4c06-b7a1-bbf4cee398ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERS = 1000\n",
    "ESR = 50\n",
    "VERBOSE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e6551-1618-45be-b634-4c2d3efe2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_baseline_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a948ca-48a8-463d-8fa7-dec6a5ae06c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, split in enumerate(april_test):\n",
    "    booster, dtest, y_test = load_train_save(\n",
    "        df,\n",
    "        split,\n",
    "        \"test_2m\",\n",
    "        True,\n",
    "        baseline_params,\n",
    "        FEATURES_TO_DROP,\n",
    "        BASELINE_MODELS_DIR,\n",
    "        i,\n",
    "        True,\n",
    "        ITERS,\n",
    "        ESR,\n",
    "        VERBOSE,\n",
    "    )\n",
    "    preds = booster.predict(dtest)\n",
    "    mae_baseline_test.append(MAE(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa232155-64bb-45ba-b3ad-a589896318b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72.80978393554688]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_baseline_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49d3189-913a-4b3d-b948-7c56a4e2695c",
   "metadata": {},
   "source": [
    "## Separate XGBoost Models for Consumption and Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e95aaa2-0fcc-4636-80d8-ca1a9f7855e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': (Timestamp('2021-09-01 00:00:00'),\n",
       "   Timestamp('2023-01-31 23:00:00')),\n",
       "  'test': (Timestamp('2023-02-01 00:00:00'),\n",
       "   Timestamp('2023-02-28 23:00:00'))},\n",
       " {'train': (Timestamp('2021-09-01 00:00:00'),\n",
       "   Timestamp('2023-02-28 23:00:00')),\n",
       "  'test': (Timestamp('2023-03-01 00:00:00'),\n",
       "   Timestamp('2023-03-31 23:00:00'))},\n",
       " {'train': (Timestamp('2021-09-01 00:00:00'),\n",
       "   Timestamp('2023-03-31 23:00:00')),\n",
       "  'test': (Timestamp('2023-04-01 00:00:00'),\n",
       "   Timestamp('2023-04-30 23:00:00'))},\n",
       " {'train': (Timestamp('2021-09-01 00:00:00'),\n",
       "   Timestamp('2023-04-30 23:00:00')),\n",
       "  'test': (Timestamp('2023-05-01 00:00:00'),\n",
       "   Timestamp('2023-05-31 23:00:00'))}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_ts = df[\"datetime\"].min()\n",
    "splits = get_month_splits(start_ts, 17, 1, 1, 4)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42383474-9ca9-4514-b4b2-726cadbe09c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'max_depth': 7,\n",
       " 'random_state': 10,\n",
       " 'subsample': 0.8,\n",
       " 'colsample_bytree': 0.8,\n",
       " 'objective': 'reg:absoluteerror',\n",
       " 'eval_metric': 'mae',\n",
       " 'tree_method': 'hist',\n",
       " 'device': 'cuda',\n",
       " 'n_jobs': -1}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8913db87-1c4a-440f-b8ac-ecb3ec0fbd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datetime', 'data_block_id', 'date']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES_TO_DROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bdef6e-a16b-49e0-9601-60a996ab880f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../models/xgb_baseline')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASELINE_MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f7dec-d46c-4706-9010-f92803ee1d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERS = 1000\n",
    "ESR = 50\n",
    "VERBOSE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab03bd-efb3-4f9d-9168-c85367218918",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_split_models = []\n",
    "\n",
    "for i, split in enumerate(splits):\n",
    "    for iscons in [False, True]:\n",
    "        booster, dtest, y_test = load_train_save(\n",
    "            df.loc[df[\"is_consumption\"] == iscons],\n",
    "            split,\n",
    "            f\"test_4m_iscons_{iscons}\",\n",
    "            True,\n",
    "            baseline_params,\n",
    "            FEATURES_TO_DROP,\n",
    "            BASELINE_MODELS_DIR,\n",
    "            i,\n",
    "            True,\n",
    "            ITERS,\n",
    "            ESR,\n",
    "            VERBOSE,\n",
    "        )\n",
    "        preds = booster.predict(dtest)\n",
    "        mae_split_models.append(\n",
    "            {\n",
    "                \"split\": i,\n",
    "                \"type\": [\"production\", \"consumption\"][iscons],\n",
    "                \"mae\": MAE(y_test, preds),\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43294f6c-dfd6-4162-9cf2-71b67d6ad78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>type</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>production</td>\n",
       "      <td>12.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>consumption</td>\n",
       "      <td>56.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>production</td>\n",
       "      <td>37.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>consumption</td>\n",
       "      <td>77.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>production</td>\n",
       "      <td>74.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>consumption</td>\n",
       "      <td>68.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>production</td>\n",
       "      <td>91.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>consumption</td>\n",
       "      <td>55.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split         type   mae\n",
       "0      0   production 12.07\n",
       "1      0  consumption 56.77\n",
       "2      1   production 37.66\n",
       "3      1  consumption 77.91\n",
       "4      2   production 74.57\n",
       "5      2  consumption 68.41\n",
       "6      3   production 91.56\n",
       "7      3  consumption 55.41"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_split_models_df = DataFrame(mae_split_models)\n",
    "mae_split_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3505faa-1208-4750-a513-ec8751f2ce86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "0   34.42\n",
       "1   57.78\n",
       "2   71.49\n",
       "3   73.49\n",
       "Name: mae, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_split_models_df.groupby([\"split\"])[\"mae\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb58e205-4b39-4278-94e6-78048a0c6df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "consumption   64.63\n",
       "production    53.96\n",
       "Name: mae, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_split_models_df.groupby([\"type\"])[\"mae\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cc8b76-346b-4bf0-863f-120a3706a7fc",
   "metadata": {},
   "source": [
    "# 3. Optuna Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba24d0c5-0bdf-4b21-a84e-09e6abd00b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': (Timestamp('2021-09-01 00:00:00'),\n",
       "   Timestamp('2022-08-31 23:00:00')),\n",
       "  'test': (Timestamp('2022-09-01 00:00:00'),\n",
       "   Timestamp('2022-09-30 23:00:00'))},\n",
       " {'train': (Timestamp('2021-09-01 00:00:00'),\n",
       "   Timestamp('2022-11-30 23:00:00')),\n",
       "  'test': (Timestamp('2022-12-01 00:00:00'),\n",
       "   Timestamp('2022-12-31 23:00:00'))},\n",
       " {'train': (Timestamp('2021-09-01 00:00:00'),\n",
       "   Timestamp('2023-02-28 23:00:00')),\n",
       "  'test': (Timestamp('2023-03-01 00:00:00'),\n",
       "   Timestamp('2023-03-31 23:00:00'))}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splits for 3 models with different time period\n",
    "optuna_train_lv = get_month_splits(start_ts, 12, 1, 3, 3)\n",
    "optuna_train_lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66643230-6ae5-49c8-a652-307760f6178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.03, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 20),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 0.001, 100),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.001, 100),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 10),\n",
    "        \"grow_policy\": trial.suggest_categorical(\n",
    "            \"grow_policy\", [\"depthwise\", \"lossguide\"]\n",
    "        ),\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"device\": \"cuda\",\n",
    "        \"objective\": \"reg:absoluteerror\",\n",
    "        \"eval_metric\": \"mae\",\n",
    "    }\n",
    "    num_boost_round = trial.suggest_int(\"num_boost_round\", 500, 2500, step=500)\n",
    "\n",
    "    cv_scores = np.empty(len(optuna_train_lv))\n",
    "\n",
    "    for i, split in enumerate(optuna_train_lv):\n",
    "        params[\"random_state\"] = RAND + i\n",
    "        X_train, y_train = drop_split(df, split[\"train\"], FEATURES_TO_DROP)\n",
    "        dtrain = DMatrix(X_train, y_train, enable_categorical=True)\n",
    "        del X_train, y_train\n",
    "\n",
    "        X_val, y_val = drop_split(df, split[\"test\"], FEATURES_TO_DROP)\n",
    "        dval = DMatrix(X_val, y_val, enable_categorical=True)\n",
    "        del X_val\n",
    "\n",
    "        evals = [(dtrain, \"train\"), (dval, \"val\")]\n",
    "\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            evals=evals,\n",
    "            num_boost_round=num_boost_round,\n",
    "            early_stopping_rounds=ESR,\n",
    "            verbose_eval=VERBOSE,\n",
    "        )\n",
    "\n",
    "        preds = booster.predict(dval)\n",
    "        cv_scores[i] = MAE(y_val, preds)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc53618e-66e8-4344-85bc-f81e1279f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "STORAGE = \"sqlite:///../optuna_db/optuna_study_long_val_rand_incr.db\"\n",
    "n_trials = 120\n",
    "n_startup_trials = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1753b13c-44be-4ce5-89f6-d04266593503",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6563a073-dbb3-4dca-b7ef-629f63fb0477",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/jlpe-9TtSrW0h-py3.13/lib/python3.13/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2025-11-24 19:34:48,303] Using an existing study with name 'xgb_optuna' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of existing trials >= n_trials. Skipping optimization.\n"
     ]
    }
   ],
   "source": [
    "study_lvri = optuna.create_study(\n",
    "    storage=STORAGE,\n",
    "    sampler=TPESampler(n_startup_trials=n_startup_trials, multivariate=True),\n",
    "    pruner=optuna.pruners.SuccessiveHalvingPruner(),\n",
    "    study_name=\"xgb_optuna\",\n",
    "    direction=\"minimize\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "existing_trials = len(study_lvri.trials)\n",
    "\n",
    "if existing_trials >= n_trials:\n",
    "    print(\"Number of existing trials >= n_trials. Skipping optimization.\")\n",
    "else:\n",
    "    remaining = n_trials - existing_trials\n",
    "    print(f\"Run {remaining} trials to reach {n_trials}\")\n",
    "    study_lvri.optimize(\n",
    "        objective,\n",
    "        n_trials=remaining,\n",
    "        show_progress_bar=True,\n",
    "        n_jobs=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72b5e21-4799-455f-aed3-0941f856a4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.08116086324056"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_lvri.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae1a678-b0b5-44bc-9438-a9991392e0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate 0.03876143929687533\n",
      "max_depth 10\n",
      "min_child_weight 15\n",
      "subsample 0.6036800627210576\n",
      "colsample_bytree 0.9850053687946877\n",
      "lambda 0.8860473392127588\n",
      "alpha 14.228611523759795\n",
      "gamma 3.526361333846049\n",
      "grow_policy lossguide\n",
      "random_state 10\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "best_params = study_lvri.best_params.copy()\n",
    "num_boost_round = best_params.pop(\"num_boost_round\")\n",
    "best_params.update({\"random_state\": RAND})\n",
    "for k, v in best_params.items():\n",
    "    print(k, v)\n",
    "print(num_boost_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aaed9c-360c-40f9-b8fb-bcf5117f53fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': (Timestamp('2021-09-01 00:00:00'),\n",
       "   Timestamp('2023-03-31 23:00:00')),\n",
       "  'test': (Timestamp('2023-04-01 00:00:00'),\n",
       "   Timestamp('2023-04-30 23:00:00'))}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "april_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a1e194-8f9d-4309-92b1-d2efe1788ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_tests = []\n",
    "OPTUNA_MODELS_DIR = Path(\"../models/xgb_optuna\")\n",
    "OPTUNA_MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i, split in enumerate(april_test):\n",
    "    X_train, y_train = drop_split(df, split[\"train\"], FEATURES_TO_DROP)\n",
    "    dtrain = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "    del X_train, y_train\n",
    "    \n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        verbose_eval=True,\n",
    "    )\n",
    "    del dtrain\n",
    "\n",
    "    model_path = OPTUNA_MODELS_DIR / f\"optuna_split_{i}.ubj\"\n",
    "    meta_path = OPTUNA_MODELS_DIR / f\"optuna_split_{i}_meta.json\"\n",
    "\n",
    "    meta = {\n",
    "        \"train_start\": str(split[\"train\"][0]),\n",
    "        \"train_end\": str(split[\"train\"][1]),\n",
    "        \"test_start\": str(split[\"test\"][0]),\n",
    "        \"test_end\": str(split[\"test\"][1]),\n",
    "        \"params\": best_params,\n",
    "        \"num_boost_round\": num_boost_round,\n",
    "    }\n",
    "\n",
    "    booster.save_model(model_path)\n",
    "    with open(meta_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        json.dump(meta, fout, ensure_ascii=False, indent=2)\n",
    "\n",
    "    X_test, y_test = drop_split(df, split[\"test\"], FEATURES_TO_DROP)\n",
    "    dtest = xgb.DMatrix(X_test, enable_categorical=True)\n",
    "    del X_test\n",
    "    preds = booster.predict(dtest)\n",
    "    mae_tests.append(MAE(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d31fe81-3450-4733-b2d7-122b8b77bf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71.47074890136719]\n"
     ]
    }
   ],
   "source": [
    "print(mae_tests)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
