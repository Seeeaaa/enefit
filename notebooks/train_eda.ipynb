{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d6b9c47-d0d8-4101-9f91-5ee2f0752041",
   "metadata": {},
   "source": [
    "# 1. Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f8e0aa-e4c4-43a5-aedb-02783adc467e",
   "metadata": {},
   "source": [
    "Data description sourced from the Kaggle competition page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a7d74-e3b1-4955-8eec-a3d7cab79fcd",
   "metadata": {},
   "source": [
    "### train.csv\n",
    "- `county` - An ID code for the county.\n",
    "- `is_business` - Boolean for whether or not the prosumer is a business.\n",
    "- `product_type` - ID code with the following mapping of codes to contract types: `{0: \"Combined\", 1: \"Fixed\", 2: \"General service\", 3: \"Spot\"}`.\n",
    "- `target` - The consumption or production amount for the relevant segment for the hour. The segments are defined by the `county`, `is_business`, and `product_type`.\n",
    "- `is_consumption` - Boolean for whether or not this row's target is consumption or production.\n",
    "- `datetime` - The Estonian time in EET (UTC+2) / EEST (UTC+3).\n",
    "- `data_block_id` - All rows sharing the same `data_block_id` will be available at the same forecast time. This is a function of what information is available when forecasts are actually made, at 11 AM each morning. For example, if the forecast weather `data_block_id` for predictins made on October 31st is 100 then the historic weather `data_block_id` for October 31st will be 101 as the historic weather data is only actually available the next day.\n",
    "- `row_id` - A unique identifier for the row.\n",
    "- `prediction_unit_id` - A unique identifier for the `county`, `is_business`, and `product_type` combination. *New prediction units can appear or disappear in the test set*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947b2733-ba9e-4bf5-bf78-6da083ca07a9",
   "metadata": {},
   "source": [
    "### gas_prices.csv\n",
    "\n",
    "- `origin_date` - The date when the day-ahead prices became available.\n",
    "- `forecast_date` - The date when the forecast prices should be relevant.\n",
    "- `[lowest/highest]_price_per_mwh` - The lowest/highest price of natural gas that on the day ahead market that trading day, in Euros per megawatt hour equivalent.\n",
    "- `data_block_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc39fed-e77a-44ad-ad57-d280adc83753",
   "metadata": {},
   "source": [
    "### client.csv\n",
    "- `product_type`\n",
    "- `county` - An ID code for the county. See `county_id_to_name_map.json` for the mapping of ID codes to county names.\n",
    "- `eic_count` - The aggregated number of consumption points (EICs - European Identifier Code).\n",
    "- `installed_capacity` - Installed photovoltaic solar panel capacity in kilowatts.\n",
    "- `is_business` - Boolean for whether or not the prosumer is a business.\n",
    "- `date`\n",
    "- `data_block_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c979aa5-2ad4-4541-a881-01ef1712c97d",
   "metadata": {},
   "source": [
    "### electricity_prices.csv\n",
    "- `origin_date`\n",
    "- `forecast_date` - Represents the start of the 1-hour period when the price is valid\n",
    "- `euros_per_mwh` - The price of electricity on the day ahead markets in euros per megawatt hour.\n",
    "- `data_block_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a73a1c7-c995-4b32-a389-aaef90094133",
   "metadata": {},
   "source": [
    "### forecast_weather.csv\n",
    "Weather forecasts that would have been available at prediction time. Sourced from the <u>[European Centre for Medium-Range Weather Forecasts](https://codes.ecmwf.int/grib/param-db/?filter=grib2)</u>.\n",
    "\n",
    "- `[latitude/longitude]` - The coordinates of the weather forecast.\n",
    "- `origin_datetime` - The timestamp of when the forecast was generated.\n",
    "- `hours_ahead` - The number of hours between the forecast generation and the forecast weather. Each forecast covers 48 hours in total.\n",
    "- `temperature` - The air temperature at 2 meters above ground in degrees Celsius. Estimated for the end of the 1-hour period.\n",
    "- `dewpoint` - The dew point temperature at 2 meters above ground in degrees Celsius. Estimated for the end of the 1-hour period.\n",
    "- `cloudcover_[low/mid/high/total]` - The percentage of the sky covered by clouds in the following altitude bands: 0-2 km, 2-6, 6+, and total. Estimated for the end of the 1-hour period.\n",
    "- `10_metre_[u/v]_wind_component` - The [eastward/northward] component of wind speed measured 10 meters above surface in meters per second. Estimated for the end of the 1-hour period.\n",
    "- `data_block_id`\n",
    "- `forecast_datetime` - The timestamp of the predicted weather. Generated from `origin_datetime` plus `hours_ahead`. This represents the start of the 1-hour period for which weather data are forecasted.\n",
    "- `direct_solar_radiation` - The direct solar radiation reaching the surface on a plane perpendicular to the direction of the Sun accumulated during the hour, in watt-hours per square meter.\n",
    "- `surface_solar_radiation_downwards` - The solar radiation, both direct and diffuse, that reaches a horizontal plane at the surface of the Earth, accumulated during the hour, in watt-hours per square meter.\n",
    "- `snowfall` - Snowfall over hour in units of meters of water equivalent.\n",
    "- `total_precipitation` - The accumulated liquid, comprising rain and snow that falls on Earth's surface over the described hour, in units of meters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a498a9-20bb-4ea3-942d-675b1eafb286",
   "metadata": {},
   "source": [
    "### historical_weather.csv\n",
    "<u>[Historic weather data](https://open-meteo.com/en/docs)</u>.\n",
    "\n",
    "- `datetime` - This represents the start of the 1-hour period for which weather data are measured.\n",
    "- `temperature` - Measured at the end of the 1-hour period.\n",
    "- `dewpoint` - Measured at the end of the 1-hour period.\n",
    "- `rain` - Different from the forecast conventions. The rain from large scale weather systems of the hour in millimeters.\n",
    "- `snowfall` - Different from the forecast conventions. Snowfall over the hour in centimeters.\n",
    "- `surface_pressure` - The air pressure at surface in hectopascals.\n",
    "- `cloudcover_[low/mid/high/total]` - Different from the forecast conventions. Cloud cover at 0-3 km, 3-8, 8+, and total.\n",
    "- `windspeed_10m` - Different from the forecast conventions. The wind speed at 10 meters above ground in meters per second.\n",
    "- `winddirection_10m` - Different from the forecast conventions. The wind direction at 10 meters above ground in degrees.\n",
    "- `shortwave_radiation` - Different from the forecast conventions. The global horizontal irradiation in watt-hours per square meter.\n",
    "- `direct_solar_radiation`\n",
    "- `diffuse_radiation` - Different from the forecast conventions. The diffuse solar irradiation in watt-hours per square meter.\n",
    "- `[latitude/longitude]` - The coordinates of the weather station.\n",
    "- `data_block_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e91539-52f2-4918-a49c-597e20e151c4",
   "metadata": {},
   "source": [
    "# 2. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8694e6f-4c39-4f4c-938a-d919b4fa6397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcet as cc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mtransforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from matplotlib import dates as mdates\n",
    "from pandas.core.groupby.generic import DataFrameGroupBy\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f25ca-5e4f-4031-a941-c597d861d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND = 10\n",
    "DATA_PATH = \"../raw_data/\"\n",
    "\n",
    "train_df = pd.read_csv(f\"{DATA_PATH}train.csv\")\n",
    "gas_prices_df = pd.read_csv(f\"{DATA_PATH}gas_prices.csv\")\n",
    "client_df = pd.read_csv(f\"{DATA_PATH}client.csv\")\n",
    "electricity_prices_df = pd.read_csv(f\"{DATA_PATH}electricity_prices.csv\")\n",
    "forecast_weather_df = pd.read_csv(f\"{DATA_PATH}forecast_weather.csv\")\n",
    "historical_weather_df = pd.read_csv(f\"{DATA_PATH}historical_weather.csv\")\n",
    "station_county_mapping = pd.read_csv(\n",
    "    f\"{DATA_PATH}weather_station_to_county_mapping.csv\"\n",
    ")\n",
    "county_id_to_name_map = pd.read_json(\n",
    "    f\"{DATA_PATH}county_id_to_name_map.json\",\n",
    "    typ=\"series\",\n",
    ").str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f971b-a00d-4c26-a23c-dfdeb274f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_DICT = {\n",
    "    \"train_df\": train_df,\n",
    "    \"gas_prices_df\": gas_prices_df,\n",
    "    \"client_df\": client_df,\n",
    "    \"electricity_prices_df\": electricity_prices_df,\n",
    "    \"forecast_weather_df\": forecast_weather_df,\n",
    "    \"historical_weather_df\": historical_weather_df,\n",
    "}\n",
    "CATEGORICAL_DICT = {\n",
    "    \"county\": county_id_to_name_map,\n",
    "    \"is_business\": {0: \"not_business\", 1: \"business\"},\n",
    "    \"is_consumption\": {0: \"production\", 1: \"consumption\"},\n",
    "    \"product_type\": {\n",
    "        0: \"combined\",\n",
    "        1: \"fixed\",\n",
    "        2: \"general_service\",\n",
    "        3: \"spot\",\n",
    "    },\n",
    "}\n",
    "COLORS_LIST = (\n",
    "    cc.glasbey[:4]\n",
    "    + [cc.glasbey[8]]\n",
    "    + cc.glasbey[5:8]\n",
    "    + [cc.glasbey[4]]\n",
    "    + [cc.glasbey[12]]\n",
    "    + cc.glasbey[10:12]\n",
    "    + [cc.glasbey[9]]\n",
    "    + cc.glasbey[13:16]\n",
    ")\n",
    "PALETTE = sns.color_palette(COLORS_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a70352-098d-4da4-aae9-3522943f0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\n",
    "    \"display.float_format\",\n",
    "    lambda x: f\"{x:.2e}\" if abs(x) < 0.01 and x != 0 else f\"{x:.2f}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b065e0a-6cbd-4f8b-9c90-c4b66e8a5928",
   "metadata": {},
   "source": [
    "# 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9e7dc-7191-4882-8da4-58fe3030a175",
   "metadata": {},
   "source": [
    "From description:\n",
    "- `datetime` - The Estonian time in EET (UTC+2) / EEST (UTC+3).\n",
    "- `data_block_id` - All rows sharing the same `data_block_id` will be available at the same forecast time. This is a function of what information is available when forecasts are actually made, at 11 AM each morning. For example, if the forecast weather `data_block_id` for predictins made on October 31st is 100 then the historic weather `data_block_id` for October 31st will be 101 as the historic weather data is only actually available the next day.\n",
    "- `row_id` - A unique identifier for the row.\n",
    "- `prediction_unit_id` - A unique identifier for the `county`, `is_business`, and `product_type` combination. *New prediction units can appear or disappear in the test set*.\n",
    "\n",
    "Also competition host <u>[provided](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers/discussion/455833)</u> this scheme:\n",
    "***\n",
    "Let’s say we are on day D at 11am. We want to predict next day D+1 net consumption from 00 to 23 for every hours.\n",
    "<table style=\"border: 1px solid black; border-collapse: collapse; width: 100%;\">\n",
    "  <tr>\n",
    "    <th style=\"border: 1px solid black;\">Category</th>\n",
    "    <th style=\"border: 1px solid black;\">Weather forecast</th>\n",
    "    <th style=\"border: 1px solid black;\">Historical weather</th>\n",
    "    <th style=\"border: 1px solid black;\">Historical consumption and production / Client data</th>\n",
    "    <th style=\"border: 1px solid black;\">Electricity prices</th>\n",
    "    <th style=\"border: 1px solid black;\">Gas prices</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid black;\">Last available data</td>\n",
    "    <td style=\"border: 1px solid black;\">Forecast for every hours of D and D+1 (published on D)</td>\n",
    "    <td style=\"border: 1px solid black;\">Every hours until day D, 10 am</td>\n",
    "    <td style=\"border: 1px solid black;\">Every hours of Day D-1</td>\n",
    "    <td style=\"border: 1px solid black;\">Every hours of day D (published on D-1)</td>\n",
    "    <td style=\"border: 1px solid black;\">Data for day D (published on D-1)</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Prices are published everyday at 2 pm (so after 11 am), that is we do not have D+1 prices.\n",
    "The data_block_id already reflects this timeline of availability of the data. There is no need to apply additional lag if joining on data_block_id.\n",
    "***\n",
    "\n",
    "Later, I will explore whether there are any discrepancies in the correlations between `data_block_id` and `datetime`, or between `prediction_unit_id` and the `categorical features`. For now, I will analyze the data by:\n",
    "1. Checking all DataFrames using `describe()` and `info()`.\n",
    "2. Verifying the presence of missing values or duplicates.\n",
    "\n",
    "I will use the following functions for initial analysis and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f1f9d-7938-4863-a3ee-85b470c4deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_centered_header(text: str) -> None:\n",
    "    \"\"\"\n",
    "    Prints a line of 100 characters with the given text centered in\n",
    "    it and filled with '<>'.\n",
    "    \"\"\"\n",
    "    total_length = 100\n",
    "    text = f\" {text.strip()} \"\n",
    "    side_length = (total_length - len(text)) // 2\n",
    "    print(\n",
    "        \"<\" * side_length\n",
    "        + text\n",
    "        + \">\" * (total_length - len(text) - side_length)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22058a79-8e71-4372-9b74-a4f77b4c2107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_show_info(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Display DataFrame summary, NaNs and duplicated values.\n",
    "    \"\"\"\n",
    "\n",
    "    print_centered_header(\"HEAD\")\n",
    "    display(df.head())\n",
    "\n",
    "    print_centered_header(\"INFO\")\n",
    "    df.info(show_counts=True)\n",
    "\n",
    "    print_centered_header(\"DESCRIBE\")\n",
    "    display(df.describe(include=\"all\"))\n",
    "\n",
    "    print_centered_header(\"MISSING VALUES\")\n",
    "    nan_counts = df.isna().sum()\n",
    "    nan_series = nan_counts[nan_counts > 0]\n",
    "    if nan_series.empty:\n",
    "        print(\"No missing values\")\n",
    "    else:\n",
    "        display(nan_series)\n",
    "\n",
    "    print_centered_header(\"DUPLICATES\")\n",
    "    dup_counts = df.duplicated().sum()\n",
    "    if dup_counts:\n",
    "        display(dup_counts)\n",
    "    else:\n",
    "        print(\"No duplicate rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6c2409-d07e-4233-8f03-e87f200726df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_mapper(\n",
    "    df: pd.DataFrame,\n",
    "    values_mapper: dict,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Map categorical columns in the DataFrame to their corresponding\n",
    "    values based on the provided mapper and convert these columns to\n",
    "    categorical type.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame to process.\n",
    "    values_mapper : dict\n",
    "        A dictionary where keys are column names, and values are\n",
    "        mapping dictionaries.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Modified DataFrame with specified columns mapped to their\n",
    "        categorical values.\n",
    "    \"\"\"\n",
    "    for key, value in values_mapper.items():\n",
    "        if key in df.columns:\n",
    "            df[key] = df[key].map(value).astype(\"category\")\n",
    "        else:\n",
    "            print(f\"Column '{key}' not found in DataFrame, skipping.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec08694b-0ac5-4b58-99e2-e9231b4a4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mismatched_indices_check(\n",
    "    date_diff: pd.Series,\n",
    "    id_diff: pd.Series,\n",
    "    difference: np.float64,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Check if rows with an n-day difference in the date_diff have\n",
    "    mismatched indices with id_diff rows that have difference of n.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\n",
    "        f\"Difference {difference}: \",[\n",
    "            \"no mismatches\",\n",
    "            \"indices mismatch detected\"][\n",
    "        int(np.any(\n",
    "            date_diff[date_diff == pd.Timedelta(difference, \"day\")]\n",
    "            .index\n",
    "            != id_diff[id_diff == difference].index))],\n",
    "        \".\",\n",
    "        sep=\"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c11981-b592-495d-8765-2cf853d62efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_groups(dfgb: DataFrameGroupBy, column: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Combine values of the specified column in each subgroup into tuples,\n",
    "    compare these tuples within each group, and return the count of\n",
    "    duplicated and non-duplicated tuples.\n",
    "    \"\"\"\n",
    "    return dfgb[column].agg(tuple).duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d370cf86-2a74-4eb8-ae1a-e76832270193",
   "metadata": {},
   "source": [
    "## train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26fa8d-480e-4216-814e-186a8ba13a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< HEAD >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>target</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>datetime</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>prediction_unit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96.59</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17.31</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   county  is_business  product_type  target  is_consumption  \\\n",
       "0       0            0             1    0.71               0   \n",
       "1       0            0             1   96.59               1   \n",
       "2       0            0             2    0.00               0   \n",
       "3       0            0             2   17.31               1   \n",
       "4       0            0             3    2.90               0   \n",
       "\n",
       "              datetime  data_block_id  row_id  prediction_unit_id  \n",
       "0  2021-09-01 00:00:00              0       0                   0  \n",
       "1  2021-09-01 00:00:00              0       1                   0  \n",
       "2  2021-09-01 00:00:00              0       2                   1  \n",
       "3  2021-09-01 00:00:00              0       3                   1  \n",
       "4  2021-09-01 00:00:00              0       4                   2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< INFO >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2018352 entries, 0 to 2018351\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   county              2018352 non-null  int64  \n",
      " 1   is_business         2018352 non-null  int64  \n",
      " 2   product_type        2018352 non-null  int64  \n",
      " 3   target              2017824 non-null  float64\n",
      " 4   is_consumption      2018352 non-null  int64  \n",
      " 5   datetime            2018352 non-null  object \n",
      " 6   data_block_id       2018352 non-null  int64  \n",
      " 7   row_id              2018352 non-null  int64  \n",
      " 8   prediction_unit_id  2018352 non-null  int64  \n",
      "dtypes: float64(1), int64(7), object(1)\n",
      "memory usage: 138.6+ MB\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< DESCRIBE >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>target</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>datetime</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>prediction_unit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2018352.00</td>\n",
       "      <td>2018352.00</td>\n",
       "      <td>2018352.00</td>\n",
       "      <td>2017824.00</td>\n",
       "      <td>2018352.00</td>\n",
       "      <td>2018352</td>\n",
       "      <td>2018352.00</td>\n",
       "      <td>2018352.00</td>\n",
       "      <td>2018352.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-27 12:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.30</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.90</td>\n",
       "      <td>274.86</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321.87</td>\n",
       "      <td>1009175.50</td>\n",
       "      <td>33.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.78</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.08</td>\n",
       "      <td>909.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182.63</td>\n",
       "      <td>582648.18</td>\n",
       "      <td>19.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.00</td>\n",
       "      <td>504587.75</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>31.13</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323.00</td>\n",
       "      <td>1009175.50</td>\n",
       "      <td>33.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>180.21</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>479.00</td>\n",
       "      <td>1513763.25</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>15480.27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>637.00</td>\n",
       "      <td>2018351.00</td>\n",
       "      <td>68.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           county  is_business  product_type     target  is_consumption  \\\n",
       "count  2018352.00   2018352.00    2018352.00 2017824.00      2018352.00   \n",
       "unique        NaN          NaN           NaN        NaN             NaN   \n",
       "top           NaN          NaN           NaN        NaN             NaN   \n",
       "freq          NaN          NaN           NaN        NaN             NaN   \n",
       "mean         7.30         0.54          1.90     274.86            0.50   \n",
       "std          4.78         0.50          1.08     909.50            0.50   \n",
       "min          0.00         0.00          0.00       0.00            0.00   \n",
       "25%          3.00         0.00          1.00       0.38            0.00   \n",
       "50%          7.00         1.00          2.00      31.13            0.50   \n",
       "75%         11.00         1.00          3.00     180.21            1.00   \n",
       "max         15.00         1.00          3.00   15480.27            1.00   \n",
       "\n",
       "                   datetime  data_block_id     row_id  prediction_unit_id  \n",
       "count               2018352     2018352.00 2018352.00          2018352.00  \n",
       "unique                15312            NaN        NaN                 NaN  \n",
       "top     2022-11-27 12:00:00            NaN        NaN                 NaN  \n",
       "freq                    138            NaN        NaN                 NaN  \n",
       "mean                    NaN         321.87 1009175.50               33.05  \n",
       "std                     NaN         182.63  582648.18               19.59  \n",
       "min                     NaN           0.00       0.00                0.00  \n",
       "25%                     NaN         166.00  504587.75               16.00  \n",
       "50%                     NaN         323.00 1009175.50               33.00  \n",
       "75%                     NaN         479.00 1513763.25               50.00  \n",
       "max                     NaN         637.00 2018351.00               68.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< MISSING VALUES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target    528\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< DUPLICATES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No duplicate rows\n"
     ]
    }
   ],
   "source": [
    "df_show_info(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276e470-db61-40b8-b140-9d06e4661c6a",
   "metadata": {},
   "source": [
    "- There is a small number of missing values (528/2,018,352 < 0.1%) and no duplicates in the DataFrame. Only the `target` feature contains missing values, which can likely be handled using interpolation or mean imputation to ensure data consistency.\n",
    "- The categorical features `county`, `is_business`, `product_type`, and `is_consumption` can be converted to the categorical data type. Additionally, their values can be renamed to improve clarity and understanding.\n",
    "- The `target` feature can be converted to `float32` for memory optimization.\n",
    "- The `datetime` feature can be converted to `datetime64[ns]`.\n",
    "- The `data_block_id` feature can be converted to `uint16` (range: 0 through 65,535) due to its small maximum value.\n",
    "- The `row_id` feature appears to be similar to the index values in the current default sorting. This feature could potentially be deleted in the future if it is not used for data merging later. For now, it can be converted to `uint32` (range: 0 through 4,294,967,295) as its range fits well within this data type. The use of `int64` is unnecessary because it supports negative numbers, which are irrelevant in this case.\n",
    "- The `prediction_unit_id` feature can be converted to `uint8` (range: 0 through 255). Although new combinations may appear in the future, this data type is sufficient to uniquely represent all future combinations of current county, is_business, and product_type (16 * 2 * 4 = 96)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116376df-986a-4875-bbaf-cea7a4691065",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a7bef3-191a-4c37-92ab-2b54f5aaa4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename to avoid confusion and improve readability\n",
    "train_df = categorical_mapper(train_df, CATEGORICAL_DICT)\n",
    "\n",
    "# Change data types to reduce memory usage\n",
    "train_df = train_df.astype(\n",
    "    {\n",
    "        \"target\": \"float32\",\n",
    "        \"data_block_id\": \"uint16\",\n",
    "        \"row_id\": \"uint32\",\n",
    "        \"prediction_unit_id\": \"uint8\",\n",
    "        \"datetime\": \"datetime64[ns]\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Rename to distinct from datetime-like features from other DFs\n",
    "train_df = train_df.rename(columns={\"datetime\": \"target_datetime\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a38920-b145-4834-b3ee-4e6d1c2cf9c8",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73cb832-7f59-466f-8bf8-c3f29cca04f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>target</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>target_datetime</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>prediction_unit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178938</th>\n",
       "      <td>Harjumaa</td>\n",
       "      <td>not_business</td>\n",
       "      <td>fixed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>production</td>\n",
       "      <td>2021-10-31 03:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>178938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178939</th>\n",
       "      <td>Harjumaa</td>\n",
       "      <td>not_business</td>\n",
       "      <td>fixed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>consumption</td>\n",
       "      <td>2021-10-31 03:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>178939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178940</th>\n",
       "      <td>Harjumaa</td>\n",
       "      <td>not_business</td>\n",
       "      <td>general_service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>production</td>\n",
       "      <td>2021-10-31 03:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>178940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178941</th>\n",
       "      <td>Harjumaa</td>\n",
       "      <td>not_business</td>\n",
       "      <td>general_service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>consumption</td>\n",
       "      <td>2021-10-31 03:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>178941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178942</th>\n",
       "      <td>Harjumaa</td>\n",
       "      <td>not_business</td>\n",
       "      <td>spot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>production</td>\n",
       "      <td>2021-10-31 03:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>178942</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          county   is_business     product_type  target is_consumption  \\\n",
       "178938  Harjumaa  not_business            fixed     NaN     production   \n",
       "178939  Harjumaa  not_business            fixed     NaN    consumption   \n",
       "178940  Harjumaa  not_business  general_service     NaN     production   \n",
       "178941  Harjumaa  not_business  general_service     NaN    consumption   \n",
       "178942  Harjumaa  not_business             spot     NaN     production   \n",
       "\n",
       "           target_datetime  data_block_id  row_id  prediction_unit_id  \n",
       "178938 2021-10-31 03:00:00             60  178938                   0  \n",
       "178939 2021-10-31 03:00:00             60  178939                   0  \n",
       "178940 2021-10-31 03:00:00             60  178940                   1  \n",
       "178941 2021-10-31 03:00:00             60  178941                   1  \n",
       "178942 2021-10-31 03:00:00             60  178942                   2  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.isna().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540205db-12b9-4799-9270-d659285802f8",
   "metadata": {},
   "source": [
    "The `datetime` values for rows with missing target values start from '2021-10-31 03:00:00', rather than from '2021-09-01 00:00:00'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abafc092-d591-48f0-b690-f6f042dd8a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2021-10-31 03:00:00', '2022-03-27 03:00:00', '2022-10-30 03:00:00',\n",
       " '2023-03-26 03:00:00']\n",
       "Length: 4, dtype: datetime64[ns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_datetimes = train_df[train_df.isna().any(axis=1)].target_datetime.unique()\n",
    "na_datetimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5904abf-b0e6-4553-8d34-29876715901e",
   "metadata": {},
   "source": [
    "All missing values correspond to the start or end of daylight saving time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879cdba-8ed4-4dc5-92e7-7ff9510f7b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().values.sum() == (\n",
    "    train_df.loc[\n",
    "        train_df[\"target_datetime\"].isin(na_datetimes), [\"target\"]\n",
    "    ].shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6496441-199b-4f92-88de-130257f60e99",
   "metadata": {},
   "source": [
    "All 528 target values at these timestamps are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d4c88b-6973-4caf-86d4-22fc6e56d005",
   "metadata": {},
   "source": [
    "### Consistency and Relationship Validation\n",
    "#### Row Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165075d2-d32b-47c1-81d3-877f37ac378f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_df[\"row_id\"] != train_df.index).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c933c4-19d6-431c-a0d4-f573a5583a99",
   "metadata": {},
   "source": [
    "All `row_id` values are equal to index values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2f0e13-ea49-40f3-bf67-f90ab25c624d",
   "metadata": {},
   "source": [
    "#### Datetime and data_block_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f268a-47c2-44a4-b0a0-ffb3b8e65b20",
   "metadata": {},
   "source": [
    "For predictions made for day D + 1, all historical consumption and production data should have `data_block_id` values equal to D - 1. This is because the `data_block_id` represents the data available at a specific time. Data for day D is unavailable at the time of prediction, as it corresponds to the current day, and no historical data exists for it yet.\n",
    "\n",
    "Therefore, `target_datetime` and `data_block_id` columns require a check to ensure that, in chronological order, both the date and id values show uniform growth. That is, if one date corresponds to multiple `data_block_id` values, it will be noticeable, as the differences between rows in these two columns will not be uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ebe91c-d0fc-4406-9846-0ef5a7733e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date differences: <TimedeltaArray>\n",
      "[NaT, '0 days', '1 days']\n",
      "Length: 3, dtype: timedelta64[ns]\n",
      "Data block ID differences: [nan  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Create variables to store the differences between the current and\n",
    "# previous row for all rows in target_datetime and data_block_id\n",
    "train_date_diff = train_df[\"target_datetime\"].dt.date.diff()\n",
    "train_id_diff = train_df[\"data_block_id\"].diff()\n",
    "\n",
    "# Print unique values to verify that default order reflects sorting\n",
    "# from oldest to newest without skips\n",
    "print(\"Date differences:\", train_date_diff.unique())\n",
    "print(\"Data block ID differences:\", train_id_diff.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec5185-1db8-4b0f-ad40-a02158da4c6f",
   "metadata": {},
   "source": [
    "- `NaT` and `NaN` values correspond to the first row in both columns, where no previous row data is available for comparison.\n",
    "- A value of '0' indicates that the current and previous rows belong to the same day.\n",
    "- A value of '1' indicates the transition from one day to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5effd833-7188-40e0-af43-7b4c5a2bf0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference nan: no mismatches.\n",
      "Difference 0.0: no mismatches.\n",
      "Difference 1.0: no mismatches.\n"
     ]
    }
   ],
   "source": [
    "for difference in train_id_diff.unique():\n",
    "    mismatched_indices_check(train_date_diff, train_id_diff, difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5844145-bb47-4d99-9c87-f651c87667ee",
   "metadata": {},
   "source": [
    "The default order of the raw data for this DataFrame is sorted by datetime, and the `data_block_id` reflects the actual data availability, with no errors observed in the `target_datetime` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eb884e-139d-45f0-b097-00b97bfd7db1",
   "metadata": {},
   "source": [
    "#### Categorical Features and Their Identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abbc69f-e0a9-4365-9120-c2ea83e07d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that each combination of county, product_type, and\n",
    "# is_business corresponds to exactly one unique prediction_unit_id\n",
    "(\n",
    "    train_df.groupby(\n",
    "        [\n",
    "            \"county\",\n",
    "            \"product_type\",\n",
    "            \"is_business\",\n",
    "        ],\n",
    "        observed=True,\n",
    "    )[\"prediction_unit_id\"].nunique()\n",
    "    != 1\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d8fe47-e778-438d-9512-c9adfc418174",
   "metadata": {},
   "source": [
    "All combinations of `county`, `is_business`, and `product_type` correspond to a single `prediction_unit_id`, with no errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70137672-8297-45a9-a357-3e0ff989d2ec",
   "metadata": {},
   "source": [
    "## gas_prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f2c74-d559-458c-9a78-5c9e92138fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< HEAD >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>lowest_price_per_mwh</th>\n",
       "      <th>highest_price_per_mwh</th>\n",
       "      <th>origin_date</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>45.23</td>\n",
       "      <td>46.32</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-02</td>\n",
       "      <td>45.62</td>\n",
       "      <td>46.29</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-03</td>\n",
       "      <td>45.85</td>\n",
       "      <td>46.40</td>\n",
       "      <td>2021-09-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-04</td>\n",
       "      <td>46.30</td>\n",
       "      <td>46.80</td>\n",
       "      <td>2021-09-03</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-05</td>\n",
       "      <td>46.30</td>\n",
       "      <td>46.58</td>\n",
       "      <td>2021-09-04</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  forecast_date  lowest_price_per_mwh  highest_price_per_mwh origin_date  \\\n",
       "0    2021-09-01                 45.23                  46.32  2021-08-31   \n",
       "1    2021-09-02                 45.62                  46.29  2021-09-01   \n",
       "2    2021-09-03                 45.85                  46.40  2021-09-02   \n",
       "3    2021-09-04                 46.30                  46.80  2021-09-03   \n",
       "4    2021-09-05                 46.30                  46.58  2021-09-04   \n",
       "\n",
       "   data_block_id  \n",
       "0              1  \n",
       "1              2  \n",
       "2              3  \n",
       "3              4  \n",
       "4              5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< INFO >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 637 entries, 0 to 636\n",
      "Data columns (total 5 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   forecast_date          637 non-null    object \n",
      " 1   lowest_price_per_mwh   637 non-null    float64\n",
      " 2   highest_price_per_mwh  637 non-null    float64\n",
      " 3   origin_date            637 non-null    object \n",
      " 4   data_block_id          637 non-null    int64  \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 25.0+ KB\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< DESCRIBE >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>lowest_price_per_mwh</th>\n",
       "      <th>highest_price_per_mwh</th>\n",
       "      <th>origin_date</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>637</td>\n",
       "      <td>637.00</td>\n",
       "      <td>637.00</td>\n",
       "      <td>637</td>\n",
       "      <td>637.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>95.04</td>\n",
       "      <td>107.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>319.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>47.55</td>\n",
       "      <td>54.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>184.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.10</td>\n",
       "      <td>34.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>60.00</td>\n",
       "      <td>67.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>85.21</td>\n",
       "      <td>93.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>319.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>109.00</td>\n",
       "      <td>130.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>478.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>250.00</td>\n",
       "      <td>305.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>637.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       forecast_date  lowest_price_per_mwh  highest_price_per_mwh origin_date  \\\n",
       "count            637                637.00                 637.00         637   \n",
       "unique           637                   NaN                    NaN         637   \n",
       "top       2021-09-01                   NaN                    NaN  2021-08-31   \n",
       "freq               1                   NaN                    NaN           1   \n",
       "mean             NaN                 95.04                 107.75         NaN   \n",
       "std              NaN                 47.55                  54.74         NaN   \n",
       "min              NaN                 28.10                  34.00         NaN   \n",
       "25%              NaN                 60.00                  67.53         NaN   \n",
       "50%              NaN                 85.21                  93.47         NaN   \n",
       "75%              NaN                109.00                 130.74         NaN   \n",
       "max              NaN                250.00                 305.00         NaN   \n",
       "\n",
       "        data_block_id  \n",
       "count          637.00  \n",
       "unique            NaN  \n",
       "top               NaN  \n",
       "freq              NaN  \n",
       "mean           319.00  \n",
       "std            184.03  \n",
       "min              1.00  \n",
       "25%            160.00  \n",
       "50%            319.00  \n",
       "75%            478.00  \n",
       "max            637.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< MISSING VALUES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No missing values\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< DUPLICATES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No duplicate rows\n"
     ]
    }
   ],
   "source": [
    "df_show_info(gas_prices_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb7db5-4144-4ba4-8124-1e8794b88c25",
   "metadata": {},
   "source": [
    "- There are no missing values or duplicates in the DataFrame.\n",
    "- The `data_block_id` values start from 1, unlike the `data_block_id` values in train_df, which start from 0. This difference exists because </u>[`[lowest/highest]_price_per_mwh` are end-of-day prices and aren't available in the late morning when forecasts are made](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers/discussion/453355#2515054)</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d22ee4-948f-4d37-a90b-dfe11be0fa14",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ef5dc-7d5f-4f05-b46d-ee52791e3c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data types to reduce memory usage\n",
    "gas_prices_df = gas_prices_df.astype(\n",
    "    {\n",
    "        \"forecast_date\": \"datetime64[ns]\",\n",
    "        \"lowest_price_per_mwh\": \"float32\",\n",
    "        \"highest_price_per_mwh\": \"float32\",\n",
    "        \"origin_date\": \"datetime64[ns]\",\n",
    "        \"data_block_id\": \"uint16\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Rename to distinct from datetime-like features from other DFs\n",
    "gas_prices_df = gas_prices_df.rename(\n",
    "    columns={\n",
    "        \"forecast_date\": \"gas_forecast_date\",\n",
    "        \"origin_date\": \"gas_origin_date\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c6c68f-f43b-4457-b4b2-caf1379641bc",
   "metadata": {},
   "source": [
    "### Consistency and Relationship Validation\n",
    "#### Origin and forecast dates\n",
    "Due to the strong correlation between the two datetime columns (at least based on the description and a few observed rows), it's necessary to verify if this correlation holds true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b8c99-8b05-4406-8fa4-a13ffe01b079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TimedeltaArray>\n",
      "[NaT, '1 days']\n",
      "Length: 2, dtype: timedelta64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Check that each origin date is the next day compared to the previous\n",
    "# one\n",
    "\n",
    "gas_date_diff = gas_prices_df[\"gas_origin_date\"].diff()\n",
    "print(gas_date_diff.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac223506-6fec-481d-9eb8-bc8dfc36cd1b",
   "metadata": {},
   "source": [
    "- Yes, all values are chronological days without skips. The `NaT` value corresponds to the first date, where no previous date exists for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9254055c-50b3-4702-8057-0b5862e6b10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any forecast dates are not exactly one day after origin dates\n",
    "(\n",
    "    gas_prices_df[\"gas_origin_date\"]\n",
    "    + pd.Timedelta(days=1)\n",
    "    != gas_prices_df[\"gas_forecast_date\"]\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f40e67-c764-4985-b86d-904044194ddd",
   "metadata": {},
   "source": [
    "- All `gas_origin_date` values are correct and represent the day before their corresponding `gas_forecast_date` values. This means that correlation between these features is 1, and one of them can likely be deleted.\n",
    "- The raw data in this DataFrame is sorted chronologically by datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a83fe-b2d0-4909-96ea-d77ec3d3a3d9",
   "metadata": {},
   "source": [
    "#### Origin date and data_block_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f248ed1-f98b-4c91-aa71-3c3f73073720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan  1.]\n"
     ]
    }
   ],
   "source": [
    "gas_id_diff = gas_prices_df[\"data_block_id\"].diff()\n",
    "print(gas_id_diff.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252e0e15-83ad-4f2f-8148-767be995779f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference nan: no mismatches.\n",
      "Difference 1.0: no mismatches.\n"
     ]
    }
   ],
   "source": [
    "for difference in gas_id_diff.unique():\n",
    "    mismatched_indices_check(gas_date_diff, gas_id_diff, difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522bb44a-1e9d-45fd-bf7f-33d8b473820b",
   "metadata": {},
   "source": [
    "- Similar to `gas_origin_date`, the first value is missing, and all subsequent values have a difference of 1. Since the differences are consistent across both columns, it can be concluded that there are no errors between `gas_origin_date` and `data_block_id`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc05598f-23b8-4c4d-9348-195317dc2dba",
   "metadata": {},
   "source": [
    "## client_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de931d3-3a4d-450b-a38c-df9047d00dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< HEAD >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type</th>\n",
       "      <th>county</th>\n",
       "      <th>eic_count</th>\n",
       "      <th>installed_capacity</th>\n",
       "      <th>is_business</th>\n",
       "      <th>date</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>952.89</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>166.40</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>688</td>\n",
       "      <td>7207.88</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>400.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1411.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_type  county  eic_count  installed_capacity  is_business  \\\n",
       "0             1       0        108              952.89            0   \n",
       "1             2       0         17              166.40            0   \n",
       "2             3       0        688             7207.88            0   \n",
       "3             0       0          5              400.00            1   \n",
       "4             1       0         43             1411.00            1   \n",
       "\n",
       "         date  data_block_id  \n",
       "0  2021-09-01              2  \n",
       "1  2021-09-01              2  \n",
       "2  2021-09-01              2  \n",
       "3  2021-09-01              2  \n",
       "4  2021-09-01              2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< INFO >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41919 entries, 0 to 41918\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   product_type        41919 non-null  int64  \n",
      " 1   county              41919 non-null  int64  \n",
      " 2   eic_count           41919 non-null  int64  \n",
      " 3   installed_capacity  41919 non-null  float64\n",
      " 4   is_business         41919 non-null  int64  \n",
      " 5   date                41919 non-null  object \n",
      " 6   data_block_id       41919 non-null  int64  \n",
      "dtypes: float64(1), int64(5), object(1)\n",
      "memory usage: 2.2+ MB\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< DESCRIBE >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type</th>\n",
       "      <th>county</th>\n",
       "      <th>eic_count</th>\n",
       "      <th>installed_capacity</th>\n",
       "      <th>is_business</th>\n",
       "      <th>date</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41919.00</td>\n",
       "      <td>41919.00</td>\n",
       "      <td>41919.00</td>\n",
       "      <td>41919.00</td>\n",
       "      <td>41919.00</td>\n",
       "      <td>41919</td>\n",
       "      <td>41919.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>636</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.90</td>\n",
       "      <td>7.30</td>\n",
       "      <td>73.35</td>\n",
       "      <td>1450.77</td>\n",
       "      <td>0.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>322.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.08</td>\n",
       "      <td>4.78</td>\n",
       "      <td>144.06</td>\n",
       "      <td>2422.23</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>321.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>645.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>324.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>1567.15</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>480.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1517.00</td>\n",
       "      <td>19314.31</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>637.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        product_type   county  eic_count  installed_capacity  is_business  \\\n",
       "count       41919.00 41919.00   41919.00            41919.00     41919.00   \n",
       "unique           NaN      NaN        NaN                 NaN          NaN   \n",
       "top              NaN      NaN        NaN                 NaN          NaN   \n",
       "freq             NaN      NaN        NaN                 NaN          NaN   \n",
       "mean            1.90     7.30      73.35             1450.77         0.54   \n",
       "std             1.08     4.78     144.06             2422.23         0.50   \n",
       "min             0.00     0.00       5.00                5.50         0.00   \n",
       "25%             1.00     3.00      13.00              321.90         0.00   \n",
       "50%             2.00     7.00      32.00              645.20         1.00   \n",
       "75%             3.00    11.00      70.00             1567.15         1.00   \n",
       "max             3.00    15.00    1517.00            19314.31         1.00   \n",
       "\n",
       "              date  data_block_id  \n",
       "count        41919       41919.00  \n",
       "unique         636            NaN  \n",
       "top     2022-11-26            NaN  \n",
       "freq            69            NaN  \n",
       "mean           NaN         322.90  \n",
       "std            NaN         182.08  \n",
       "min            NaN           2.00  \n",
       "25%            NaN         167.00  \n",
       "50%            NaN         324.00  \n",
       "75%            NaN         480.00  \n",
       "max            NaN         637.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< MISSING VALUES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No missing values\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< DUPLICATES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No duplicate rows\n"
     ]
    }
   ],
   "source": [
    "df_show_info(client_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed2c661-ba53-4858-b61b-fababe96d55f",
   "metadata": {},
   "source": [
    "- There are no missing values or duplicates in the DataFrame.\n",
    "- The `data_block_id` values start from 2 instead of 0 or 1, as mentioned earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37133253-bdda-4121-a185-856ee26f650d",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c71bd98-3e38-4c5f-97a4-bfd9c1b7e8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'is_consumption' not found in DataFrame, skipping.\n"
     ]
    }
   ],
   "source": [
    "# Rename to avoid confusion and improve readability\n",
    "client_df = categorical_mapper(client_df, CATEGORICAL_DICT)\n",
    "\n",
    "# Change data types to reduce memory usage\n",
    "client_df = client_df.astype(\n",
    "    {\n",
    "        \"eic_count\": \"uint32\",\n",
    "        \"installed_capacity\": \"float32\",\n",
    "        \"date\": \"datetime64[ns]\",\n",
    "        \"data_block_id\": \"uint16\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Rename to distinct from datetime-like features from other DFs\n",
    "client_df = client_df.rename(columns={\"date\": \"client_date\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd668c-fb8c-40fd-9ba4-1b915b83d911",
   "metadata": {},
   "source": [
    "### Consistency and Relationship Validation\n",
    "#### Date and data_block_id\n",
    "As with the previous DataFrames, it is necessary to validate the correlation between `client_date` and `data_block_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b63cf9-15d2-4f24-b2a0-1999d15b760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date differences: <TimedeltaArray>\n",
      "[NaT, '0 days', '1 days']\n",
      "Length: 3, dtype: timedelta64[ns]\n",
      "Data block ID differences: [nan  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Create variables to store the differences between the current and\n",
    "# previous row for all rows in client_date and data_block_id\n",
    "client_date_diff = client_df[\"client_date\"].dt.date.diff()\n",
    "client_id_diff = client_df[\"data_block_id\"].diff()\n",
    "\n",
    "\n",
    "# Print unique values to verify that default order reflects sorting\n",
    "# from oldest to newest without skips\n",
    "print(\"Date differences:\", client_date_diff.unique())\n",
    "print(\"Data block ID differences:\", client_id_diff.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2dcd03-99b7-4f13-95f1-890aefd19bf5",
   "metadata": {},
   "source": [
    "- `NaT` and `NaN` values correspond to the first row in both columns, where no previous row data is available for comparison.\n",
    "- A value of '0' indicates that the current and previous rows belong to the same day.\n",
    "- A value of '1' indicates the transition from one day to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89eda7a-2f9b-44ca-ab7c-1ddc5cd526a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference nan: no mismatches.\n",
      "Difference 0.0: no mismatches.\n",
      "Difference 1.0: no mismatches.\n"
     ]
    }
   ],
   "source": [
    "for difference in client_id_diff.unique():\n",
    "    mismatched_indices_check(client_date_diff, client_id_diff, difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae831531-752d-4ca8-902e-c428007961f0",
   "metadata": {},
   "source": [
    "- The default order of the raw data for this DataFrame is sorted by datetime, and the `data_block_id` reflects the actual data availability, with no errors observed in the `client_date` column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d83cf3c-9401-442d-bae5-290c9e14e973",
   "metadata": {},
   "source": [
    "## electricity_prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c7771-33b8-4c10-b6b4-f031d455512a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< HEAD >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>euros_per_mwh</th>\n",
       "      <th>origin_date</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>92.51</td>\n",
       "      <td>2021-08-31 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-01 01:00:00</td>\n",
       "      <td>88.90</td>\n",
       "      <td>2021-08-31 01:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-01 02:00:00</td>\n",
       "      <td>87.35</td>\n",
       "      <td>2021-08-31 02:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-01 03:00:00</td>\n",
       "      <td>86.88</td>\n",
       "      <td>2021-08-31 03:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-01 04:00:00</td>\n",
       "      <td>88.43</td>\n",
       "      <td>2021-08-31 04:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         forecast_date  euros_per_mwh          origin_date  data_block_id\n",
       "0  2021-09-01 00:00:00          92.51  2021-08-31 00:00:00              1\n",
       "1  2021-09-01 01:00:00          88.90  2021-08-31 01:00:00              1\n",
       "2  2021-09-01 02:00:00          87.35  2021-08-31 02:00:00              1\n",
       "3  2021-09-01 03:00:00          86.88  2021-08-31 03:00:00              1\n",
       "4  2021-09-01 04:00:00          88.43  2021-08-31 04:00:00              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< INFO >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15286 entries, 0 to 15285\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   forecast_date  15286 non-null  object \n",
      " 1   euros_per_mwh  15286 non-null  float64\n",
      " 2   origin_date    15286 non-null  object \n",
      " 3   data_block_id  15286 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 477.8+ KB\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< DESCRIBE >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>euros_per_mwh</th>\n",
       "      <th>origin_date</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15286</td>\n",
       "      <td>15286.00</td>\n",
       "      <td>15286</td>\n",
       "      <td>15286.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>15286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15286</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-08-31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>157.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>318.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>121.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>85.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>128.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>319.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>199.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>478.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>637.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              forecast_date  euros_per_mwh          origin_date  data_block_id\n",
       "count                 15286       15286.00                15286       15286.00\n",
       "unique                15286            NaN                15286            NaN\n",
       "top     2021-09-01 00:00:00            NaN  2021-08-31 00:00:00            NaN\n",
       "freq                      1            NaN                    1            NaN\n",
       "mean                    NaN         157.06                  NaN         318.99\n",
       "std                     NaN         121.15                  NaN         183.89\n",
       "min                     NaN         -10.06                  NaN           1.00\n",
       "25%                     NaN          85.29                  NaN         160.00\n",
       "50%                     NaN         128.28                  NaN         319.00\n",
       "75%                     NaN         199.80                  NaN         478.00\n",
       "max                     NaN        4000.00                  NaN         637.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< MISSING VALUES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No missing values\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< DUPLICATES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No duplicate rows\n"
     ]
    }
   ],
   "source": [
    "df_show_info(electricity_prices_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e19efa-97a7-461f-a349-a1aaab1a2bc3",
   "metadata": {},
   "source": [
    "- There are no missing values or duplicates in the DataFrame.\n",
    "- The `data_block_id` values start from 1.\n",
    "- The minimum value of the `euros_per_mwh` column is negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0431754-2c7e-4bb2-950e-0c784961306e",
   "metadata": {},
   "source": [
    "### Non-positive Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c2d28-1315-43e2-b010-dcda1ca0d7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electricity_prices_df[electricity_prices_df[\"euros_per_mwh\"] <= 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e9d81-64b2-437f-8658-8d8a156a0015",
   "metadata": {},
   "source": [
    "According to the [<u>official comment</u>](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers/discussion/454932#2523730), such prices are not an error.\n",
    "\n",
    "[<u>From Wikipedia</u>](https://en.wikipedia.org/wiki/Negative_pricing): negative pricing can occur when demand for a product drops or supply increases to an extent that owners or suppliers are prepared to pay others to accept it, in effect setting the price to a negative number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f68560-19e4-4cd6-b567-db034d5735da",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a822d526-6132-4206-bc9d-d6d39cc3f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data types to reduce memory usage\n",
    "electricity_prices_df = electricity_prices_df.astype(\n",
    "    {\n",
    "        \"forecast_date\": \"datetime64[ns]\",\n",
    "        \"euros_per_mwh\": \"float32\",\n",
    "        \"origin_date\": \"datetime64[ns]\",\n",
    "        \"data_block_id\": \"uint16\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Rename to distinct from datetime-like features from other DFs\n",
    "electricity_prices_df = electricity_prices_df.rename(\n",
    "    columns={\n",
    "        \"forecast_date\": \"electricity_forecast_datetime\",\n",
    "        \"origin_date\": \"electricity_origin_datetime\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229fdca-c53e-498a-93fe-6db5a3dcee54",
   "metadata": {},
   "source": [
    "### Consistency and Relationship Validation\n",
    "As with `electricity_prices_df`, it is necessary to validate the correlation between origin date, forecast date, and `data_block_id`.\n",
    "#### Origin and forecast dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61db965b-9986-4363-8c17-c1cf29ae112e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimedeltaArray>\n",
       "[NaT, '0 days 01:00:00', '0 days 02:00:00']\n",
       "Length: 3, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that each electricity_origin_date is the next hour compared\n",
    "# to the previous one\n",
    "electricity_prices_df[\"electricity_origin_datetime\"].diff().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ce105-379c-4349-bde1-a6ecaac260e7",
   "metadata": {},
   "source": [
    "There are also values with a 2-hour difference. This might indicate an issue with data collection or other inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b4597-7d6a-4832-9c4a-261ecf548801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>electricity_forecast_datetime</th>\n",
       "      <th>euros_per_mwh</th>\n",
       "      <th>electricity_origin_datetime</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>2022-03-27 03:00:00</td>\n",
       "      <td>100.07</td>\n",
       "      <td>2022-03-26 03:00:00</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13705</th>\n",
       "      <td>2023-03-26 03:00:00</td>\n",
       "      <td>40.12</td>\n",
       "      <td>2023-03-25 03:00:00</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      electricity_forecast_datetime  euros_per_mwh  \\\n",
       "4970            2022-03-27 03:00:00         100.07   \n",
       "13705           2023-03-26 03:00:00          40.12   \n",
       "\n",
       "      electricity_origin_datetime  data_block_id  \n",
       "4970          2022-03-26 03:00:00            208  \n",
       "13705         2023-03-25 03:00:00            572  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electricity_prices_df[\n",
    "    electricity_prices_df[\"electricity_origin_datetime\"].diff()\n",
    "    == pd.Timedelta(2, \"hour\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dee1054-ed4f-4f12-86bc-e6854210912e",
   "metadata": {},
   "source": [
    "The 2-hour time difference occurs at 03:00:00 on the dates 2022-03-27 and 2023-03-26, corresponding to the transition to daylight saving time. This transition results in missing records for the previous hour.\n",
    "\n",
    "Nevertheless, despite these missing values, the data remains consistent on a daily basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bc218b-d518-43cc-b1d8-67d6d488a0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any forecast dates are not exactly one day after origin dates\n",
    "(\n",
    "    electricity_prices_df[\"electricity_origin_datetime\"]\n",
    "    + pd.Timedelta(days=1)\n",
    "    != electricity_prices_df[\"electricity_forecast_datetime\"]\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc31320-e82b-42d5-91b7-6ac58f1577b8",
   "metadata": {},
   "source": [
    "- All `electricity_origin_datetime` values represent the day before their corresponding `electricity_forecast_datetime` values.\n",
    "- The raw data in this DataFrame is sorted chronologically by datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb2a93f-cf52-4dc4-90e5-55708e3a2fb4",
   "metadata": {},
   "source": [
    "#### Origin date and data_block_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69292ea4-4a96-46fd-8999-ed02f8c71fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date differences: <TimedeltaArray>\n",
      "[NaT, '0 days', '1 days']\n",
      "Length: 3, dtype: timedelta64[ns]\n",
      "Data block ID differences: [nan  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Create variables to store the differences between the current and\n",
    "# previous row for all rows in electricity_origin_datetime and data_block_id\n",
    "electricity_date_diff = electricity_prices_df[\n",
    "    \"electricity_origin_datetime\"\n",
    "].dt.date.diff()\n",
    "electricity_id_diff = electricity_prices_df[\"data_block_id\"].diff()\n",
    "\n",
    "# Print unique values to verify that default order reflects sorting\n",
    "# from oldest to newest without skips\n",
    "print(\"Date differences:\", electricity_date_diff.unique())\n",
    "print(\"Data block ID differences:\", electricity_id_diff.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb14b95-b710-4962-98d8-878d75db61e0",
   "metadata": {},
   "source": [
    "- `NaT` and `NaN` values correspond to the first row in both columns, where no previous row data is available for comparison.\n",
    "- A value of '0' indicates that the current and previous rows belong to the same day.\n",
    "- A value of '1' indicates the transition from one day to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d1f66-64df-4c89-a7d4-1df37ddae839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference nan: no mismatches.\n",
      "Difference 0.0: no mismatches.\n",
      "Difference 1.0: no mismatches.\n"
     ]
    }
   ],
   "source": [
    "for difference in electricity_id_diff.unique():\n",
    "    mismatched_indices_check(\n",
    "        electricity_date_diff, electricity_id_diff, difference\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85706d86-e8f5-40f4-8bab-49a96ad3aa28",
   "metadata": {},
   "source": [
    "- The default order of the raw data for this DataFrame is sorted by datetime, and the `data_block_id` reflects the actual data availability, with no errors observed in the `electricity_origin_datetime` column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8737f2cc-ed66-4ca8-9f32-695a1f30a724",
   "metadata": {},
   "source": [
    "## forecast_weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e027ae6-fc3e-42e4-89e9-78a947cfc32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< HEAD >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>origin_datetime</th>\n",
       "      <th>hours_ahead</th>\n",
       "      <th>temperature</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>cloudcover_high</th>\n",
       "      <th>cloudcover_low</th>\n",
       "      <th>cloudcover_mid</th>\n",
       "      <th>cloudcover_total</th>\n",
       "      <th>10_metre_u_wind_component</th>\n",
       "      <th>10_metre_v_wind_component</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>forecast_datetime</th>\n",
       "      <th>direct_solar_radiation</th>\n",
       "      <th>surface_solar_radiation_downwards</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>total_precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.60</td>\n",
       "      <td>21.70</td>\n",
       "      <td>2021-09-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>15.66</td>\n",
       "      <td>11.55</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01 03:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.60</td>\n",
       "      <td>22.20</td>\n",
       "      <td>2021-09-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>13.00</td>\n",
       "      <td>10.69</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4.46e-03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01 03:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.60</td>\n",
       "      <td>22.70</td>\n",
       "      <td>2021-09-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>14.21</td>\n",
       "      <td>11.67</td>\n",
       "      <td>0.73</td>\n",
       "      <td>5.62e-03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.45</td>\n",
       "      <td>-7.42</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01 03:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57.60</td>\n",
       "      <td>23.20</td>\n",
       "      <td>2021-09-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>14.84</td>\n",
       "      <td>12.26</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.07</td>\n",
       "      <td>6.26e-04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.09</td>\n",
       "      <td>-9.16</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01 03:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.60</td>\n",
       "      <td>23.70</td>\n",
       "      <td>2021-09-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>15.29</td>\n",
       "      <td>12.46</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.53e-05</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.27</td>\n",
       "      <td>-8.98</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01 03:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude      origin_datetime  hours_ahead  temperature  \\\n",
       "0     57.60      21.70  2021-09-01 02:00:00            1        15.66   \n",
       "1     57.60      22.20  2021-09-01 02:00:00            1        13.00   \n",
       "2     57.60      22.70  2021-09-01 02:00:00            1        14.21   \n",
       "3     57.60      23.20  2021-09-01 02:00:00            1        14.84   \n",
       "4     57.60      23.70  2021-09-01 02:00:00            1        15.29   \n",
       "\n",
       "   dewpoint  cloudcover_high  cloudcover_low  cloudcover_mid  \\\n",
       "0     11.55             0.90            0.02            0.00   \n",
       "1     10.69             0.89        4.46e-03            0.00   \n",
       "2     11.67             0.73        5.62e-03            0.00   \n",
       "3     12.26             0.34            0.07        6.26e-04   \n",
       "4     12.46             0.10            0.09        1.53e-05   \n",
       "\n",
       "   cloudcover_total  10_metre_u_wind_component  10_metre_v_wind_component  \\\n",
       "0              0.91                      -0.41                      -9.11   \n",
       "1              0.89                       0.21                      -5.36   \n",
       "2              0.73                       1.45                      -7.42   \n",
       "3              0.39                       1.09                      -9.16   \n",
       "4              0.18                       1.27                      -8.98   \n",
       "\n",
       "   data_block_id    forecast_datetime  direct_solar_radiation  \\\n",
       "0              1  2021-09-01 03:00:00                    0.00   \n",
       "1              1  2021-09-01 03:00:00                    0.00   \n",
       "2              1  2021-09-01 03:00:00                    0.00   \n",
       "3              1  2021-09-01 03:00:00                    0.00   \n",
       "4              1  2021-09-01 03:00:00                    0.00   \n",
       "\n",
       "   surface_solar_radiation_downwards  snowfall  total_precipitation  \n",
       "0                               0.00      0.00                 0.00  \n",
       "1                               0.00      0.00                 0.00  \n",
       "2                               0.00      0.00                 0.00  \n",
       "3                               0.00      0.00                 0.00  \n",
       "4                               0.00      0.00                 0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< INFO >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3424512 entries, 0 to 3424511\n",
      "Data columns (total 18 columns):\n",
      " #   Column                             Non-Null Count    Dtype  \n",
      "---  ------                             --------------    -----  \n",
      " 0   latitude                           3424512 non-null  float64\n",
      " 1   longitude                          3424512 non-null  float64\n",
      " 2   origin_datetime                    3424512 non-null  object \n",
      " 3   hours_ahead                        3424512 non-null  int64  \n",
      " 4   temperature                        3424512 non-null  float64\n",
      " 5   dewpoint                           3424512 non-null  float64\n",
      " 6   cloudcover_high                    3424512 non-null  float64\n",
      " 7   cloudcover_low                     3424512 non-null  float64\n",
      " 8   cloudcover_mid                     3424512 non-null  float64\n",
      " 9   cloudcover_total                   3424512 non-null  float64\n",
      " 10  10_metre_u_wind_component          3424512 non-null  float64\n",
      " 11  10_metre_v_wind_component          3424512 non-null  float64\n",
      " 12  data_block_id                      3424512 non-null  int64  \n",
      " 13  forecast_datetime                  3424512 non-null  object \n",
      " 14  direct_solar_radiation             3424512 non-null  float64\n",
      " 15  surface_solar_radiation_downwards  3424510 non-null  float64\n",
      " 16  snowfall                           3424512 non-null  float64\n",
      " 17  total_precipitation                3424512 non-null  float64\n",
      "dtypes: float64(14), int64(2), object(2)\n",
      "memory usage: 470.3+ MB\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< DESCRIBE >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>origin_datetime</th>\n",
       "      <th>hours_ahead</th>\n",
       "      <th>temperature</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>cloudcover_high</th>\n",
       "      <th>cloudcover_low</th>\n",
       "      <th>cloudcover_mid</th>\n",
       "      <th>cloudcover_total</th>\n",
       "      <th>10_metre_u_wind_component</th>\n",
       "      <th>10_metre_v_wind_component</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>forecast_datetime</th>\n",
       "      <th>direct_solar_radiation</th>\n",
       "      <th>surface_solar_radiation_downwards</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>total_precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3424512.00</td>\n",
       "      <td>3424512.00</td>\n",
       "      <td>3424512</td>\n",
       "      <td>3424512.00</td>\n",
       "      <td>3424512.00</td>\n",
       "      <td>3424512.00</td>\n",
       "      <td>3424512.00</td>\n",
       "      <td>3424512.00</td>\n",
       "      <td>3424512.00</td>\n",
       "      <td>3424512.00</td>\n",
       "      <td>3424512.00</td>\n",
       "      <td>3424512.00</td>\n",
       "      <td>3424512.00</td>\n",
       "      <td>3424512</td>\n",
       "      <td>3424512.00</td>\n",
       "      <td>3424510.00</td>\n",
       "      <td>3424512.00</td>\n",
       "      <td>3424512.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-01 02:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-10-30 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>58.65</td>\n",
       "      <td>24.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.50</td>\n",
       "      <td>5.74</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.73</td>\n",
       "      <td>319.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151.19</td>\n",
       "      <td>110.76</td>\n",
       "      <td>2.53e-05</td>\n",
       "      <td>7.86e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.69</td>\n",
       "      <td>2.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.85</td>\n",
       "      <td>7.84</td>\n",
       "      <td>7.12</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.22</td>\n",
       "      <td>183.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.51</td>\n",
       "      <td>187.44</td>\n",
       "      <td>1.22e-04</td>\n",
       "      <td>2.78e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>57.60</td>\n",
       "      <td>21.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-27.50</td>\n",
       "      <td>-29.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-17.58</td>\n",
       "      <td>-22.12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-3.81e-06</td>\n",
       "      <td>-1.53e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>58.12</td>\n",
       "      <td>23.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.75</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.36e-04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>-1.98</td>\n",
       "      <td>160.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>58.65</td>\n",
       "      <td>24.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.50</td>\n",
       "      <td>4.87</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.94</td>\n",
       "      <td>319.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>59.17</td>\n",
       "      <td>26.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.25</td>\n",
       "      <td>11.15</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.51</td>\n",
       "      <td>478.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>212.84</td>\n",
       "      <td>144.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.77e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.70</td>\n",
       "      <td>28.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.00</td>\n",
       "      <td>31.81</td>\n",
       "      <td>23.68</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>22.57</td>\n",
       "      <td>19.31</td>\n",
       "      <td>637.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>954.42</td>\n",
       "      <td>848.71</td>\n",
       "      <td>4.83e-03</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         latitude  longitude      origin_datetime  hours_ahead  temperature  \\\n",
       "count  3424512.00 3424512.00              3424512   3424512.00   3424512.00   \n",
       "unique        NaN        NaN                  637          NaN          NaN   \n",
       "top           NaN        NaN  2021-09-01 02:00:00          NaN          NaN   \n",
       "freq          NaN        NaN                 5376          NaN          NaN   \n",
       "mean        58.65      24.95                  NaN        24.50         5.74   \n",
       "std          0.69       2.02                  NaN        13.85         7.84   \n",
       "min         57.60      21.70                  NaN         1.00       -27.50   \n",
       "25%         58.12      23.20                  NaN        12.75         0.26   \n",
       "50%         58.65      24.95                  NaN        24.50         4.87   \n",
       "75%         59.17      26.70                  NaN        36.25        11.15   \n",
       "max         59.70      28.20                  NaN        48.00        31.81   \n",
       "\n",
       "         dewpoint  cloudcover_high  cloudcover_low  cloudcover_mid  \\\n",
       "count  3424512.00       3424512.00      3424512.00      3424512.00   \n",
       "unique        NaN              NaN             NaN             NaN   \n",
       "top           NaN              NaN             NaN             NaN   \n",
       "freq          NaN              NaN             NaN             NaN   \n",
       "mean         2.41             0.39            0.43            0.36   \n",
       "std          7.12             0.44            0.44            0.42   \n",
       "min        -29.68             0.00            0.00            0.00   \n",
       "25%         -2.36             0.00        3.36e-04            0.00   \n",
       "50%          1.84             0.09            0.23            0.10   \n",
       "75%          7.30             0.98            1.00            0.90   \n",
       "max         23.68             1.00            1.00            1.00   \n",
       "\n",
       "        cloudcover_total  10_metre_u_wind_component  \\\n",
       "count         3424512.00                 3424512.00   \n",
       "unique               NaN                        NaN   \n",
       "top                  NaN                        NaN   \n",
       "freq                 NaN                        NaN   \n",
       "mean                0.68                       1.26   \n",
       "std                 0.40                       4.00   \n",
       "min                 0.00                     -17.58   \n",
       "25%                 0.26                      -1.47   \n",
       "50%                 0.98                       1.47   \n",
       "75%                 1.00                       3.81   \n",
       "max                 1.00                      22.57   \n",
       "\n",
       "        10_metre_v_wind_component  data_block_id    forecast_datetime  \\\n",
       "count                  3424512.00     3424512.00              3424512   \n",
       "unique                        NaN            NaN                15310   \n",
       "top                           NaN            NaN  2022-10-30 03:00:00   \n",
       "freq                          NaN            NaN                  448   \n",
       "mean                         0.73         319.00                  NaN   \n",
       "std                          4.22         183.89                  NaN   \n",
       "min                        -22.12           1.00                  NaN   \n",
       "25%                         -1.98         160.00                  NaN   \n",
       "50%                          0.94         319.00                  NaN   \n",
       "75%                          3.51         478.00                  NaN   \n",
       "max                         19.31         637.00                  NaN   \n",
       "\n",
       "        direct_solar_radiation  surface_solar_radiation_downwards   snowfall  \\\n",
       "count               3424512.00                         3424510.00 3424512.00   \n",
       "unique                     NaN                                NaN        NaN   \n",
       "top                        NaN                                NaN        NaN   \n",
       "freq                       NaN                                NaN        NaN   \n",
       "mean                    151.19                             110.76   2.53e-05   \n",
       "std                     256.51                             187.44   1.22e-04   \n",
       "min                      -0.77                              -0.33  -3.81e-06   \n",
       "25%                       0.00                               0.00       0.00   \n",
       "50%                       0.00                               0.60       0.00   \n",
       "75%                     212.84                             144.17       0.00   \n",
       "max                     954.42                             848.71   4.83e-03   \n",
       "\n",
       "        total_precipitation  \n",
       "count            3424512.00  \n",
       "unique                  NaN  \n",
       "top                     NaN  \n",
       "freq                    NaN  \n",
       "mean               7.86e-05  \n",
       "std                2.78e-04  \n",
       "min               -1.53e-05  \n",
       "25%                    0.00  \n",
       "50%                    0.00  \n",
       "75%                2.77e-05  \n",
       "max                    0.02  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< MISSING VALUES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "surface_solar_radiation_downwards    2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< DUPLICATES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No duplicate rows\n"
     ]
    }
   ],
   "source": [
    "df_show_info(forecast_weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b630472b-23a3-447a-8d9b-7c40cf51c0ac",
   "metadata": {},
   "source": [
    "- There are 2 missing values and zero duplicates in the DataFrame. Only the `surface_solar_radiation_downwards` column contains missing values. \n",
    "- The `data_block_id` values start from 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9226e72c-48a3-4c88-a410-88f95cc16e87",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a797a5f-906c-4997-88c7-cad3da413f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>origin_datetime</th>\n",
       "      <th>hours_ahead</th>\n",
       "      <th>temperature</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>cloudcover_high</th>\n",
       "      <th>cloudcover_low</th>\n",
       "      <th>cloudcover_mid</th>\n",
       "      <th>cloudcover_total</th>\n",
       "      <th>10_metre_u_wind_component</th>\n",
       "      <th>10_metre_v_wind_component</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>forecast_datetime</th>\n",
       "      <th>direct_solar_radiation</th>\n",
       "      <th>surface_solar_radiation_downwards</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>total_precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239900</th>\n",
       "      <td>59.70</td>\n",
       "      <td>26.70</td>\n",
       "      <td>2021-10-15 02:00:00</td>\n",
       "      <td>30</td>\n",
       "      <td>6.80</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.88</td>\n",
       "      <td>4.43</td>\n",
       "      <td>45</td>\n",
       "      <td>2021-10-16 08:00:00</td>\n",
       "      <td>96.49</td>\n",
       "      <td>27.91</td>\n",
       "      <td>8.52e-05</td>\n",
       "      <td>9.33e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240605</th>\n",
       "      <td>58.20</td>\n",
       "      <td>22.20</td>\n",
       "      <td>2021-10-15 02:00:00</td>\n",
       "      <td>37</td>\n",
       "      <td>8.58</td>\n",
       "      <td>4.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8.08</td>\n",
       "      <td>1.09</td>\n",
       "      <td>45</td>\n",
       "      <td>2021-10-16 15:00:00</td>\n",
       "      <td>50.61</td>\n",
       "      <td>109.79</td>\n",
       "      <td>7.38e-07</td>\n",
       "      <td>4.70e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240636</th>\n",
       "      <td>58.80</td>\n",
       "      <td>23.70</td>\n",
       "      <td>2021-10-15 02:00:00</td>\n",
       "      <td>37</td>\n",
       "      <td>8.45</td>\n",
       "      <td>2.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>6.33</td>\n",
       "      <td>1.83</td>\n",
       "      <td>45</td>\n",
       "      <td>2021-10-16 15:00:00</td>\n",
       "      <td>210.04</td>\n",
       "      <td>138.86</td>\n",
       "      <td>3.87e-04</td>\n",
       "      <td>3.82e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240717</th>\n",
       "      <td>58.20</td>\n",
       "      <td>22.20</td>\n",
       "      <td>2021-10-15 02:00:00</td>\n",
       "      <td>38</td>\n",
       "      <td>9.07</td>\n",
       "      <td>5.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.68</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0.53</td>\n",
       "      <td>45</td>\n",
       "      <td>2021-10-16 16:00:00</td>\n",
       "      <td>240.38</td>\n",
       "      <td>113.18</td>\n",
       "      <td>-7.45e-09</td>\n",
       "      <td>5.77e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240765</th>\n",
       "      <td>59.10</td>\n",
       "      <td>25.20</td>\n",
       "      <td>2021-10-15 02:00:00</td>\n",
       "      <td>38</td>\n",
       "      <td>7.34</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.74</td>\n",
       "      <td>4.01</td>\n",
       "      <td>1.24</td>\n",
       "      <td>45</td>\n",
       "      <td>2021-10-16 16:00:00</td>\n",
       "      <td>207.74</td>\n",
       "      <td>94.55</td>\n",
       "      <td>9.78e-06</td>\n",
       "      <td>3.86e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294016</th>\n",
       "      <td>59.40</td>\n",
       "      <td>27.70</td>\n",
       "      <td>2023-05-06 02:00:00</td>\n",
       "      <td>35</td>\n",
       "      <td>6.58</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.62</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>613</td>\n",
       "      <td>2023-05-07 13:00:00</td>\n",
       "      <td>782.50</td>\n",
       "      <td>717.67</td>\n",
       "      <td>4.92e-07</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294017</th>\n",
       "      <td>59.40</td>\n",
       "      <td>28.20</td>\n",
       "      <td>2023-05-06 02:00:00</td>\n",
       "      <td>35</td>\n",
       "      <td>7.92</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.03</td>\n",
       "      <td>-1.98</td>\n",
       "      <td>613</td>\n",
       "      <td>2023-05-07 13:00:00</td>\n",
       "      <td>468.47</td>\n",
       "      <td>573.81</td>\n",
       "      <td>-3.58e-07</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294026</th>\n",
       "      <td>59.70</td>\n",
       "      <td>25.70</td>\n",
       "      <td>2023-05-06 02:00:00</td>\n",
       "      <td>35</td>\n",
       "      <td>3.55</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.14e-04</td>\n",
       "      <td>2.14e-04</td>\n",
       "      <td>3.71</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>613</td>\n",
       "      <td>2023-05-07 13:00:00</td>\n",
       "      <td>861.86</td>\n",
       "      <td>735.80</td>\n",
       "      <td>-4.62e-07</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294027</th>\n",
       "      <td>59.70</td>\n",
       "      <td>26.20</td>\n",
       "      <td>2023-05-06 02:00:00</td>\n",
       "      <td>35</td>\n",
       "      <td>3.73</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.19</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>613</td>\n",
       "      <td>2023-05-07 13:00:00</td>\n",
       "      <td>859.87</td>\n",
       "      <td>731.89</td>\n",
       "      <td>5.51e-07</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294031</th>\n",
       "      <td>59.70</td>\n",
       "      <td>28.20</td>\n",
       "      <td>2023-05-06 02:00:00</td>\n",
       "      <td>35</td>\n",
       "      <td>7.62</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.16</td>\n",
       "      <td>-2.05</td>\n",
       "      <td>613</td>\n",
       "      <td>2023-05-07 13:00:00</td>\n",
       "      <td>800.42</td>\n",
       "      <td>712.41</td>\n",
       "      <td>-5.07e-07</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>793673 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         latitude  longitude      origin_datetime  hours_ahead  temperature  \\\n",
       "239900      59.70      26.70  2021-10-15 02:00:00           30         6.80   \n",
       "240605      58.20      22.20  2021-10-15 02:00:00           37         8.58   \n",
       "240636      58.80      23.70  2021-10-15 02:00:00           37         8.45   \n",
       "240717      58.20      22.20  2021-10-15 02:00:00           38         9.07   \n",
       "240765      59.10      25.20  2021-10-15 02:00:00           38         7.34   \n",
       "...           ...        ...                  ...          ...          ...   \n",
       "3294016     59.40      27.70  2023-05-06 02:00:00           35         6.58   \n",
       "3294017     59.40      28.20  2023-05-06 02:00:00           35         7.92   \n",
       "3294026     59.70      25.70  2023-05-06 02:00:00           35         3.55   \n",
       "3294027     59.70      26.20  2023-05-06 02:00:00           35         3.73   \n",
       "3294031     59.70      28.20  2023-05-06 02:00:00           35         7.62   \n",
       "\n",
       "         dewpoint  cloudcover_high  cloudcover_low  cloudcover_mid  \\\n",
       "239900       3.21             0.00            0.46            0.56   \n",
       "240605       4.84             0.00            0.52            0.45   \n",
       "240636       2.29             0.00            0.43            0.78   \n",
       "240717       5.56             0.00            0.51            0.33   \n",
       "240765       1.13             0.00            0.14            0.71   \n",
       "...           ...              ...             ...             ...   \n",
       "3294016     -1.04             0.00            0.00            0.01   \n",
       "3294017     -2.04             0.00            0.09            0.27   \n",
       "3294026      0.39             0.00            0.00        2.14e-04   \n",
       "3294027     -0.31             0.00            0.00            0.00   \n",
       "3294031     -0.13             0.00            0.00            0.01   \n",
       "\n",
       "         cloudcover_total  10_metre_u_wind_component  \\\n",
       "239900               0.75                      11.88   \n",
       "240605               0.64                       8.08   \n",
       "240636               0.79                       6.33   \n",
       "240717               0.68                       8.60   \n",
       "240765               0.74                       4.01   \n",
       "...                   ...                        ...   \n",
       "3294016              0.01                       2.62   \n",
       "3294017              0.28                       3.03   \n",
       "3294026          2.14e-04                       3.71   \n",
       "3294027              0.00                       5.19   \n",
       "3294031              0.01                       3.16   \n",
       "\n",
       "         10_metre_v_wind_component  data_block_id    forecast_datetime  \\\n",
       "239900                        4.43             45  2021-10-16 08:00:00   \n",
       "240605                        1.09             45  2021-10-16 15:00:00   \n",
       "240636                        1.83             45  2021-10-16 15:00:00   \n",
       "240717                        0.53             45  2021-10-16 16:00:00   \n",
       "240765                        1.24             45  2021-10-16 16:00:00   \n",
       "...                            ...            ...                  ...   \n",
       "3294016                      -3.73            613  2023-05-07 13:00:00   \n",
       "3294017                      -1.98            613  2023-05-07 13:00:00   \n",
       "3294026                      -1.50            613  2023-05-07 13:00:00   \n",
       "3294027                      -2.33            613  2023-05-07 13:00:00   \n",
       "3294031                      -2.05            613  2023-05-07 13:00:00   \n",
       "\n",
       "         direct_solar_radiation  surface_solar_radiation_downwards  snowfall  \\\n",
       "239900                    96.49                              27.91  8.52e-05   \n",
       "240605                    50.61                             109.79  7.38e-07   \n",
       "240636                   210.04                             138.86  3.87e-04   \n",
       "240717                   240.38                             113.18 -7.45e-09   \n",
       "240765                   207.74                              94.55  9.78e-06   \n",
       "...                         ...                                ...       ...   \n",
       "3294016                  782.50                             717.67  4.92e-07   \n",
       "3294017                  468.47                             573.81 -3.58e-07   \n",
       "3294026                  861.86                             735.80 -4.62e-07   \n",
       "3294027                  859.87                             731.89  5.51e-07   \n",
       "3294031                  800.42                             712.41 -5.07e-07   \n",
       "\n",
       "         total_precipitation  \n",
       "239900              9.33e-04  \n",
       "240605              4.70e-04  \n",
       "240636              3.82e-03  \n",
       "240717              5.77e-04  \n",
       "240765              3.86e-04  \n",
       "...                      ...  \n",
       "3294016                 0.00  \n",
       "3294017                 0.00  \n",
       "3294026                 0.00  \n",
       "3294027                 0.00  \n",
       "3294031                 0.00  \n",
       "\n",
       "[793673 rows x 18 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_weather_df[forecast_weather_df.snowfall != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4184db55-84c3-403b-971e-5815b7f7627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data types to reduce memory usage\n",
    "forecast_weather_df[[\"latitude\", \"longitude\"]] = forecast_weather_df[\n",
    "    [\"latitude\", \"longitude\"]\n",
    "].mul(10)\n",
    "forecast_weather_df = forecast_weather_df.astype(\n",
    "    {\n",
    "        \"latitude\": \"uint16\",\n",
    "        \"longitude\": \"uint16\",\n",
    "        \"origin_datetime\": \"datetime64[ns]\",\n",
    "        \"temperature\": \"float32\",\n",
    "        \"dewpoint\": \"float32\",\n",
    "        \"cloudcover_high\": \"float32\",\n",
    "        \"cloudcover_low\": \"float32\",\n",
    "        \"cloudcover_mid\": \"float32\",\n",
    "        \"cloudcover_total\": \"float32\",\n",
    "        \"10_metre_u_wind_component\": \"float32\",\n",
    "        \"10_metre_v_wind_component\": \"float32\",\n",
    "        \"data_block_id\": \"uint16\",\n",
    "        \"forecast_datetime\": \"datetime64[ns]\",\n",
    "        \"direct_solar_radiation\": \"float32\",\n",
    "        \"surface_solar_radiation_downwards\": \"float32\",\n",
    "        \"snowfall\": \"float32\",\n",
    "        \"total_precipitation\": \"float32\",\n",
    "    }\n",
    ")\n",
    "\n",
    "forecast_weather_df[\"hours_ahead\"] = pd.to_timedelta(\n",
    "    forecast_weather_df[\"hours_ahead\"], \"h\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3cf0b7-9b50-47d3-9a4e-ef0874058921",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52033f48-4a41-4348-818b-5c4746715f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>origin_datetime</th>\n",
       "      <th>hours_ahead</th>\n",
       "      <th>temperature</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>cloudcover_high</th>\n",
       "      <th>cloudcover_low</th>\n",
       "      <th>cloudcover_mid</th>\n",
       "      <th>cloudcover_total</th>\n",
       "      <th>10_metre_u_wind_component</th>\n",
       "      <th>10_metre_v_wind_component</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>forecast_datetime</th>\n",
       "      <th>direct_solar_radiation</th>\n",
       "      <th>surface_solar_radiation_downwards</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>total_precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1849670</th>\n",
       "      <td>597</td>\n",
       "      <td>237</td>\n",
       "      <td>2022-08-11 02:00:00</td>\n",
       "      <td>0 days 03:00:00</td>\n",
       "      <td>19.04</td>\n",
       "      <td>16.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>5.91</td>\n",
       "      <td>7.62</td>\n",
       "      <td>345</td>\n",
       "      <td>2022-08-11 05:00:00</td>\n",
       "      <td>17.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849782</th>\n",
       "      <td>597</td>\n",
       "      <td>237</td>\n",
       "      <td>2022-08-11 02:00:00</td>\n",
       "      <td>0 days 04:00:00</td>\n",
       "      <td>18.80</td>\n",
       "      <td>16.99</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5.42</td>\n",
       "      <td>8.10</td>\n",
       "      <td>345</td>\n",
       "      <td>2022-08-11 06:00:00</td>\n",
       "      <td>206.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         latitude  longitude     origin_datetime     hours_ahead  temperature  \\\n",
       "1849670       597        237 2022-08-11 02:00:00 0 days 03:00:00        19.04   \n",
       "1849782       597        237 2022-08-11 02:00:00 0 days 04:00:00        18.80   \n",
       "\n",
       "         dewpoint  cloudcover_high  cloudcover_low  cloudcover_mid  \\\n",
       "1849670     16.85             0.91            0.00            0.00   \n",
       "1849782     16.99             0.84            0.00            0.00   \n",
       "\n",
       "         cloudcover_total  10_metre_u_wind_component  \\\n",
       "1849670              0.91                       5.91   \n",
       "1849782              0.84                       5.42   \n",
       "\n",
       "         10_metre_v_wind_component  data_block_id   forecast_datetime  \\\n",
       "1849670                       7.62            345 2022-08-11 05:00:00   \n",
       "1849782                       8.10            345 2022-08-11 06:00:00   \n",
       "\n",
       "         direct_solar_radiation  surface_solar_radiation_downwards  snowfall  \\\n",
       "1849670                   17.10                                NaN      0.00   \n",
       "1849782                  206.41                                NaN      0.00   \n",
       "\n",
       "         total_precipitation  \n",
       "1849670                 0.00  \n",
       "1849782                 0.00  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_weather_df[forecast_weather_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04cc04f-32d7-4bc6-85a3-33f9e8d8b0f0",
   "metadata": {},
   "source": [
    "- Since there are only two missing values, it could be due to a local issue lasting for just 2 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf762ee-0c72-49b7-8654-56a1fa94b1b5",
   "metadata": {},
   "source": [
    "### Consistency and Relationship Validation\n",
    "Ensure `origin_datetime`, `forecast_datetime`, `hours_ahead` values are coherent within respective `latitude` and `longitude` groups.\n",
    "#### Origin datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c47428-ac46-46d4-a323-59bca3929c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origin_datetime\n",
       "True     111\n",
       "False      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sameness check\n",
    "forecast_geo_gb = forecast_weather_df.groupby([\"latitude\", \"longitude\"])\n",
    "same_groups(forecast_geo_gb, \"origin_datetime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4921cbdd-020a-4d7c-84f7-326b7bce5151",
   "metadata": {},
   "source": [
    "This DataFrame contains 112 unique combinations of `latitude` and `longitude`, representing distinct geographical points for weather forecasts. Only one `False` value corresponds to the first group, indicating that all other location points have identical subsequences of `origin_datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f6ff0f-a89d-40e1-b523-ad6c1dd245e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origin_datetime\n",
       "02:00:00    1843968\n",
       "01:00:00    1580544\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forecast creation times\n",
    "forecast_weather_df[\"origin_datetime\"].dt.time.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03160b7-3f66-48fa-bfed-89a964df3799",
   "metadata": {},
   "source": [
    "All forecasts are made at either 1 AM or 2 AM, likely due to shifts associated with transitions to and from daylight saving time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffc3f13-51cb-492a-8849-c2201f376e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origin_datetime\n",
       "0 days 00:00:00    29939\n",
       "1 days 00:00:00      632\n",
       "0 days 23:00:00        2\n",
       "1 days 01:00:00        2\n",
       "NaT                    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select latitude and longitude values for the first entry of the\n",
    "# geographical group, as the sequences of origin_datetime values are\n",
    "# identical across each group\n",
    "lat0, lon0 = forecast_weather_df.iloc[0][[\"latitude\", \"longitude\"]]\n",
    "fw_subset_df = forecast_weather_df[\n",
    "    (forecast_weather_df[\"latitude\"] == lat0)\n",
    "    & (forecast_weather_df[\"longitude\"] == lon0)\n",
    "]\n",
    "\n",
    "# Calculate the differences between consecutive origin_datetime values\n",
    "# for the selected geographical group\n",
    "fod_diff = fw_subset_df[\"origin_datetime\"].diff()\n",
    "\n",
    "# Display the counts of unique differences between consecutive\n",
    "# origin_datetime entries\n",
    "fod_diff.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7174e10f-fff4-4200-a8c9-8bddc46c2903",
   "metadata": {},
   "source": [
    "- `0 days 00:00:00`: rows corresponding to the same location and day, but with different `hours_ahead` values.\n",
    "- `1 days 00:00:00`: indicates a shift from previous origin day.\n",
    "- `0 days 23:00:00`: likely caused by a transition to daylight saving time.\n",
    "- `1 days 01:00:00`: likely caused by a transition from daylight saving time.\n",
    "- `NaT`: corresponds to the first rows in each group.\n",
    "\n",
    "Based on these differences, it can be concluded that the data in this DataFrame is sorted by `origin_datetime` by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce26318f-f8c2-40d1-a079-a03563369bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_datetime</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>327936</th>\n",
       "      <td>2021-11-01 01:00:00</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118208</th>\n",
       "      <td>2022-03-28 02:00:00</td>\n",
       "      <td>1 days 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284800</th>\n",
       "      <td>2022-10-31 01:00:00</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075072</th>\n",
       "      <td>2023-03-27 02:00:00</td>\n",
       "      <td>1 days 01:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            origin_datetime      difference\n",
       "327936  2021-11-01 01:00:00 0 days 23:00:00\n",
       "1118208 2022-03-28 02:00:00 1 days 01:00:00\n",
       "2284800 2022-10-31 01:00:00 0 days 23:00:00\n",
       "3075072 2023-03-27 02:00:00 1 days 01:00:00"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select rows where differences in origin_datetime are not 0, 1 day, or\n",
    "# NaT\n",
    "unusual_diff_df = fw_subset_df[\n",
    "    (fod_diff != pd.Timedelta(0))\n",
    "    & (fod_diff != pd.Timedelta(1, \"d\"))\n",
    "    & (~fod_diff.isna())\n",
    "][[\"origin_datetime\"]]\n",
    "\n",
    "# Merge the filtered timestamps with their corresponding time\n",
    "# differences\n",
    "pd.merge(\n",
    "    unusual_diff_df,\n",
    "    fod_diff[unusual_diff_df.index].rename(\"difference\"),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab673bc-b932-42a0-94fd-0fa67c760103",
   "metadata": {},
   "source": [
    "Yes, the autumn shift corresponds to a switch to winter time, and the spring shift corresponds to a switch to summer time. Specifically:\n",
    "- The `origin_datetime` hour is `02:00:00` during the following periods:\n",
    "  - From `2021-09-01` to `2021-10-31`\n",
    "  - From `2022-03-28` to `2022-10-30`\n",
    "  - From `2023-03-27` to `2023-05-30`\n",
    "- The `origin_datetime` hour is `01:00:00` during the following periods:\n",
    "  - From `2021-11-01` to `2022-03-27`\n",
    "  - From `2022-10-31` to `2023-03-26`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ac02d1-b632-4aee-93fa-b7901f38b1a8",
   "metadata": {},
   "source": [
    "#### Forecast datetime\n",
    "From the data description:\n",
    "- `forecast_datetime` - The timestamp of the predicted weather. Generated from `origin_datetime` plus `hours_ahead`. This represents the start of the 1-hour period for which weather data are forecasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d493e884-f1d9-4d25-8339-a7c0083481dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forecast_datetime\n",
      "True     111\n",
      "False      1\n",
      "Name: count, dtype: int64\n",
      "hours_ahead\n",
      "True     111\n",
      "False      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sameness check for other two datetime features\n",
    "for column in (\"forecast_datetime\", \"hours_ahead\"):\n",
    "    print(same_groups(forecast_geo_gb, column))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d59d05-ab69-442d-b4b4-57c770afea97",
   "metadata": {},
   "source": [
    "As with `origin_datetime`, for each geographical group, the sequence of `forecast_datetime` or `hours_ahead` values is identical across the locations. Therefore, it is sufficient to check the `forecast_datetime` and `hours_ahead` features using data from just one location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c40908-f95a-40b3-b80c-3d0871c47474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2021-10-30 02:00:00', '2021-10-31 02:00:00', '2022-03-26 01:00:00',\n",
       " '2022-03-27 01:00:00', '2022-10-29 02:00:00', '2022-10-30 02:00:00',\n",
       " '2023-03-25 01:00:00', '2023-03-26 01:00:00']\n",
       "Length: 8, dtype: datetime64[ns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the equality stated in the dataset description:\n",
    "# origin_datetime + hours_ahead = forecast_datetime\n",
    "unusual_sum_df = fw_subset_df[\n",
    "    fw_subset_df[\"origin_datetime\"]\n",
    "    + fw_subset_df[\"hours_ahead\"]\n",
    "    != fw_subset_df[\"forecast_datetime\"]\n",
    "]\n",
    "unusual_sum_df[\"origin_datetime\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd542c-df3c-4424-b708-ae846d2cb828",
   "metadata": {},
   "source": [
    "Values that do not satisfy the condition occur only within the 48 hours preceding a switch to or from DST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0b25e-d1cd-4a7f-bc28-9d2a95dcdf7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that entries not satisfying the condition will satisfy it after\n",
    "# adding or subtracting respectively.\n",
    "# For autumn,\n",
    "# origin_datetime + hours_ahead == forecast_datetime + 1 hour.\n",
    "# For spring,\n",
    "# origin_datetime + hours_ahead == forecast_datetime - 1 hour.\n",
    "\n",
    "(unusual_sum_df[\"origin_datetime\"]\n",
    " + unusual_sum_df[\"hours_ahead\"]\n",
    " != unusual_sum_df[\"forecast_datetime\"]\n",
    " + pd.to_timedelta(np.where(\n",
    "     unusual_sum_df[\"origin_datetime\"].dt.month == 10,  # October\n",
    "     1,  # Add 1 hour for autumn switch to DST (October)\n",
    "     -1  # Subtract 1 hour for spring switch from DST (March)\n",
    " ), 'h')\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7836cb2-1896-457d-b85a-500b054791fa",
   "metadata": {},
   "source": [
    "All conditions are satisfied after corresponding addition or subtraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc74b68-571d-49bd-b6a5-5a2d748b8904",
   "metadata": {},
   "source": [
    "#### data_block_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92af9350-9faf-43a3-8ac3-338aaae7f13f",
   "metadata": {},
   "source": [
    "## historical_weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9920a6bd-e99c-4fe1-97d7-62b6c0e66975",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_show_info(historical_weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7de862-eb2e-4746-bd1e-3c4d6957f12d",
   "metadata": {},
   "source": [
    "- The `data_block_id` column type is `float64`, unlike in other DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b3b870-e0ed-4ee2-8879-265009971f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if all values in data_block_id are \n",
    "# integers to avoid errors and allow conversion to int type\n",
    "\n",
    "print(np.unique(historical_weather_df.data_block_id.unique() %1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14a2630-f93e-4df8-8c0a-5bcfe7b072f3",
   "metadata": {},
   "source": [
    "- No anomalous values; all have a remainder of 0 and can be converted to `uint16` type (which can store values from 0 to 65535), as the minimum value is 1 and the maximum is 637."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661bf2db-f164-49f7-996a-ca11fa3ddda0",
   "metadata": {},
   "source": [
    "- There are no missing values or duplicates in the DataFrame.\n",
    "- The `data_block_id` is `float64` because the data in the original file is in \"n.0\" format.\n",
    "- The `data_block_id` values start from 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f1a11-c115-44ad-b10c-b768d0ed4c28",
   "metadata": {},
   "source": [
    "## station_county_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6becd8-afd3-49a2-9368-12a035466c7c",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33e36aea-5480-4177-8e70-bc4f71941c19",
   "metadata": {},
   "source": [
    "- `Datetime` can be unpacked into multiple time-based features.\n",
    "- `[latitude/longitude]` features represent the coordinates of the weather forecast and the weather station, which may require comparison for alignment or validation.\n",
    "- Features that appear in multiple DataFrames can have different values, dtypes, and meanings (for example, `cloudcover_[low/mid/high/total]` in `forecast_weather_df` and `historical_weather_df`). It is worth renaming such features to make their differences more explicit.\n",
    "- At first glance, the features `data_block_id`, `datetime`, and `row_id` appear to be correlated. Similarly, `prediction_unit_id` appears to correlate with `county`, `is_business`, and `product_type`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11184b72-39c8-4d78-9a17-c24c17759bd5",
   "metadata": {},
   "source": [
    "## Decoding and Data Type Conversion\n",
    "### Mapping Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8950f-0029-4a1b-b258-70055e9662ac",
   "metadata": {},
   "source": [
    "Nominal categorical features exist only in the train_df, client_df DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b5ba3d-7d7f-419a-8e1f-daa61307f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming categorical columns to improve readability\n",
    "values_mapper = {\n",
    "    \"county\": county_id_to_name_map,\n",
    "    \"is_business\": {0: \"not_business\", 1: \"business\"},\n",
    "    \"is_consumption\": {0: \"production\", 1: \"consumption\"},\n",
    "    \"product_type\": {\n",
    "        0: \"combined\",\n",
    "        1: \"fixed\",\n",
    "        2: \"general_service\",\n",
    "        3: \"spot\",\n",
    "    },\n",
    "}\n",
    "\n",
    "decoding_categorical_list = [train_df, client_df]\n",
    "\n",
    "# Iterate over DataFrames with an index for tracking\n",
    "for df_index, df in enumerate(decoding_categorical_list):\n",
    "    for column, mapping in values_mapper.items():\n",
    "        if column in df.columns:\n",
    "            # Check for unexpected values\n",
    "            unexpected_values = set(df[column].unique()) - set(mapping.keys())\n",
    "            if unexpected_values:\n",
    "                print(\n",
    "                    f\"\\\n",
    "Unexpected values in DataFrame {df_index}, column '{column}':\\\n",
    "{unexpected_values}\"\n",
    "                )\n",
    "            else:\n",
    "                # Apply mapping and convert to categorical type\n",
    "                df[column] = df[column].map(mapping).astype(\"category\")\n",
    "    display(df.dtypes)\n",
    "    display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910554b4-9983-4429-aa82-9342e00ab2de",
   "metadata": {},
   "source": [
    "### Datetime Conversion and Reducing Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf70a1-3bd1-4adc-999d-689400c3f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame with the dtypes of all features as strings for simplicity\n",
    "features_dtypes_df = (\n",
    "    pd.concat([pd.DataFrame(df.dtypes).T for df in DF_LIST])\n",
    "    .astype(\"str\")\n",
    "    .set_index(pd.Index(NAMES_LIST))\n",
    ")\n",
    "\n",
    "# Show all features\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(features_dtypes_df)\n",
    "pd.reset_option(\"display.max_columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c195d6-659a-4d7d-b07f-1706d24d7a9e",
   "metadata": {},
   "source": [
    "- Only datetime-like features have object `dtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f5ce63-1954-4aeb-8ffc-bc58242bf0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dtypes_df[features_dtypes_df == 'object'].dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62288c9c-1602-4391-8ebe-b93510632c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming datetime-like features\n",
    "train_df = train_df.rename(columns={\"datetime\": \"target_datetime\"})\n",
    "gas_prices_df = gas_prices_df.rename(\n",
    "    columns={\n",
    "        \"forecast_date\": \"gas_forecast_date\",\n",
    "        \"origin_date\": \"gas_origin_date\",\n",
    "    }\n",
    ")\n",
    "client_df = client_df.rename(columns={\"date\": \"client_date\"})\n",
    "electricity_prices_df = electricity_prices_df.rename(\n",
    "    columns={\n",
    "        \"forecast_date\": \"electricity_forecast_datetime\",\n",
    "        \"origin_date\": \"electricity_origin_date\",\n",
    "    }\n",
    ")\n",
    "forecast_weather_df = forecast_weather_df.rename(\n",
    "    columns={\n",
    "        \"origin_datetime\": \"weather_origin_datetime\",\n",
    "        \"hours_ahead\": \"weather_hours_ahead\",\n",
    "        \"forecast_datetime\": \"weather_forecast_datetime\",\n",
    "    }\n",
    ")\n",
    "historical_weather_df = historical_weather_df.rename(columns={\"datetime\": \"historical_datetime\"})\n",
    "datetime - This represents the start of the 1-hour period for which weather data are measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9a72e9-99c5-4510-926a-47503c54cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_weather_df[['origin_datetime', 'hours_ahead', 'forecast_datetime']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035799f1-bace-401d-abd5-f0f3a6c283bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_weather_df.groupby('origin_datetime')['hours_ahead'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef4f61-f048-44ed-8d0b-59f135ae8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast_weather_df[['origin_datetime', 'hours_ahead', 'forecast_datetime']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98b37ab-270e-4d00-b34e-6ae6f6744103",
   "metadata": {},
   "source": [
    "forecast_weather_df\n",
    "- origin_datetime - The timestamp of when the forecast was generated.\n",
    "- hours_ahead - The number of hours between the forecast generation and the forecast weather. Each forecast covers 48 hours in total.\n",
    "- forecast_datetime - The timestamp of the predicted weather. Generated from origin_datetime plus hours_ahead. This represents the start of the 1-hour period for which weather data are forecasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ff468f-8f8f-478a-b6b4-09a3432e4c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(features_dtypes_df[features_dtypes_df == 'object'].dropna(axis=1, how='all'))\n",
    "pd.reset_option(\"display.max_columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f33d266-1321-4ed6-9a36-57f97023cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in DF_LIST:\n",
    "#     df['data_block_id'] = df['data_block_id'].astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f78aef-07ee-45bb-ae73-4013f3510849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(features_dtypes_df.drop(columns=['county', 'is_business', 'product_type', 'is_consumption']).values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50effe2-1a55-48ee-a766-70bddd1e8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict.fromkeys(train_df.dtypes[train_df.dtypes == 'category'].index, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6495d7e6-4436-44ae-a420-1bbddf850926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in DF_LIST:\n",
    "#     local_mapper = {}\n",
    "#     for dtype in ['float64', 'int64', 'object']:\n",
    "#         # if dtype in df.dtypes.astype('str').values:\n",
    "#         if dtype in df.dtypes.values:\n",
    "#             local_mapper.update(dict.fromkeys(df.dtypes[df.dtypes == dtype].index, dtype))\n",
    "\n",
    "            \n",
    "#             # print(dtype)\n",
    "#             # print(df.dtypes[df.dtypes == dtype])\n",
    "#             # print(50 * '-')\n",
    "#         else:\n",
    "#             print(f'no {dtype}')\n",
    "#             print(50 * '-')\n",
    "#     print(local_mapper)\n",
    "\n",
    "#     # df = df.astype(local_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d737607-a503-411b-bb7a-ed2bec8e4e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_columns\", None)\n",
    "# display(features_dtypes_df.drop(columns=['county', 'is_business', 'product_type', 'is_consumption']))\n",
    "# pd.reset_option(\"display.max_columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66eb50-8b30-4bee-a68c-4bb0d661d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_dtypes_df[features_dtypes_df.isin(['object'])].dropna(axis=1, how='all').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690cf36-0083-4078-9cb9-056c4728e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_nominal_dtypes_mapper = {\n",
    "#     \"target\": \"float32\",\n",
    "#     # \"datetime\": \"datetime64[ns]\",\n",
    "#     \"data_block_id\": \"uint16\"\n",
    "#     \"row_id\": \"uint32\",\n",
    "#     \"prediction_unit_id\": \"uint8\",\n",
    "#     \"forecast_date\": \"datetime64[ns]\",\n",
    "#     # \"lowest_price_per_mwh\" ':'\n",
    "\n",
    "#     'datetime': \"datetime64[ns]\",\n",
    "#     'forecast_date': \"datetime64[ns]\",\n",
    "#     'origin_date': \"datetime64[ns]\",\n",
    "#     'date': \"datetime64[ns]\",\n",
    "#     'origin_datetime': \"datetime64[ns]\",\n",
    "#     'forecast_datetime': \"datetime64[ns]\",\n",
    "    \n",
    "# }\n",
    "\n",
    "train_df = train_df.astype(\n",
    "    {\n",
    "        \"target\": \"float32\",\n",
    "        \"data_block_id\": \"uint16\",\n",
    "        \"row_id\": \"uint32\",\n",
    "        \"prediction_unit_id\": \"uint8\",\n",
    "        \"datetime\": \"datetime64[ns]\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfcb926-5b3a-4e0f-bdc2-d712312dede1",
   "metadata": {},
   "source": [
    "#### train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804d2c88-90ef-4a5d-8eda-c97c9f75caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Renaming to avoid confusion and improve readability\n",
    "# values_mapper = {\n",
    "#     \"county\": county_id_to_name_map,\n",
    "#     \"is_business\": {0: \"not_business\", 1: \"business\"},\n",
    "#     \"is_consumption\": {0: \"production\", 1: \"consumption\"},\n",
    "#     \"product_type\": {\n",
    "#         0: \"combined\",\n",
    "#         1: \"fixed\",\n",
    "#         2: \"general_service\",\n",
    "#         3: \"spot\",\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# # Check for unexpected values in columns to ensure mappings are up-to-date\n",
    "# for column, mapping in values_mapper.items():\n",
    "#     unexpected_values = set(train_df[column].unique()) - set(mapping.keys())\n",
    "#     if unexpected_values:\n",
    "#         print(f\"Unexpected values in {column}: {unexpected_values}\")\n",
    "\n",
    "# for key, value in values_mapper.items():\n",
    "#     train_df[key] = train_df[key].map(value).astype(\"category\")\n",
    "\n",
    "# # Change data types to reduce memory usage\n",
    "# train_df = train_df.astype(\n",
    "#     {\n",
    "#         \"target\": \"float32\",\n",
    "#         \"data_block_id\": \"uint16\",\n",
    "#         \"row_id\": \"uint32\",\n",
    "#         \"prediction_unit_id\": \"uint8\",\n",
    "#         \"datetime\": \"datetime64[ns]\",\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a560a138-e0ed-4ac6-9d15-34ca2f8a871b",
   "metadata": {},
   "source": [
    "#### gas_prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38515c4c-bd56-48f1-b793-8d39ac64357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change data types to reduce memory usage\n",
    "# gas_prices_df = gas_prices_df.astype(\n",
    "#     {\n",
    "#         \"forecast_date\": \"datetime64[ns]\",\n",
    "#         \"lowest_price_per_mwh\": \"float32\",\n",
    "#         \"highest_price_per_mwh\": \"float32\",\n",
    "#         \"origin_date\": \"datetime64[ns]\",\n",
    "#         \"data_block_id\": \"uint16\",\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a5974b-0895-4c12-8017-9b9d01f6ae64",
   "metadata": {},
   "source": [
    "# 4. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424f14df-1624-497d-8557-5de43817f181",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7003bf43-7780-4858-b00c-fd417639482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5630cba-d558-4e04-b15e-053609da30c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b0d83-dd65-470c-bace-79be97612b50",
   "metadata": {},
   "source": [
    "- The target has missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f96f0f-8e34-44af-8171-3706103a9db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().apply(lambda x: x.apply(\"{0:.2f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15085d1f-195a-437f-9ef4-42703814843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c78a3d-03ee-4f5f-8a6d-eebb94736a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new time-related features based on datetime\n",
    "\n",
    "# df[\"hour\"] = df[\"datetime\"].dt.hour.astype(\"uint8\")\n",
    "# df[\"day_of_week\"] = df[\"datetime\"].dt.day_of_week.astype(\"uint8\")\n",
    "# df[\"day\"] = df[\"datetime\"].dt.day.astype(\"uint16\")\n",
    "# df[\"week_of_year\"] = df[\"datetime\"].dt.isocalendar().week.astype(\"int8\")\n",
    "# df[\"month\"] = df[\"datetime\"].dt.month.astype(\"int8\")\n",
    "df[\"month\"] = df[\"datetime\"].dt.month.astype(\"category\")\n",
    "# df[\"quarter\"] = df[\"datetime\"].dt.quarter.astype(\"int8\")\n",
    "# df[\"year\"] = df[\"datetime\"].dt.year.astype(\"uint16\")\n",
    "df[\"year\"] = df[\"datetime\"].dt.year.astype(\"category\")\n",
    "\n",
    "# df[\"date\"] = df[\"datetime\"].dt.date\n",
    "df[\"date\"] = df[\"datetime\"].dt.date.astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03a645b-9a1f-453d-bdd7-8b47f56a8b0e",
   "metadata": {},
   "source": [
    "### Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ae369-c0b3-4e07-b6d2-19c39f9e37cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = 30\n",
    "# plt.figure(figsize=(12, 4))\n",
    "\n",
    "\n",
    "# sns.histplot(\n",
    "#     data=df,\n",
    "#     x='target',\n",
    "#     hue='is_consumption',\n",
    "#     bins=bins,\n",
    "#     multiple=\"dodge\",\n",
    "#     linewidth=0.5\n",
    "# )\n",
    "# plt.title('Distribution of Energy Consumption (Target)')\n",
    "# plt.xlabel('Energy values')\n",
    "# # plt.ylabel('Frequency')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779643df-d453-4315-bbee-0112c335787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating target's discrete intervals\n",
    "bins = 10\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "target_bins_percentage = round(\n",
    "    pd.cut(np.array(df.target), bins, precision=0).value_counts()\n",
    "    / df.shape[0]\n",
    "    * 100,\n",
    "    2,\n",
    ")\n",
    "\n",
    "# Re-calculate first value so\n",
    "# that the sum of the percentages is equal to 100.0\n",
    "target_bins_percentage[0] = 100 - target_bins_percentage[1:].sum()\n",
    "target_bins_percentage = [f\"{i:.2f}%\" for i in target_bins_percentage]\n",
    "\n",
    "target_max = df.target.max()\n",
    "ticks = range(0, int(target_max) + 1, int(target_max / bins))\n",
    "\n",
    "ax = sns.histplot(\n",
    "    df.target,\n",
    "    bins=bins,\n",
    "    kde=True,\n",
    "    linewidth=0.5,\n",
    ")\n",
    "\n",
    "# Adding group percentage to the top of each bar\n",
    "ax.bar_label(ax.containers[0], target_bins_percentage, padding=6, fontsize=11)\n",
    "\n",
    "plt.title(\n",
    "    f\"Histogram of {bins} discrete bins of the target values with KDE-line\"\n",
    ")\n",
    "plt.xticks(ticks=ticks, rotation=0)\n",
    "plt.xlabel(\"Target values\")\n",
    "\n",
    "# Using a logarithmic scale for the y-axis for better visualization\n",
    "# of small quantities of target values\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Count, log scale\", rotation=0, labelpad=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127b5ac5-fe6d-42e8-bbbe-4912c562dacc",
   "metadata": {},
   "source": [
    "- The target distribution is non-normal, it is right-skewed.\n",
    "- There are more values in the first discrete bin than the total number in the rest; the KDE-line shows that most of the values are near zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa9a5ed-8d33-48e7-b4ee-8ad8a40aeda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = 3  # The number of boxenplot levels\n",
    "\n",
    "# list with data for additional lines and text\n",
    "# started from .25 because lower corresponding percentiles are the same\n",
    "\n",
    "levels_list = [0.25] + np.cumsum(\n",
    "    [0.5 / pow(2, i) for i in range(levels + 1)]\n",
    ").tolist()\n",
    "levels_values = df.target.describe(levels_list)[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c42b314-83d3-42dc-9d62-ce61fa2fde2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 8))\n",
    "ax = sns.boxenplot(\n",
    "    df,\n",
    "    y=\"target\",\n",
    "    linewidth=0,\n",
    "    k_depth=levels,\n",
    "    flier_kws={\n",
    "        \"marker\": \".\",\n",
    "        \"s\": 0.1,\n",
    "    },\n",
    ")\n",
    "\n",
    "ax.set_xlim(ax.get_xlim()[0], ax.get_xlim()[1])\n",
    "\n",
    "plt.hlines(\n",
    "    levels_values.values,\n",
    "    0,\n",
    "    ax.get_xlim()[1],\n",
    "    \"orange\",\n",
    "    lw=1.2,\n",
    ")\n",
    "\n",
    "for ix, l in enumerate(levels_values):\n",
    "    plt.text(\n",
    "        ax.get_xlim()[1] + 0.03,\n",
    "        levels_values.values[ix],\n",
    "        f\"{levels_values.index[ix]}: {levels_values.values[ix]:.2f}\",\n",
    "        fontsize=11,\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "    )\n",
    "\n",
    "ax.set_ylim(-0.1, 30_000)\n",
    "plt.yscale(\"symlog\", linthresh=1)\n",
    "plt.title(f\"Boxenplot of the target values with {levels} levels\")\n",
    "plt.ylabel(\"Target values, log scale\", rotation=0, labelpad=65)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df2c8d5-4405-47b7-b54f-92943f139cc0",
   "metadata": {},
   "source": [
    "- Q<sub>1</sub> ≈ 0.38\n",
    "- Q<sub>2</sub> ≈ 31.13\n",
    "- Q<sub>3</sub> ≈ 180.21\n",
    "- There are only two levels on the Q<sub>1</sub> side of the boxenplot (as opposed to three levels on the Q<sub>3</sub> side), which means that there is a huge number of identical values that cannot be separated. That is, two different percentiles (6.25% and 12.5%) have the same value, which equal to the minimum value - 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b8e51-1fbd-469e-8c2b-8b58785bba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.target.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e0b346-07d0-4a33-aa46-6a7a3f7b035d",
   "metadata": {},
   "source": [
    "- Zero values are the most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e7e79e-c01a-43de-bda8-693b7ec6b3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.target.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f8298e-0bcf-4291-9849-2d4b6dc9229d",
   "metadata": {},
   "source": [
    "- Zero values occur in more than 10% of the cases (351496 / 2017824)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36309d19-113c-4824-94a1-16cdc29ea487",
   "metadata": {},
   "source": [
    "### Add classes comparasing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf890c32-80a1-4438-9b91-994c39b5519a",
   "metadata": {},
   "source": [
    "### County, is_business, is_consumption and product_type combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3e898c-55f2-4c76-ac57-8e051635b18b",
   "metadata": {},
   "source": [
    "From the description:\n",
    "\n",
    "- target - The consumption or production amount for the relevant segment for the hour. The segments are defined by the county, is_business, and product_type.\n",
    "- prediction_unit_id - A unique identifier for the county, is_business, and product_type combination. New prediction units can appear or disappear in the test set.\n",
    "\n",
    "Therefore, each combination of the county, is_business, is_consumption, and product_type should be considered as a separate time series. New time series may appear or existing ones may disappear in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e1c29a-3867-4e45-8724-d440a0add4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of target values in each time series and map each county to\n",
    "# its corresponding identifier from county_id_to_name_map\n",
    "\n",
    "df_categories = (\n",
    "    df.groupby(\n",
    "        [\n",
    "            \"county\",\n",
    "            \"is_business\",\n",
    "            \"product_type\",\n",
    "            \"is_consumption\",\n",
    "        ],\n",
    "        observed=True,\n",
    "    )[\"target\"]\n",
    "    .count()\n",
    "    .reset_index()\n",
    ")\n",
    "df_categories[\"county_num\"] = df_categories[\"county\"].map(\n",
    "    pd.Series(county_id_to_name_map.index, county_id_to_name_map.values)\n",
    ")\n",
    "df_categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068370fd-fc11-4217-abc6-4f5049706da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dimensions for each column\n",
    "\n",
    "county_dim = go.parcats.Dimension(values=df_categories.county, label=\"County\")\n",
    "is_business_dim = go.parcats.Dimension(\n",
    "    values=df_categories.is_business, label=\"Is business?\"\n",
    ")\n",
    "product_type_dim = go.parcats.Dimension(\n",
    "    values=df_categories.product_type, label=\"Product type\"\n",
    ")\n",
    "is_consumption_dim = go.parcats.Dimension(\n",
    "    values=df_categories.is_consumption, label=\"Is consumption?\"\n",
    ")\n",
    "\n",
    "color = df_categories.county_num\n",
    "colorscale = px.colors.make_colorscale(COLORS_LIST)\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Parcats(\n",
    "            dimensions=[\n",
    "                county_dim,\n",
    "                product_type_dim,\n",
    "                is_business_dim,\n",
    "                is_consumption_dim,\n",
    "            ],\n",
    "            line={\"color\": color, \"colorscale\": colorscale},\n",
    "            hoveron=\"dimension\",\n",
    "            labelfont={\"size\": 16, \"family\": \"sans-serif\"},\n",
    "            tickfont={\"size\": 16, \"family\": \"sans-serif\", \"color\": \"blue\"},\n",
    "            arrangement=\"freeform\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    font={\"size\": 18, \"family\": \"sans-serif\"},\n",
    "    title=\"Parallel categories diagram for all observed combinations of catego\\\n",
    "rical features\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8304a0-8367-4d91-9cc9-601ad7da495d",
   "metadata": {},
   "source": [
    "- There are different combinations of county-product_type-is_business features. All these combinations have two variants for is_consumption feature. What this means is that it is possible for each timestamp there are two target values for county-product_type-is_business combinations corresponding to consumption and production.\n",
    "- Only two counties have one combiation of product_type-is_business features: Läänemaa and Unknown. Both of them have only 'spot' and 'business' values in corresponding features.\n",
    "- It is worth noting that the description of prediction_unit_id says that new combinations of county, is_business, and product_type features may appear or disappear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd327029-e702-4b6a-9594-20923358f161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the first point\n",
    "\n",
    "# There are no timestamps in the dataframe,\n",
    "# for which there are only consumption or production values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261edcdd-6bfd-4aa1-b3d3-9dde0f8f5be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prodcons_df(\n",
    "    df: pd.DataFrame,\n",
    "    compare: str,\n",
    "    # group: list[str],\n",
    ") -> pd.DataFrame:\n",
    "    df = (\n",
    "        df.loc[df[\"is_consumption\"] == compare]\n",
    "        .groupby(\n",
    "            [\"datetime\", \"county\", \"is_business\", \"product_type\"],\n",
    "            observed=True,\n",
    "        )[\"target\"]\n",
    "        .count()\n",
    "        .reset_index()\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1f7afd-d572-4898-b524-2ead1b5bce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_prodcons_df(df, \"consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06beac1a-ec6e-4d36-ae59-81742926e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_prodcons_df(df, \"consumption\").equals(\n",
    "    create_prodcons_df(df, \"production\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29dba8e-2236-4cc7-a35d-a4fb37b4cd30",
   "metadata": {},
   "source": [
    "Yes, the first point is correct.\n",
    "For each combinations of datetime-county-is_business-product_type features there are one consumption value and one production value (including nan values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ddcb3e-b4ee-4033-8e23-dde2328bdd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x=\"datetime\",\n",
    "    y=\"target\",\n",
    "    s=1,\n",
    ")\n",
    "\n",
    "plt.title(\"Target values timeline\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Target values\", rotation=0, labelpad=40)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5fcc35-e010-48b3-a398-9b9d4bac4cce",
   "metadata": {},
   "source": [
    "- Values less than 1500 are indistinguishable, the point density is too high for this plot.\n",
    "- The target variable has seasonal and weekly cycles.\n",
    "- There are 'voids' during the New Year holidays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f0a1b-8889-464c-9043-bd807d469c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumption values are multiplied by (-1) for better visualisation\n",
    "\n",
    "df[\"modified_target\"] = np.where(\n",
    "    df[\"is_consumption\"] == \"consumption\",\n",
    "    df[\"target\"].mul(-1),\n",
    "    df[\"target\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6722578-402d-46c4-919e-b044fd558418",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "sns.scatterplot(\n",
    "    df.groupby(\n",
    "        [\"date\", \"is_consumption\", \"county\", \"product_type\"], observed=True\n",
    "    )[\"modified_target\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"modified_target\"),\n",
    "    # df,\n",
    "    x=\"date\",\n",
    "    # x=\"datetime\",\n",
    "    y=\"modified_target\",\n",
    "    hue=\"county\",\n",
    "    palette=PALETTE,\n",
    "    s=10,\n",
    ")\n",
    "\n",
    "plt.title(\n",
    "    \"Average energy consumption (below 0) or production (above 0) for each \\\n",
    "day for each county\",\n",
    "    fontsize=13,\n",
    ")\n",
    "\n",
    "plt.legend(\n",
    "    title=\"County\",\n",
    "    title_fontsize=12,\n",
    "    bbox_to_anchor=(1.005, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0,\n",
    "    markerscale=3,\n",
    "    frameon=False,\n",
    "    fontsize=11,\n",
    ")\n",
    "\n",
    "months_locator = mdates.MonthLocator()\n",
    "ax.xaxis.set_major_locator(months_locator)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Modified target\", rotation=0, labelpad=50)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6bec4c-086e-4ee8-a0fa-feca8f8bbef8",
   "metadata": {},
   "source": [
    "1. Electricity consumption and production values are increasing from year to year.\n",
    "2. Energy production in winter is significantly lower than in summer.\n",
    "3. Energy consumption in winter is bigger than in summer.\n",
    "4. During the New Year holidays, there is a decrease in electricity consumption.\n",
    "5. Harjumaa county has highest average (per day) values of energy consumption (for the entire observation period) and production (for spring-autumn period). Tartumaa has second highest values for the entire observation period except last two weeks when Valgamaa get ahead in energy production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f124fe-08b2-44ea-a4a5-c1140a17e394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the first point\n",
    "\n",
    "# Electricity consumption and production values are\n",
    "# increasing from year to year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8e614-28d8-4659-ac50-4188833f5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to only one year being fully available,\n",
    "# the other two years will be compared with respective months of 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9deea5b-6ef4-45cd-a17e-691c49d1d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_target_comparison_by_year(\n",
    "#     df: pd.DataFrame,\n",
    "#     first_year: int,\n",
    "#     second_year: int,\n",
    "# ) -> pd.DataFrame:\n",
    "\n",
    "#     if df[df[\"year\"] == first_year].month.unique().size == 12:\n",
    "#         complete_year = first_year\n",
    "#         incomplete_year = second_year\n",
    "#     else:\n",
    "#         complete_year = second_year\n",
    "#         incomplete_year = first_year\n",
    "\n",
    "#     grouped = df.loc[\n",
    "#         df[\"year\"].isin([incomplete_year, complete_year])\n",
    "#         & df.month.isin(df[df[\"year\"] == incomplete_year].month.unique())\n",
    "#     ].groupby(\n",
    "#         [\n",
    "#             \"is_consumption\",\n",
    "#             \"year\",\n",
    "#         ],\n",
    "#         observed=True,\n",
    "#     )[\n",
    "#         \"target\"\n",
    "#     ]\n",
    "\n",
    "#     return (\n",
    "#         pd.merge(\n",
    "#             grouped.describe(), grouped.sum(), on=[\"is_consumption\", \"year\"]\n",
    "#         )\n",
    "#         .rename(columns={\"target\": \"sum\"})\n",
    "#         .reset_index()\n",
    "#         .melt(id_vars=[\"year\", \"is_consumption\"])\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e18b6-92dd-4702-bd1d-b3cf1310d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year in [2021, 2023]:\n",
    "#     ax = sns.catplot(\n",
    "#         create_target_comparison_by_year(df, year, 2022),\n",
    "#         kind=\"bar\",\n",
    "#         x=\"year\",\n",
    "#         y=\"value\",\n",
    "#         col=\"variable\",\n",
    "#         hue=\"is_consumption\",\n",
    "#         sharey=False,\n",
    "#         height=2.7,\n",
    "#         aspect=0.6,\n",
    "#     ).set_titles(\"{col_name}\")\n",
    "#     ax.fig.subplots_adjust(top=0.8)\n",
    "#     if year > 2022:\n",
    "#         ax.fig.suptitle(\n",
    "#             f\"Comparing descriptive statistics between 2022 and \\\n",
    "# {year}\"\n",
    "#         )\n",
    "#     else:\n",
    "#         ax.fig.suptitle(\n",
    "#             f\"Comparing descriptive statistics between {year} and \\\n",
    "# 2022\"\n",
    "#         )\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172a84d3-a9fc-4e21-b226-7b2af63ea5cf",
   "metadata": {},
   "source": [
    "Yes, the first point is correct.\n",
    "- Total sum, quartiles, means and maximum values increase from year to year. The standard deviation also increase. The minimum value does not change; it is zero. None of the descriptive statistics decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195136a2-f45d-4ff1-86d4-c18a3bc1eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the second point\n",
    "# It appears that the relative growth rate of energy production is\n",
    "# growing faster than the relative growth rate of consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c21dd-97b4-4d79-b00b-4efbee89b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_difference_percentage(\n",
    "#     base_df: pd.DataFrame,\n",
    "#     first_year: int,\n",
    "#     second_year: int,\n",
    "# ) -> pd.DataFrame:\n",
    "\n",
    "#     df = create_target_comparison_by_year(base_df, first_year, second_year)\n",
    "#     # .sort_values(by=[\"is_consumption\", \"year\" , \"variable\"])\n",
    "#     # df = df[df[\"variable\"].isin([\"50%\", \"max\", \"mean\", \"sum\"])]\n",
    "\n",
    "#     first_df = df[df[\"year\"] == first_year].reset_index(drop=True)\n",
    "#     second_df = df[df[\"year\"] == second_year].reset_index(drop=True)\n",
    "\n",
    "#     percent = (\n",
    "#         (second_df.value - first_df.value) / first_df.value * 100\n",
    "#     ).rename(\"percentage_difference\")\n",
    "#     second_df = pd.concat(\n",
    "#         [\n",
    "#             second_df.drop(columns=[\"value\"]),\n",
    "#             first_df[\"value\"].rename(\"previous_value\"),\n",
    "#             second_df.value,\n",
    "#             percent,\n",
    "#         ],\n",
    "#         axis=1,\n",
    "#     )\n",
    "\n",
    "#     return second_df\n",
    "\n",
    "    \n",
    "# calculate_difference_percentage(df, 2022, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3458f7e-d989-4ea8-9fa5-f44eabb75900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage_df = pd.concat([\n",
    "#     calculate_difference_percentage(df, 2022, 2023),\n",
    "#     calculate_difference_percentage(df, 2021, 2022),\n",
    "# ]).reset_index(drop=True)\n",
    "\n",
    "# ax = sns.catplot(\n",
    "#     percentage_df,\n",
    "#     x=\"year\",\n",
    "#     y=\"percentage_difference\",\n",
    "#     row=\"is_consumption\",\n",
    "#     col=\"variable\",\n",
    "#     kind=\"bar\",\n",
    "#     hue='is_consumption',\n",
    "#     sharey=False,\n",
    "#     height=2.5,\n",
    "#     aspect=0.6,\n",
    "#     # height=3,\n",
    "#     # aspect=1,\n",
    "#     margin_titles=True\n",
    "# )\n",
    "# ax.fig.subplots_adjust(top=0.88)\n",
    "# ax.fig.suptitle('Visualisation the difference between two years in percent')\n",
    "# # ax.tick_params(axis='x', rotation=30)\n",
    "# plt.show()\n",
    "# # The second bar of the first barplot is missing because median value for the corresponding previous year months (2021 year, months from 9 to 12) was 0 and for this case growth is uncountable in percent.\n",
    "# # Yes, the third point is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45e680-db0f-4f0e-bba1-c977719d09bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_range = pd.date_range(df.datetime.min(), df.datetime.max(), 4)\n",
    "\n",
    "# ax = sns.relplot(\n",
    "#     data=df,\n",
    "#     x=\"datetime\",\n",
    "#     y=\"modified_target\",\n",
    "#     row=\"is_business\",\n",
    "#     col=\"product_type\",\n",
    "#     hue=\"county\",\n",
    "#     palette=PALETTE,\n",
    "#     height=3,\n",
    "#     s=3,\n",
    "# )\n",
    "# ax.set_titles(\"{col_name}\")\n",
    "# ax.set(xticks=date_range)\n",
    "# ax.set_xticklabels(\n",
    "#     date_range,\n",
    "#     rotation=30,\n",
    "# )\n",
    "# ax.axes[0, 0].xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m\"))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf19bb71-b707-41a0-99e0-630ae83ade1e",
   "metadata": {},
   "source": [
    "# ?Conclusions from relplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e0275-9a31-4d11-b438-cf8b2303a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.rcParams[\"patch.edgecolor\"] = \"none\"\n",
    "\n",
    "ax = sns.histplot(\n",
    "    data=df[\n",
    "        [\n",
    "            \"county\",\n",
    "            \"product_type\",\n",
    "        ]\n",
    "    ],\n",
    "    y=\"county\",\n",
    "    hue=\"product_type\",\n",
    "    multiple=\"stack\",\n",
    "    shrink=0.75,\n",
    "    palette=\"deep\",\n",
    ")\n",
    "\n",
    "sns.move_legend(\n",
    "    ax,\n",
    "    \"upper left\",\n",
    "    bbox_to_anchor=(1, 1),\n",
    "    title=\"product_type\",\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "plt.title(\n",
    "    \"Counties by product type\",\n",
    ")\n",
    "plt.xticks(\n",
    "    ticks=range(0, int(2.5e5), int(2.5e4)),\n",
    ")\n",
    "plt.xlabel(\n",
    "    \"Number of target values\",\n",
    "    fontsize=11,\n",
    ")\n",
    "plt.ylabel(\"Estonian counties\", rotation=0, labelpad=60, fontsize=11)\n",
    "\n",
    "plt.show()\n",
    "plt.rcParams[\"patch.edgecolor\"] = \"black\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a564d5-33c8-4682-815e-d80dcc8d74ad",
   "metadata": {},
   "source": [
    "1. Counties have different numbers of total records and ratios of contract types.\n",
    "2. First place by the count of records is the 'Spot' product type, the second place is 'Fixed' product type. Third place is most likely the 'Combined' product type.\n",
    "3. It seems that for the \"spot\" product type, the number of records for all counties is approximately 60000, except for Läänemaa and Unknown counties, where the number of records is approximately 30000.\n",
    "4. Some counties don't have certain types of contracts. In the records of Läänemaa and Unknown county there is only one type of product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89947d38-d30e-4837-b9f4-f7d4368c8bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the second point\n",
    "# First place by the count of records is the 'Spot' product type,\n",
    "# the second place is 'Fixed' product type.\n",
    "# Third place is most likely the 'Combined' product type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dc6950-cd57-4c56-8d1c-65af75e47a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"product_type\"], observed=True)[[\"target\"]].count().sort_values(\n",
    "    \"target\", ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3197baf5-7743-465e-a630-12e678181bf2",
   "metadata": {},
   "source": [
    "Yes, the second point is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d664017-f755-4e08-80a6-b1545d9c83e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the third point\n",
    "# It seems that for the \"spot\" product type, the number of records\n",
    "# for all counties is approximately 60000, except for Läänemaa and\n",
    "# Unknown counties, where the number of records is approximately 30000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16365af-4401-4905-abb6-cbaddbcf4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"county\", \"product_type\"], observed=True)[\n",
    "    [\"target\"]\n",
    "].count().query('product_type == \"Spot\"').target.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68994ed-78ad-4ad5-b3f1-2b901c3fb935",
   "metadata": {},
   "source": [
    "Yes, the third point is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca785142-6b21-4e0d-998b-00c3256525b7",
   "metadata": {},
   "source": [
    "Comparing the total number of records in each subgroup (all combinations of \"county\", \"product_type\", \"is_business\", \"is_consumption\" that appear in the dataframe) due to the fact that counties have different total number of records and ratios of contract types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d3a18a-bf4c-49a9-a8a2-617a877ef4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering columns\n",
    "# df_categories = df_categories.copy()[[\n",
    "#     \"county\",\n",
    "#     \"product_type\",\n",
    "#     \"is_business\",\n",
    "#     \"is_consumption\",\n",
    "#     \"target\",\n",
    "#     \"county_num\",\n",
    "# ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98465212-bab8-4218-a03a-aa4768ee82c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories[\"subgroup\"] = (\n",
    "    df_categories[[\"county\", \"product_type\", \"is_business\", \"is_consumption\"]]\n",
    "    .astype(str)\n",
    "    .agg(\"-\".join, axis=1)\n",
    ")\n",
    "df_categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5fba42-5227-4e3d-88d3-a482b934c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_df = (\n",
    "#     df.groupby([\n",
    "#         \"county\",\n",
    "#         \"product_type\",\n",
    "#         \"is_business\",\n",
    "#         \"is_consumption\",\n",
    "#     ], observed=True,)[\"target\"].count().reset_index()\n",
    "# )\n",
    "# count_df[\"subgroup\"] = (\n",
    "#     count_df[[\"county\", \"product_type\", \"is_business\", \"is_consumption\"]]\n",
    "#     .astype(str)\n",
    "#     .agg(\"-\".join, axis=1)\n",
    "# )\n",
    "# count_df.head()\n",
    "\n",
    "# first_part_df = count_df[count_df['county'].isin(count_df.county.unique()[:int(count_df.county.nunique() / 2)])]\n",
    "# second_part_df = count_df[count_df['county'].isin(count_df.county.unique()[int(count_df.county.nunique() / 2):])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7db8eb-3893-41fd-9c4d-f4bb8d403eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f71f7-51b7-43a2-bf7d-6ee4013ffc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_part_df = df_categories[\n",
    "    df_categories[\"county\"].isin(\n",
    "        df_categories.county.unique()[\n",
    "            : int(df_categories.county.nunique() / 2)\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "second_part_df = df_categories[\n",
    "    df_categories[\"county\"].isin(\n",
    "        df_categories.county.unique()[\n",
    "            int(df_categories.county.nunique() / 2) :\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab34da-24a2-48a7-a87a-acf95470932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 1\n",
    "cols = 2\n",
    "categories = [first_part_df, second_part_df]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 14))\n",
    "plt.subplots_adjust(\n",
    "    wspace=1.1,\n",
    ")\n",
    "for ind, column in enumerate(categories):\n",
    "    plt.subplot(rows, cols, ind + 1)\n",
    "    data = categories[ind]\n",
    "    ax = sns.barplot(\n",
    "        data=data,\n",
    "        x=\"target\",\n",
    "        y=\"subgroup\",\n",
    "        hue=\"county\",\n",
    "        palette=PALETTE,\n",
    "    )\n",
    "    ax.set_yticks([i for i in range(data.subgroup.nunique())])\n",
    "    ax.set_yticklabels(\n",
    "        data.subgroup.apply(lambda x: \"-\".join(x.split(\"-\")[-3:])),\n",
    "    )\n",
    "    if ind == 0:\n",
    "        ax.legend_.remove()\n",
    "    else:\n",
    "        sns.move_legend(\n",
    "            ax,\n",
    "            \"upper left\",\n",
    "            bbox_to_anchor=(1, 1),\n",
    "            title=\"County\",\n",
    "            frameon=False,\n",
    "        )\n",
    "    plt.ylabel(\n",
    "        ylabel=\"\",\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c429c8e-f3df-4fd3-9a7d-2e8a86e1bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e9ce34-6ecf-4233-a9d9-79807054108c",
   "metadata": {},
   "source": [
    "Each combination of county, product_type, and is_business has the same number of target values for both consumption and production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cd7743-d394-4d30-bdb2-1ee9e6651c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows = 4\n",
    "# cols = 1\n",
    "# categories = [\"county\", \"is_business\", \"product_type\", \"is_consumption\"]\n",
    "\n",
    "# fig, ax = plt.subplots(\n",
    "#     nrows=rows,\n",
    "#     ncols=cols,\n",
    "#     figsize=(12, 15),\n",
    "# )\n",
    "\n",
    "# for ind, column in enumerate(categories):\n",
    "#     plt.subplot(rows, cols, ind + 1)\n",
    "#     data = (\n",
    "#         df[column]\n",
    "#         .value_counts(normalize=True)\n",
    "#         .rename(\"percentage\")\n",
    "#         .mul(100)\n",
    "#         .reset_index()\n",
    "#         .round(2)\n",
    "#     )\n",
    "\n",
    "#     # Rounding for total sum == 100.0\n",
    "#     data[\"percentage\"] = data[\"percentage\"].transform(\n",
    "#         lambda x: pd.Series(\n",
    "#             {x.index[0]: (100 - x.iloc[1:].sum())}\n",
    "#         ).combine_first(x)\n",
    "#     )\n",
    "\n",
    "#     barplot = sns.barplot(\n",
    "#         data=data,\n",
    "#         y=column,\n",
    "#         x=\"percentage\",\n",
    "#         hue=column,\n",
    "#         orient=\"h\",\n",
    "#         legend=False,\n",
    "#         # palette=PALETTE,\n",
    "#     )\n",
    "#     for container in barplot.containers:\n",
    "#         barplot.bar_label(\n",
    "#             container,\n",
    "#             fmt=f\"%.{2}f\",\n",
    "#         )\n",
    "\n",
    "#     # plt.legend('', frameon=False)\n",
    "#     plt.ylabel(\n",
    "#         column,\n",
    "#         rotation=0,\n",
    "#         labelpad=60,\n",
    "#     )\n",
    "\n",
    "# fig.align_ylabels()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f60127d-6f40-4b5a-9690-1f5e4bbed6ef",
   "metadata": {},
   "source": [
    "# ?Conclusions from barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca46a7-35f7-4a2a-a431-fe1e2e9f875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_business = sns.relplot(\n",
    "#     data=df,\n",
    "#     x=\"datetime\",\n",
    "#     y=\"modified_target\",\n",
    "#     col=\"is_business\",\n",
    "#     hue=\"county\",\n",
    "#     height = 8,\n",
    "#     # aspect = 1.6,\n",
    "#     # size=\"size\",\n",
    "#     # style=\"sex\",\n",
    "#     palette=PALETTE,\n",
    "#     s=1,\n",
    "# )\n",
    "# # l = target_business._legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43552525-82b8-46b0-bb03-877212acd715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(18, 8))\n",
    "# sns.boxenplot(\n",
    "#     data=df,\n",
    "#     x=\"county\",\n",
    "#     y=\"target\",\n",
    "#     hue=\"is_consumption\",\n",
    "#     # k_depth = 'full'\n",
    "#     # split=True,\n",
    "#     # style='is_business',\n",
    "# )\n",
    "\n",
    "# plt.title(\n",
    "#     \"Comparison of energy production and consumption in each county\"\n",
    "# )\n",
    "# # plt.legend(\n",
    "# #     bbox_to_anchor=(1.005, 1),\n",
    "# #     loc=\"upper left\",\n",
    "# #     borderaxespad=0,\n",
    "# #     # markerscale=3,\n",
    "# # )\n",
    "\n",
    "# for i in range(df.county.nunique()):\n",
    "#     ax.axvline(\n",
    "#         i -.5,\n",
    "#         color=\"black\",\n",
    "#         alpha=.2\n",
    "#     )\n",
    "\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# plt.yscale('log')\n",
    "# # plt.grid(axis='y',alpha=.2)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890aa420-aacd-4549-af3b-b9c8a0c03793",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    df.groupby([\"date\", \"product_type\", \"county\"], observed=True)[\"target\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"target\")\n",
    ")\n",
    "data = data.astype({\"date\": \"datetime64[ns]\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08353ac0-22d1-4c86-a651-715abfa5d981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of missing data and zeros using lineplot of the daily average\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "ax = sns.lineplot(\n",
    "    data=data,\n",
    "    x=\"date\",\n",
    "    y=\"target\",\n",
    "    style=\"product_type\",\n",
    "    hue=\"county\",\n",
    "    lw=1,\n",
    "    palette=PALETTE,\n",
    ")\n",
    "ax.grid()\n",
    "ax.set_yscale(\"log\")\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1.005, 1), frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab753d-b2c5-4e0c-8494-965283ddab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.query('county == \"Saaremaa\" and \"2021-02-01\" <= date <= \"2021-02-01\" ')\n",
    "# data.query(\n",
    "#     'product_type == \"general_service\" and county == \"Pärnumaa\" and (\"2021-02-01\" < date < \"2021-03-01\")'\n",
    "# )\n",
    "# data.county.unique().tolist()\n",
    "# df_for_missing = train_df.drop(columns=['data_block_id', 'row_id', 'prediction_unit_id']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f120f31-de39-41d6-b8ed-f3b3c2ae5e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Renaming to avoid confusion and improve readability\n",
    "# values_mapper = {\n",
    "#     \"county\": county_id_to_name_map,\n",
    "#     \"is_business\": {\n",
    "#         0: \"not_business\",\n",
    "#         1: \"business\"\n",
    "#     },\n",
    "#     \"is_consumption\": {\n",
    "#         0: \"production\",\n",
    "#         1: \"consumption\"\n",
    "#     },\n",
    "#     \"product_type\": {\n",
    "#         0: \"Combined\",\n",
    "#         1: \"Fixed\",\n",
    "#         2: \"General service\",\n",
    "#         3: \"Spot\",\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# for column in values_mapper:\n",
    "#     df_for_missing[column] = df_for_missing[column].map(values_mapper[column])\n",
    "\n",
    "# df_for_missing = df_for_missing.astype({\n",
    "#     \"county\": \"category\",\n",
    "#     \"is_business\": \"category\",\n",
    "#     \"product_type\": \"category\",\n",
    "#     \"is_consumption\": \"category\",\n",
    "#     \"datetime\": \"datetime64[ns]\",\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cdcc8d-17df-44b5-a2a2-0feadfd3c1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_missing = df[\n",
    "    [\n",
    "        \"county\",\n",
    "        \"is_business\",\n",
    "        \"product_type\",\n",
    "        \"target\",\n",
    "        \"is_consumption\",\n",
    "        \"datetime\",\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "df_for_missing[\"hour_stamp\"] = (\n",
    "    (df_for_missing[\"datetime\"] - df_for_missing[\"datetime\"].min())\n",
    "    / pd.Timedelta(hours=1)\n",
    ").astype(int)\n",
    "\n",
    "df_for_missing[\n",
    "    [\n",
    "        \"hour_stamp\",\n",
    "        \"datetime\",\n",
    "    ]\n",
    "].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2276ef22-f606-4a08-bfab-03aaa5b2fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_missing[\"group_index\"] = df_for_missing.groupby(\n",
    "    [\n",
    "        \"county\",\n",
    "        \"is_business\",\n",
    "        \"product_type\",\n",
    "        \"is_consumption\",\n",
    "    ],\n",
    "    observed=True,\n",
    ").ngroup()\n",
    "\n",
    "df_for_missing = df_for_missing.sort_values([\"hour_stamp\", \"group_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46573be-7862-4b82-acbf-fa8c8dbb0e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vl = df_for_missing.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270aa9f6-fb1c-41a5-80e8-2e0adb51670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb010ba8-e84d-43ac-a224-87ea38566d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a625ef-60dc-4312-be89-f626f78e9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "missmap = np.empty(\n",
    "    (\n",
    "        df_for_missing.hour_stamp.max() + 1,\n",
    "        df_for_missing[\"group_index\"].nunique(),\n",
    "    )\n",
    ")\n",
    "missmap.fill(np.nan)\n",
    "for obs in df_for_missing.values:\n",
    "    missmap[int(obs[6]), (obs[7])] = 0 if obs[3] == 0 else 1\n",
    "missmap = missmap.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9a75d0-3d75-4971-889b-2a60a7812e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(\n",
    "#     [\n",
    "#         [1, 0, 0, 0, 1],\n",
    "#         [1, np.NaN, np.NaN, np.NaN, 1],\n",
    "#         [1, 1, 1, 1, 1],\n",
    "#     ],\n",
    "#     # cmap=\"Paired\",\n",
    "#     cmap='viridis',\n",
    "#     cbar=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4954d943-8841-45d0-8bc3-a0b54cc5d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(20, 80))\n",
    "# sns.heatmap(\n",
    "#     missmap,\n",
    "#     # cmap='Paired',\n",
    "#     cmap=\"viridis\",\n",
    "#     cbar=False,\n",
    "# )\n",
    "# missmap = missmap.T\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.heatmap(\n",
    "    missmap,\n",
    "    # cmap='Paired',\n",
    "    cmap=\"viridis\",\n",
    "    cbar=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1916b2df-6920-472c-9bb7-4d202d660399",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.assign(\n",
    "    category_index=df.groupby(\n",
    "        [\n",
    "            \"county\",\n",
    "            \"is_business\",\n",
    "            \"product_type\",\n",
    "            \"is_consumption\",\n",
    "        ],\n",
    "        observed=True,\n",
    "    ).ngroup()\n",
    ")[[\"datetime\", \"target\", \"category_index\"]]\n",
    "test[\"datetime\"] = (\n",
    "    (test[\"datetime\"] - test[\"datetime\"].min()) / pd.Timedelta(hours=1)\n",
    ").astype(int)\n",
    "test = test.rename(columns={\"datetime\": \"hour_stamp\"})\n",
    "test.target = test.target.where(((test.target == 0) | (test.target.isna())), 1)\n",
    "test = test.pivot(\n",
    "    columns=\"category_index\", index=\"hour_stamp\", values=\"target\"\n",
    ")\n",
    "\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08ad6c1-caba-4c5c-85a9-a682a8fbc764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "plt.figure(figsize=(24, 8))\n",
    "\n",
    "cmap = ListedColormap([\"y\", \"forestgreen\"])\n",
    "xticks = 19  # Desired number -1\n",
    "max_hour_range = test.index[-1]\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    test.T,\n",
    "    cmap=cmap,\n",
    "    cbar_kws={\n",
    "        \"shrink\": 0.5,\n",
    "        \"pad\": 0.01,\n",
    "        \"aspect\": 25,\n",
    "        \"ticks\": [0.25, 0.75],\n",
    "    },\n",
    ")\n",
    "colorbar = ax.collections[0].colorbar\n",
    "colorbar.set_ticklabels([\"0\", \">0\"])\n",
    "\n",
    "plt.xticks(\n",
    "    ticks=range(0, max_hour_range, int(max_hour_range / xticks)),\n",
    "    labels=range(0, max_hour_range, int(max_hour_range / xticks)),\n",
    "    rotation=45,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aeb73a-1157-4150-86be-dfd17bf246eb",
   "metadata": {},
   "source": [
    "# ?Conclusions from heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f5b406-72b9-4e3b-8fae-0f383beff43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_percentage_in_subgroup(\n",
    "    df: pd.DataFrame, feature: str, broken_down_by: str, target: str\n",
    ") -> pd.DataFrame:\n",
    "    df = (\n",
    "        df.groupby([broken_down_by, feature], observed=True)[[target]]\n",
    "        .sum()\n",
    "        .groupby(level=0, observed=True)\n",
    "        .apply(lambda x: x * 100 / x.sum())\n",
    "        .reset_index(level=0, drop=True)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"target\": \"percentage\"})\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d86bc8-209c-4ab8-9bb6-1fedf70639c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_for_categorical_feature(\n",
    "    df: pd.DataFrame,\n",
    "    broken_down_by: str,\n",
    "    features_list: list[str],\n",
    "    target: str,\n",
    "):\n",
    "    length = len(features_list)\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=length,\n",
    "        ncols=1,\n",
    "        figsize=(16, 15),\n",
    "    )\n",
    "    fig.tight_layout(pad=5)\n",
    "\n",
    "    for idx, feature in enumerate(features_list):\n",
    "        plt.subplot(length, 1, 1 + idx)\n",
    "        data = target_percentage_in_subgroup(\n",
    "            df, feature, broken_down_by, target\n",
    "        )\n",
    "\n",
    "        barplot = sns.barplot(\n",
    "            data=data,\n",
    "            x=\"percentage\",\n",
    "            y=feature,\n",
    "            hue=broken_down_by,\n",
    "        )\n",
    "\n",
    "        for container in barplot.containers:\n",
    "            barplot.bar_label(\n",
    "                container,\n",
    "                fmt=\"%.2f\",\n",
    "            )\n",
    "\n",
    "        plt.title(f\"{feature} broken down by {broken_down_by}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1303764-89e7-4c93-9033-b1321388f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_for_categorical_feature(\n",
    "    df,\n",
    "    \"is_consumption\",\n",
    "    [\"county\", \"is_business\", \"product_type\"],\n",
    "    \"target\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5784fae-53c2-45c6-97c1-1243e04944cd",
   "metadata": {},
   "source": [
    "# ?Conclusions from barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063d88d-3546-4ae0-aae3-8389350b5cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abed618a-d92a-4a17-a9ac-5c8b1a68211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hours = df.copy()\n",
    "\n",
    "# hours_ago = (\n",
    "#     [i for i in range(1, 25)]\n",
    "#     + [24 * i for i in range(2, 8)]\n",
    "#     + [168 * i for i in range(2, 9)]\n",
    "#     + [672 * i for i in range(3, 13)]\n",
    "# )\n",
    "# for h in hours_ago:\n",
    "#     df_hours[f\"tm_{h}h\"] = df_hours[\"modified_target\"].shift(h)\n",
    "# df_hours.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f9b85-42e8-414a-80df-a01be08a0bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"tm_1h\"] = df[\"modified_target\"].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a35937-f580-488f-ae59-ef17e4fc5fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_lags(df):\n",
    "#     target_map = df['PJME_MW'].to_dict()\n",
    "#     df['lag1'] = (df.index - pd.Timedelta('364 days')).map(target_map)\n",
    "#     df['lag2'] = (df.index - pd.Timedelta('728 days')).map(target_map)\n",
    "#     df['lag3'] = (df.index - pd.Timedelta('1092 days')).map(target_map)\n",
    "#     return df\n",
    "# df_label = pd.get_dummies(df_label, drop_first=True)\n",
    "# df_label.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a961c50-b70a-454a-acfb-911ff580a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_label.drop(\n",
    "#     columns=[\n",
    "#         \"target\",\n",
    "#         \"data_block_id\",\n",
    "#         \"row_id\",\n",
    "#         \"prediction_unit_id\",\n",
    "#         \"modified_target\",\n",
    "#     ],\n",
    "#     axis=1,\n",
    "# )\n",
    "\n",
    "# y = df_label[\"modified_target\"].values\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.20, random_state=RAND\n",
    "# )\n",
    "\n",
    "# st = StandardScaler()\n",
    "# X_train_std = st.fit_transform(X_train)\n",
    "# X_test_std = st.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab19d1-f223-4c57-b205-fc5dc087d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def r2_adjusted(\n",
    "#     y_true: np.ndarray, y_pred: np.ndarray, X_test: np.ndarray | int\n",
    "# ) -> float:\n",
    "#     \"\"\"Коэффициент детерминации (множественная регрессия)\"\"\"\n",
    "#     N_objects = len(y_true)\n",
    "\n",
    "#     if isinstance(X_test, np.ndarray):\n",
    "#         N_features = X_test.shape[1]\n",
    "#     else:\n",
    "#         N_features = X_test\n",
    "\n",
    "#     #     N_features = X_test.shape[1]\n",
    "#     r2 = r2_score(y_true, y_pred)\n",
    "#     return 1 - (1 - r2) * (N_objects - 1) / (N_objects - N_features - 1)\n",
    "\n",
    "\n",
    "# def mpe(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "#     \"\"\"Mean percentage error\"\"\"\n",
    "#     return np.mean((y_true - y_pred) / y_true, axis=0) * 100\n",
    "\n",
    "\n",
    "# def mape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "#     \"\"\"Mean absolute percentage error\"\"\"\n",
    "#     return np.mean(np.abs((y_pred - y_true) / y_true), axis=0) * 100\n",
    "\n",
    "\n",
    "# def wape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "#     \"\"\"Weighted Absolute Percent Error\"\"\"\n",
    "#     return np.sum(np.abs(y_pred - y_true)) / np.sum(y_true) * 100\n",
    "\n",
    "\n",
    "# def huber_loss(\n",
    "#     y_true: np.ndarray | pd.DataFrame,\n",
    "#     y_pred: np.ndarray | pd.DataFrame,\n",
    "#     delta: float = 1.345,\n",
    "# ):\n",
    "#     \"\"\"Функция ошибки Хьюбера\"\"\"\n",
    "\n",
    "#     if isinstance(y_true, pd.DataFrame):\n",
    "#         y_true = y_true.squeeze().to_numpy()\n",
    "#     if isinstance(y_pred, pd.DataFrame):\n",
    "#         y_pred = y_pred.squeeze().to_numpy()\n",
    "\n",
    "#     assert len(y_true) == len(y_pred), \"Разные размеры данных\"\n",
    "#     huber_sum = 0\n",
    "#     for i in range(len(y_true)):\n",
    "#         if abs(y_true[i] - y_pred[i]) <= delta:\n",
    "#             huber_sum += 0.5 * (y_true[i] - y_pred[i]) ** 2\n",
    "#         else:\n",
    "#             huber_sum += delta * (abs(y_true[i] - y_pred[i]) - 0.5 * delta)\n",
    "#     huber_sum /= len(y_true)\n",
    "#     return huber_sum\n",
    "\n",
    "\n",
    "# def logcosh(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "#     \"\"\"функция ошибки Лог-Кош\"\"\"\n",
    "#     return np.sum(np.log(np.cosh(y_true - y_pred)))\n",
    "\n",
    "\n",
    "# def rmsle(y_true: np.ndarray, y_pred: np.ndarray) -> np.float64:\n",
    "#     \"\"\"\n",
    "#     Root Mean Squared Log Error (RMSLE) metric\n",
    "#     Логарифмическая ошибка средней квадратичной ошибки\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "#     except:\n",
    "#         return None\n",
    "\n",
    "\n",
    "# def get_metrics(\n",
    "#     y_test: np.ndarray,\n",
    "#     y_pred: np.ndarray,\n",
    "#     X_test: np.ndarray,\n",
    "#     name: str = None,\n",
    "#     delta: float = 1.345,\n",
    "# ):\n",
    "#     \"\"\"Генерация таблицы с метриками\"\"\"\n",
    "#     df_metrics = pd.DataFrame()\n",
    "#     df_metrics[\"model\"] = [name]\n",
    "\n",
    "#     df_metrics[\"MAE\"] = mean_absolute_error(y_test, y_pred)\n",
    "#     df_metrics[\"MSE\"] = mean_squared_error(y_test, y_pred)\n",
    "#     df_metrics[\"Huber_loss\"] = huber_loss(y_test, y_pred, delta)\n",
    "#     df_metrics[\"Logcosh\"] = logcosh(y_test, y_pred)\n",
    "#     df_metrics[\"RMSE\"] = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#     df_metrics[\"RMSLE\"] = rmsle(y_test, y_pred)\n",
    "#     df_metrics[\"R2 adjusted\"] = r2_adjusted(y_test, y_pred, X_test)\n",
    "#     df_metrics[\"MPE_%\"] = mpe(y_test, y_pred)\n",
    "#     df_metrics[\"MAPE_%\"] = mape(y_test, y_pred)\n",
    "#     df_metrics[\"WAPE_%\"] = wape(y_test, y_pred)\n",
    "\n",
    "#     return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c61be9d-d40b-4ef8-80dd-e3fd686d52c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_skl = LinearRegression()\n",
    "# lr_skl.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5fda38-2455-4c3f-867b-acd7c0bd950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_skl_pred = lr_skl.predict(X_test_std)\n",
    "# skl_m = get_metrics(y_test, lr_skl_pred, X_test_std, name=\"skl_lr\")\n",
    "# skl_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a3bb2f-54a6-49bd-867d-f4c4887725f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hours = df_hours[\n",
    "#     [\n",
    "#         \"county\",\n",
    "#         \"is_business\",\n",
    "#         \"product_type\",\n",
    "#         \"target\",\n",
    "#         \"is_consumption\",\n",
    "#         \"hour\",\n",
    "#         \"day_of_week\",\n",
    "#         \"day\",\n",
    "#         \"week_of_year\",\n",
    "#         \"month\",\n",
    "#         \"quarter\",\n",
    "#         \"year\",\n",
    "#         \"modified_target\",\n",
    "#         \"tm_1h\",\n",
    "#         \"tm_2h\",\n",
    "#         \"tm_3h\",\n",
    "#         \"tm_4h\",\n",
    "#         \"tm_5h\",\n",
    "#         \"tm_6h\",\n",
    "#         \"tm_7h\",\n",
    "#         \"tm_8h\",\n",
    "#         \"tm_9h\",\n",
    "#         \"tm_10h\",\n",
    "#         \"tm_11h\",\n",
    "#         \"tm_12h\",\n",
    "#         \"tm_13h\",\n",
    "#         \"tm_14h\",\n",
    "#         \"tm_15h\",\n",
    "#         \"tm_16h\",\n",
    "#         \"tm_17h\",\n",
    "#         \"tm_18h\",\n",
    "#         \"tm_19h\",\n",
    "#         \"tm_20h\",\n",
    "#         \"tm_21h\",\n",
    "#         \"tm_22h\",\n",
    "#         \"tm_23h\",\n",
    "#         \"tm_24h\",\n",
    "#         \"tm_48h\",\n",
    "#         \"tm_72h\",\n",
    "#         \"tm_96h\",\n",
    "#         \"tm_120h\",\n",
    "#         \"tm_144h\",\n",
    "#         \"tm_168h\",\n",
    "#         \"tm_336h\",\n",
    "#         \"tm_504h\",\n",
    "#         \"tm_672h\",\n",
    "#         \"tm_840h\",\n",
    "#         \"tm_1008h\",\n",
    "#         \"tm_1176h\",\n",
    "#         \"tm_1344h\",\n",
    "#         \"tm_2016h\",\n",
    "#         \"tm_2688h\",\n",
    "#         \"tm_3360h\",\n",
    "#         \"tm_4032h\",\n",
    "#         \"tm_4704h\",\n",
    "#         \"tm_5376h\",\n",
    "#         \"tm_6048h\",\n",
    "#         \"tm_6720h\",\n",
    "#         \"tm_7392h\",\n",
    "#         \"tm_8064h\",\n",
    "#     ]\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7194de-f912-4c8d-bf34-fe154b1569ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hours = df_hours.sort_index()\n",
    "# tss = TimeSeriesSplit(n_splits=3, test_size=300_000)\n",
    "\n",
    "# fold = 0\n",
    "# preds = []\n",
    "# scores = []\n",
    "# for train_idx, val_idx in tss.split(df_hours):\n",
    "#     train = df_hours.iloc[train_idx]\n",
    "#     test = df_hours.iloc[val_idx]\n",
    "\n",
    "#     reg = XGBRegressor(\n",
    "#         n_estimators=2000,\n",
    "#         early_stopping_rounds=50,\n",
    "#         objective=\"reg:squarederror\",\n",
    "#         enable_categorical=True,\n",
    "#         eval_metric=\"mae\",\n",
    "#         # max_depth=3,\n",
    "#         learning_rate=0.01,\n",
    "#         random_state=RAND,\n",
    "#     )\n",
    "#     FEATURES = [\n",
    "#         \"county\",\n",
    "#         \"is_business\",\n",
    "#         \"product_type\",\n",
    "#         \"is_consumption\",\n",
    "#         \"hour\",\n",
    "#         \"day_of_week\",\n",
    "#         \"day\",\n",
    "#         \"week_of_year\",\n",
    "#         \"month\",\n",
    "#         \"quarter\",\n",
    "#         \"year\",\n",
    "#         \"tm_1h\",\n",
    "#         \"tm_2h\",\n",
    "#         \"tm_3h\",\n",
    "#         \"tm_4h\",\n",
    "#         \"tm_5h\",\n",
    "#         \"tm_6h\",\n",
    "#         \"tm_7h\",\n",
    "#         \"tm_8h\",\n",
    "#         \"tm_9h\",\n",
    "#         \"tm_10h\",\n",
    "#         \"tm_11h\",\n",
    "#         \"tm_12h\",\n",
    "#         \"tm_13h\",\n",
    "#         \"tm_14h\",\n",
    "#         \"tm_15h\",\n",
    "#         \"tm_16h\",\n",
    "#         \"tm_17h\",\n",
    "#         \"tm_18h\",\n",
    "#         \"tm_19h\",\n",
    "#         \"tm_20h\",\n",
    "#         \"tm_21h\",\n",
    "#         \"tm_22h\",\n",
    "#         \"tm_23h\",\n",
    "#         \"tm_24h\",\n",
    "#         \"tm_48h\",\n",
    "#         \"tm_72h\",\n",
    "#         \"tm_96h\",\n",
    "#         \"tm_120h\",\n",
    "#         \"tm_144h\",\n",
    "#         \"tm_168h\",\n",
    "#         \"tm_336h\",\n",
    "#         \"tm_504h\",\n",
    "#         \"tm_672h\",\n",
    "#         \"tm_840h\",\n",
    "#         \"tm_1008h\",\n",
    "#         \"tm_1176h\",\n",
    "#         \"tm_1344h\",\n",
    "#         \"tm_2016h\",\n",
    "#         \"tm_2688h\",\n",
    "#         \"tm_3360h\",\n",
    "#         \"tm_4032h\",\n",
    "#         \"tm_4704h\",\n",
    "#         \"tm_5376h\",\n",
    "#         \"tm_6048h\",\n",
    "#         \"tm_6720h\",\n",
    "#         \"tm_7392h\",\n",
    "#         \"tm_8064h\",\n",
    "#     ]\n",
    "#     # TARGET = \"modified_target\"\n",
    "#     TARGET = \"target\"\n",
    "\n",
    "#     X_train = train[FEATURES]\n",
    "#     y_train = train[TARGET]\n",
    "\n",
    "#     X_test = test[FEATURES]\n",
    "#     y_test = test[TARGET]\n",
    "\n",
    "#     reg.fit(\n",
    "#         X_train,\n",
    "#         y_train,\n",
    "#         eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "#         verbose=20,\n",
    "#     )\n",
    "\n",
    "#     y_pred = reg.predict(X_test)\n",
    "#     preds.append(y_pred)\n",
    "#     score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#     scores.append(score)\n",
    "\n",
    "# hours_ago = (\n",
    "#     [i for i in range(1, 25)]\n",
    "#     + [24 * i for i in range(2, 8)]\n",
    "#     + [168 * i for i in range(2, 9)]\n",
    "#     + [672 * i for i in range(3, 13)]\n",
    "# )\n",
    "# for h in hours_ago:\n",
    "#     df[f\"t_{h}h\"] = df[\"target\"].shift(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a59dba-58ea-4b29-a6b0-533e7fe0be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(35, 30))\n",
    "\n",
    "# sns.heatmap(df_hours.corr(), annot=True, cmap=\"Blues\", fmt=\".1f\")\n",
    "# # plt.figure(figsize=(25, 25))\n",
    "# plt.show()\n",
    "# # numeric_only=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790fd79-1e77-4e6f-bb8d-af83f47a57cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sort_index().sort_values(\n",
    "#     [\"county\", \"is_business\", \"product_type\", \"is_consumption\"],\n",
    "#     kind=\"mergesort\",\n",
    "# )\n",
    "# df.sort_index()\n",
    "# tss = TimeSeriesSplit(n_splits=3, test_size=300_000)\n",
    "\n",
    "# a = {}\n",
    "# for i in range(1000):\n",
    "#     x = 0\n",
    "#     for j in range(20):\n",
    "#         x += np.random.choice([-1, 1])\n",
    "#     a[x] = a.get(x, 0) + 1\n",
    "\n",
    "\n",
    "# sns.barplot(x=list(a.keys()), y=list(a.values()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fc3653-4435-4e20-bee9-4da67b4ea8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min(data.keys())\n",
    "# max(data.keys())\n",
    "# len(data.keys())\n",
    "# {k: 0 for (k, 0) in range(min(data.keys()), max(data.keys())) if not in data.keys()}\n",
    "# {k: v*2 for (k,v) in dict1.items()}\n",
    "# {key:value for (key,value) in dictonary.items()}\n",
    "# zip()\n",
    "\n",
    "# for train_idx, val_idx in tss.split(df):\n",
    "# print('1 train:', train_idx)\n",
    "# display(df.iloc[train_idx].tail(5))\n",
    "# print('1 val:', val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76417d13-25db-4e88-9af6-04d9e23b6afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tss = TimeSeriesSplit(n_splits=3, test_size=300_000)\n",
    "# df = df.sort_index()\n",
    "\n",
    "# fig, axs = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "# fold = 0\n",
    "\n",
    "# for train_idx, val_idx in tss.split(df):\n",
    "#     train = df.iloc[train_idx]\n",
    "#     test = df.iloc[val_idx]\n",
    "#     train[\"modified_target\"].plot(\n",
    "#         ax=axs[fold],\n",
    "#         label=\"Training Set\",\n",
    "#         title=f\"Data Train/Test Split Fold {fold}\",\n",
    "#     )\n",
    "#     test[\"modified_target\"].plot(ax=axs[fold], label=\"Test Set\")\n",
    "#     axs[fold].axvline(test.index.min(), color=\"black\", ls=\"--\")\n",
    "#     fold += 1\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4637896-c557-496a-bad6-0f7734fa9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold = 0\n",
    "# preds = []\n",
    "# scores = []\n",
    "# for train_idx, val_idx in tss.split(df):\n",
    "#     train = df.iloc[train_idx]\n",
    "#     test = df.iloc[val_idx]\n",
    "\n",
    "#     reg = XGBRegressor(\n",
    "#         n_estimators=2000,\n",
    "#         early_stopping_rounds=50,\n",
    "#         objective=\"reg:squarederror\",\n",
    "#         enable_categorical=True,\n",
    "#         eval_metric=\"mae\",\n",
    "#         # max_depth=3,\n",
    "#         learning_rate=0.01,\n",
    "#         random_state=RAND,\n",
    "#     )\n",
    "#     FEATURES = [\n",
    "#         \"county\",\n",
    "#         \"is_business\",\n",
    "#         \"product_type\",\n",
    "#         # 'target',\n",
    "#         \"is_consumption\",\n",
    "#         # 'data_block_id',\n",
    "#         # 'row_id',\n",
    "#         # 'prediction_unit_id',\n",
    "#         \"hour\",\n",
    "#         \"day_of_week\",\n",
    "#         \"day\",\n",
    "#         \"week_of_year\",\n",
    "#         \"month\",\n",
    "#         \"quarter\",\n",
    "#         \"year\",\n",
    "#         # 'modified_target',\n",
    "#     ]\n",
    "#     TARGET = \"modified_target\"\n",
    "\n",
    "#     X_train = train[FEATURES]\n",
    "#     y_train = train[TARGET]\n",
    "\n",
    "#     X_test = test[FEATURES]\n",
    "#     y_test = test[TARGET]\n",
    "\n",
    "#     reg.fit(\n",
    "#         X_train,\n",
    "#         y_train,\n",
    "#         eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "#         verbose=20,\n",
    "#     )\n",
    "\n",
    "#     y_pred = reg.predict(X_test)\n",
    "#     preds.append(y_pred)\n",
    "#     score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#     scores.append(score)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
