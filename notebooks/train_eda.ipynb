{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d6b9c47-d0d8-4101-9f91-5ee2f0752041",
   "metadata": {},
   "source": [
    "# 1. Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f8e0aa-e4c4-43a5-aedb-02783adc467e",
   "metadata": {},
   "source": [
    "Data description sourced from the Kaggle competition page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a7d74-e3b1-4955-8eec-a3d7cab79fcd",
   "metadata": {},
   "source": [
    "### train.csv\n",
    "- `county` - An ID code for the county.\n",
    "- `is_business` - Boolean for whether or not the prosumer is a business.\n",
    "- `product_type` - ID code with the following mapping of codes to contract types: `{0: \"Combined\", 1: \"Fixed\", 2: \"General service\", 3: \"Spot\"}`.\n",
    "- `target` - The consumption or production amount for the relevant segment for the hour. The segments are defined by the `county`, `is_business`, and `product_type`.\n",
    "- `is_consumption` - Boolean for whether or not this row's target is consumption or production.\n",
    "- `datetime` - The Estonian time in EET (UTC+2) / EEST (UTC+3).\n",
    "- `data_block_id` - All rows sharing the same `data_block_id` will be available at the same forecast time. This is a function of what information is available when forecasts are actually made, at 11 AM each morning. For example, if the forecast weather `data_block_id` for predictins made on October 31st is 100 then the historic weather `data_block_id` for October 31st will be 101 as the historic weather data is only actually available the next day.\n",
    "- `row_id` - A unique identifier for the row.\n",
    "- `prediction_unit_id` - A unique identifier for the `county`, `is_business`, and `product_type` combination. *New prediction units can appear or disappear in the test set*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947b2733-ba9e-4bf5-bf78-6da083ca07a9",
   "metadata": {},
   "source": [
    "### gas_prices.csv\n",
    "\n",
    "- `origin_date` - The date when the day-ahead prices became available.\n",
    "- `forecast_date` - The date when the forecast prices should be relevant.\n",
    "- `[lowest/highest]_price_per_mwh` - The lowest/highest price of natural gas that on the day ahead market that trading day, in Euros per megawatt hour equivalent.\n",
    "- `data_block_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc39fed-e77a-44ad-ad57-d280adc83753",
   "metadata": {},
   "source": [
    "### client.csv\n",
    "- `product_type`\n",
    "- `county` - An ID code for the county. See `county_id_to_name_map.json` for the mapping of ID codes to county names.\n",
    "- `eic_count` - The aggregated number of consumption points (EICs - European Identifier Code).\n",
    "- `installed_capacity` - Installed photovoltaic solar panel capacity in kilowatts.\n",
    "- `is_business` - Boolean for whether or not the prosumer is a business.\n",
    "- `date`\n",
    "- `data_block_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c979aa5-2ad4-4541-a881-01ef1712c97d",
   "metadata": {},
   "source": [
    "### electricity_prices.csv\n",
    "- `origin_date`\n",
    "- `forecast_date` - Represents the start of the 1-hour period when the price is valid\n",
    "- `euros_per_mwh` - The price of electricity on the day ahead markets in euros per megawatt hour.\n",
    "- `data_block_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a73a1c7-c995-4b32-a389-aaef90094133",
   "metadata": {},
   "source": [
    "### forecast_weather.csv\n",
    "Weather forecasts that would have been available at prediction time. Sourced from the <u>[European Centre for Medium-Range Weather Forecasts](https://codes.ecmwf.int/grib/param-db/?filter=grib2)</u>.\n",
    "\n",
    "- `[latitude/longitude]` - The coordinates of the weather forecast.\n",
    "- `origin_datetime` - The timestamp of when the forecast was generated.\n",
    "- `hours_ahead` - The number of hours between the forecast generation and the forecast weather. Each forecast covers 48 hours in total.\n",
    "- `temperature` - The air temperature at 2 meters above ground in degrees Celsius. Estimated for the end of the 1-hour period.\n",
    "- `dewpoint` - The dew point temperature at 2 meters above ground in degrees Celsius. Estimated for the end of the 1-hour period.\n",
    "- `cloudcover_[low/mid/high/total]` - The percentage of the sky covered by clouds in the following altitude bands: 0-2 km, 2-6, 6+, and total. Estimated for the end of the 1-hour period.\n",
    "- `10_metre_[u/v]_wind_component` - The [eastward/northward] component of wind speed measured 10 meters above surface in meters per second. Estimated for the end of the 1-hour period.\n",
    "- `data_block_id`\n",
    "- `forecast_datetime` - The timestamp of the predicted weather. Generated from `origin_datetime` plus `hours_ahead`. This represents the start of the 1-hour period for which weather data are forecasted.\n",
    "- `direct_solar_radiation` - The direct solar radiation reaching the surface on a plane perpendicular to the direction of the Sun accumulated during the hour, in watt-hours per square meter.\n",
    "- `surface_solar_radiation_downwards` - The solar radiation, both direct and diffuse, that reaches a horizontal plane at the surface of the Earth, accumulated during the hour, in watt-hours per square meter.\n",
    "- `snowfall` - Snowfall over hour in units of meters of water equivalent.\n",
    "- `total_precipitation` - The accumulated liquid, comprising rain and snow that falls on Earth's surface over the described hour, in units of meters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a498a9-20bb-4ea3-942d-675b1eafb286",
   "metadata": {},
   "source": [
    "### historical_weather.csv\n",
    "<u>[Historic weather data](https://open-meteo.com/en/docs)</u>.\n",
    "\n",
    "- `datetime` - This represents the start of the 1-hour period for which weather data are measured.\n",
    "- `temperature` - Measured at the end of the 1-hour period.\n",
    "- `dewpoint` - Measured at the end of the 1-hour period.\n",
    "- `rain` - Different from the forecast conventions. The rain from large scale weather systems of the hour in millimeters.\n",
    "- `snowfall` - Different from the forecast conventions. Snowfall over the hour in centimeters.\n",
    "- `surface_pressure` - The air pressure at surface in hectopascals.\n",
    "- `cloudcover_[low/mid/high/total]` - Different from the forecast conventions. Cloud cover at 0-3 km, 3-8, 8+, and total.\n",
    "- `windspeed_10m` - Different from the forecast conventions. The wind speed at 10 meters above ground in meters per second.\n",
    "- `winddirection_10m` - Different from the forecast conventions. The wind direction at 10 meters above ground in degrees.\n",
    "- `shortwave_radiation` - Different from the forecast conventions. The global horizontal irradiation in watt-hours per square meter.\n",
    "- `direct_solar_radiation`\n",
    "- `diffuse_radiation` - Different from the forecast conventions. The diffuse solar irradiation in watt-hours per square meter.\n",
    "- `[latitude/longitude]` - The coordinates of the weather station.\n",
    "- `data_block_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e91539-52f2-4918-a49c-597e20e151c4",
   "metadata": {},
   "source": [
    "# 2. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8694e6f-4c39-4f4c-938a-d919b4fa6397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import colorcet as cc\n",
    "import geopandas as gpd\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mtransforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from matplotlib.dates import DateFormatter, MonthLocator\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from pandas.core.groupby.generic import DataFrameGroupBy\n",
    "from shapely.geometry import shape\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f25ca-5e4f-4031-a941-c597d861d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND = 10\n",
    "RAW_DATA = \"../raw_data/\"\n",
    "\n",
    "train_df = pd.read_csv(f\"{RAW_DATA}train.csv\")\n",
    "gas_prices_df = pd.read_csv(f\"{RAW_DATA}gas_prices.csv\")\n",
    "client_df = pd.read_csv(f\"{RAW_DATA}client.csv\")\n",
    "electricity_prices_df = pd.read_csv(f\"{RAW_DATA}electricity_prices.csv\")\n",
    "forecast_weather_df = pd.read_csv(f\"{RAW_DATA}forecast_weather.csv\")\n",
    "historical_weather_df = pd.read_csv(f\"{RAW_DATA}historical_weather.csv\")\n",
    "station_county_mapping = pd.read_csv(\n",
    "    f\"{RAW_DATA}weather_station_to_county_mapping.csv\"\n",
    ")\n",
    "county_id_to_name_map = pd.read_json(\n",
    "    f\"{RAW_DATA}county_id_to_name_map.json\",\n",
    "    typ=\"series\",\n",
    ").str.capitalize()\n",
    "\n",
    "with open(\"../additional_data/estonia.geojson\", \"r\", encoding=\"utf-8\") as f:\n",
    "    estonia_geojson = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f971b-a00d-4c26-a23c-dfdeb274f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_DICT = {\n",
    "    \"train_df\": train_df,\n",
    "    \"gas_prices_df\": gas_prices_df,\n",
    "    \"client_df\": client_df,\n",
    "    \"electricity_prices_df\": electricity_prices_df,\n",
    "    \"forecast_weather_df\": forecast_weather_df,\n",
    "    \"historical_weather_df\": historical_weather_df,\n",
    "}\n",
    "CATEGORICAL_DICT = {\n",
    "    \"county\": county_id_to_name_map,\n",
    "    \"is_business\": {0: \"not_business\", 1: \"business\"},\n",
    "    \"is_consumption\": {0: \"production\", 1: \"consumption\"},\n",
    "    \"product_type\": {\n",
    "        0: \"combined\",\n",
    "        1: \"fixed\",\n",
    "        2: \"general_service\",\n",
    "        3: \"spot\",\n",
    "    },\n",
    "}\n",
    "COLORS_LIST = (\n",
    "    cc.glasbey[:4]\n",
    "    + [cc.glasbey[8]]\n",
    "    + cc.glasbey[5:8]\n",
    "    + [cc.glasbey[4]]\n",
    "    + [cc.glasbey[12]]\n",
    "    + cc.glasbey[10:12]\n",
    "    + [cc.glasbey[9]]\n",
    "    + cc.glasbey[13:16]\n",
    ")\n",
    "PALETTE = sns.color_palette(COLORS_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a70352-098d-4da4-aae9-3522943f0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\n",
    "    \"display.float_format\",\n",
    "    lambda x: f\"{x:.2e}\" if abs(x) < 0.01 and x != 0 else f\"{x:.2f}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c67c46a-8dd3-4bec-87b8-001cfef3a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b065e0a-6cbd-4f8b-9c90-c4b66e8a5928",
   "metadata": {},
   "source": [
    "# 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9e7dc-7191-4882-8da4-58fe3030a175",
   "metadata": {},
   "source": [
    "From description:\n",
    "- `datetime` - The Estonian time in EET (UTC+2) / EEST (UTC+3).\n",
    "- `data_block_id` - All rows sharing the same `data_block_id` will be available at the same forecast time. This is a function of what information is available when forecasts are actually made, at 11 AM each morning. For example, if the forecast weather `data_block_id` for predictins made on October 31st is 100 then the historic weather `data_block_id` for October 31st will be 101 as the historic weather data is only actually available the next day.\n",
    "- `row_id` - A unique identifier for the row.\n",
    "- `prediction_unit_id` - A unique identifier for the `county`, `is_business`, and `product_type` combination. *New prediction units can appear or disappear in the test set*.\n",
    "\n",
    "Also competition host <u>[provided](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers/discussion/455833)</u> this scheme:\n",
    "***\n",
    "Letâ€™s say we are on day D at 11am. We want to predict next day D+1 net consumption from 00 to 23 for every hours.\n",
    "<table style=\"border: 1px solid black; border-collapse: collapse; width: 100%;\">\n",
    "  <tr>\n",
    "    <th style=\"border: 1px solid black;\">Category</th>\n",
    "    <th style=\"border: 1px solid black;\">Weather forecast</th>\n",
    "    <th style=\"border: 1px solid black;\">Historical weather</th>\n",
    "    <th style=\"border: 1px solid black;\">Historical consumption and production / Client data</th>\n",
    "    <th style=\"border: 1px solid black;\">Electricity prices</th>\n",
    "    <th style=\"border: 1px solid black;\">Gas prices</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid black;\">Last available data</td>\n",
    "    <td style=\"border: 1px solid black;\">Forecast for every hours of D and D+1 (published on D)</td>\n",
    "    <td style=\"border: 1px solid black;\">Every hours until day D, 10 am</td>\n",
    "    <td style=\"border: 1px solid black;\">Every hours of Day D-1</td>\n",
    "    <td style=\"border: 1px solid black;\">Every hours of day D (published on D-1)</td>\n",
    "    <td style=\"border: 1px solid black;\">Data for day D (published on D-1)</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Prices are published everyday at 2 pm (so after 11 am), that is we do not have D+1 prices.\n",
    "The data_block_id already reflects this timeline of availability of the data. There is no need to apply additional lag if joining on data_block_id.\n",
    "***\n",
    "\n",
    "Later, I will explore whether there are any discrepancies in the correlations between `data_block_id` and `datetime`, or between `prediction_unit_id` and the `categorical features`. For now, I will analyze the data by:\n",
    "1. Checking all dataframes using `describe()` and `info()`.\n",
    "2. Verifying the presence of missing values or duplicates.\n",
    "\n",
    "I will use the following functions for initial analysis and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f1f9d-7938-4863-a3ee-85b470c4deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_right_filled_header(text: str) -> None:\n",
    "    \"\"\"\n",
    "    Prints the provided header text followed by \">\" characters, filling\n",
    "    the line up to 100 characters.\n",
    "    \"\"\"\n",
    "    total_length = 100\n",
    "    text = text.strip()\n",
    "    print(\"\\n\" + text + \" \" + \">\" * (total_length - len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d008594e-8f65-4e76-a9bb-82ae23bb6650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_size(df: pd.DataFrame) -> np.int64:\n",
    "    \"Return total size of the dataframe in megabytes.\"\n",
    "    return df.memory_usage().sum() // (1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d7f167-e308-4364-bec0-169c0f275738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_summary(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Summarize a dataframe with combined information from df.info() and\n",
    "    df.describe(). Additionally, calculate the maximum length of the\n",
    "    decimal part for numpy.float64 and numpy.float32 columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The input dataframe to summarize.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A combined summary dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    column_info = {\n",
    "        \"column\": df.columns,\n",
    "        \"not_na_count\": [],\n",
    "        \"dtype\": df.dtypes.values,\n",
    "        \"size_mb\": (df.memory_usage().div(1024**2).round(2))[1:],\n",
    "        \"max_dec_len\": [],\n",
    "    }\n",
    "\n",
    "    for column in df.columns:\n",
    "        col_data = df[column]\n",
    "        column_info[\"not_na_count\"].append(col_data.notna().sum())\n",
    "\n",
    "        if (not isinstance(col_data.dtype, pd.CategoricalDtype)) and (\n",
    "            np.issubdtype(col_data.dtype, np.float64)\n",
    "            or np.issubdtype(col_data.dtype, np.float32)\n",
    "        ):\n",
    "            decimal_len = (\n",
    "                col_data.dropna()\n",
    "                .apply(lambda x: len(str(x).split(\".\")[1]))\n",
    "                .max()\n",
    "            )\n",
    "            column_info[\"max_dec_len\"].append(decimal_len)\n",
    "        else:\n",
    "            column_info[\"max_dec_len\"].append(-1)\n",
    "\n",
    "    df = pd.merge(\n",
    "        pd.DataFrame(\n",
    "            data=column_info,\n",
    "        ),\n",
    "        df.describe(include=\"all\").drop(\"count\").T.reset_index(names=\"column\"),\n",
    "        on=[\"column\"],\n",
    "    )\n",
    "\n",
    "    first_columns = [\n",
    "        \"column\",\n",
    "        \"dtype\",\n",
    "        \"size_mb\",\n",
    "        \"max_dec_len\",\n",
    "        \"min\",\n",
    "        \"max\",\n",
    "    ]\n",
    "    other_columns = [\n",
    "        column for column in df.columns if column not in first_columns\n",
    "    ]\n",
    "\n",
    "    return df.loc[:, first_columns + other_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22058a79-8e71-4372-9b74-a4f77b4c2107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_show_info(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Print the number of dataframe NaNs, the count of duplicated rows\n",
    "    and display a summary of the dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    print_right_filled_header(\"HEAD\")\n",
    "    display(df.head())\n",
    "\n",
    "    print_right_filled_header(\"TAIL\")\n",
    "    display(df.tail())\n",
    "\n",
    "    print_right_filled_header(\"MISSING VALUES\")\n",
    "    nan_counts = df.isna().sum()\n",
    "    nan_series = nan_counts[nan_counts > 0]\n",
    "    if nan_series.empty:\n",
    "        print(\"No missing values.\")\n",
    "    else:\n",
    "        display(nan_series)\n",
    "\n",
    "    print_right_filled_header(\"DUPLICATES\")\n",
    "    dup_counts = df.duplicated().sum()\n",
    "    if dup_counts:\n",
    "        display(f\"Total duplicated rows: {dup_counts}\")\n",
    "    else:\n",
    "        print(\"No duplicate rows.\")\n",
    "\n",
    "    print_right_filled_header(\"TOTAL SIZE\")\n",
    "    print(f\"Total DataFrame size: {total_size(df)} MB.\")\n",
    "\n",
    "    print_right_filled_header(\"SUMMARY\")\n",
    "    display(columns_summary(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6c2409-d07e-4233-8f03-e87f200726df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_mapper(\n",
    "    df: pd.DataFrame,\n",
    "    values_mapper: dict,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Map categorical columns in the dataframe to their corresponding\n",
    "    values based on the provided mapper and convert these columns to\n",
    "    categorical type.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe to process.\n",
    "    values_mapper : dict\n",
    "        A dictionary where keys are column names, and values are\n",
    "        mapping dictionaries.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Modified dataframe with specified columns mapped to their\n",
    "        categorical values.\n",
    "    \"\"\"\n",
    "    for key, value in values_mapper.items():\n",
    "        if key in df.columns:\n",
    "            df[key] = df[key].map(value).astype(\"category\")\n",
    "        else:\n",
    "            print(f\"Column '{key}' not found in dataframe, skipping.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec08694b-0ac5-4b58-99e2-e9231b4a4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mismatched_indices_check(\n",
    "    date_diff: pd.Series,\n",
    "    id_diff: pd.Series,\n",
    "    difference: np.float64,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Check if rows with an n-day difference in the date_diff have\n",
    "    mismatched indices with id_diff rows that have a difference of n\n",
    "    and print it.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\n",
    "        f\"Difference {difference}: \",[\n",
    "            \"no mismatches\",\n",
    "            \"indices mismatch detected\"][\n",
    "        int(np.any(\n",
    "            date_diff[date_diff == pd.Timedelta(difference, \"day\")]\n",
    "            .index\n",
    "            != id_diff[id_diff == difference].index))],\n",
    "        \".\",\n",
    "        sep=\"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c11981-b592-495d-8765-2cf853d62efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_groups(dfgb: DataFrameGroupBy, column: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Combine values of the specified column in each subgroup into\n",
    "    tuples, compare these tuples within each group, and return a\n",
    "    pd.Series of boolean values indicating whether each tuple is a duplicate.\n",
    "    \"\"\"\n",
    "    return dfgb[column].agg(tuple).duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c0854a-1cf5-4f6f-af67-f220ea830592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle_label(color: tuple | str, label: str) -> Line2D:\n",
    "    \"\"\"\n",
    "    Create a handle for legend with a circular marker with specified\n",
    "    color and label.\n",
    "    \"\"\"\n",
    "    return Line2D(\n",
    "        [],\n",
    "        [],\n",
    "        color=color,\n",
    "        marker=\"o\",\n",
    "        linestyle=\"None\",\n",
    "        markersize=8,\n",
    "        label=label,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2989cbfe-a597-461b-8fb9-70beb445d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_locations(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return (\n",
    "        df[[\"latitude\", \"longitude\"]]\n",
    "        .drop_duplicates()\n",
    "        .sort_values([\"latitude\", \"longitude\"], ignore_index=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d370cf86-2a74-4eb8-ae1a-e76832270193",
   "metadata": {},
   "source": [
    "## train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26fa8d-480e-4216-814e-186a8ba13a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HEAD >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>target</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>datetime</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>prediction_unit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96.59</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17.31</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   county  is_business  product_type  target  is_consumption  \\\n",
       "0       0            0             1    0.71               0   \n",
       "1       0            0             1   96.59               1   \n",
       "2       0            0             2    0.00               0   \n",
       "3       0            0             2   17.31               1   \n",
       "4       0            0             3    2.90               0   \n",
       "\n",
       "              datetime  data_block_id  row_id  prediction_unit_id  \n",
       "0  2021-09-01 00:00:00              0       0                   0  \n",
       "1  2021-09-01 00:00:00              0       1                   0  \n",
       "2  2021-09-01 00:00:00              0       2                   1  \n",
       "3  2021-09-01 00:00:00              0       3                   1  \n",
       "4  2021-09-01 00:00:00              0       4                   2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TAIL >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>target</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>datetime</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>prediction_unit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018347</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>197.23</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-31 23:00:00</td>\n",
       "      <td>637</td>\n",
       "      <td>2018347</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018348</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-31 23:00:00</td>\n",
       "      <td>637</td>\n",
       "      <td>2018348</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018349</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.40</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-31 23:00:00</td>\n",
       "      <td>637</td>\n",
       "      <td>2018349</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018350</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-31 23:00:00</td>\n",
       "      <td>637</td>\n",
       "      <td>2018350</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018351</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>196.24</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-31 23:00:00</td>\n",
       "      <td>637</td>\n",
       "      <td>2018351</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         county  is_business  product_type  target  is_consumption  \\\n",
       "2018347      15            1             0  197.23               1   \n",
       "2018348      15            1             1    0.00               0   \n",
       "2018349      15            1             1   28.40               1   \n",
       "2018350      15            1             3    0.00               0   \n",
       "2018351      15            1             3  196.24               1   \n",
       "\n",
       "                    datetime  data_block_id   row_id  prediction_unit_id  \n",
       "2018347  2023-05-31 23:00:00            637  2018347                  64  \n",
       "2018348  2023-05-31 23:00:00            637  2018348                  59  \n",
       "2018349  2023-05-31 23:00:00            637  2018349                  59  \n",
       "2018350  2023-05-31 23:00:00            637  2018350                  60  \n",
       "2018351  2023-05-31 23:00:00            637  2018351                  60  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MISSING VALUES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target    528\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DUPLICATES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No duplicate rows.\n",
      "\n",
      "TOTAL SIZE >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Total DataFrame size: 138 MB.\n",
      "\n",
      "SUMMARY >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>max_dec_len</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>not_na_count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>county</td>\n",
       "      <td>int64</td>\n",
       "      <td>15.40</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2018352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.30</td>\n",
       "      <td>4.78</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is_business</td>\n",
       "      <td>int64</td>\n",
       "      <td>15.40</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2018352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>product_type</td>\n",
       "      <td>int64</td>\n",
       "      <td>15.40</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2018352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>target</td>\n",
       "      <td>float64</td>\n",
       "      <td>15.40</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15480.27</td>\n",
       "      <td>2017824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>274.86</td>\n",
       "      <td>909.50</td>\n",
       "      <td>0.38</td>\n",
       "      <td>31.13</td>\n",
       "      <td>180.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is_consumption</td>\n",
       "      <td>int64</td>\n",
       "      <td>15.40</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2018352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>datetime</td>\n",
       "      <td>object</td>\n",
       "      <td>15.40</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018352</td>\n",
       "      <td>15312</td>\n",
       "      <td>2022-11-27 12:00:00</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data_block_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>15.40</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>637.00</td>\n",
       "      <td>2018352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321.87</td>\n",
       "      <td>182.63</td>\n",
       "      <td>166.00</td>\n",
       "      <td>323.00</td>\n",
       "      <td>479.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>row_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>15.40</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2018351.00</td>\n",
       "      <td>2018352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1009175.50</td>\n",
       "      <td>582648.18</td>\n",
       "      <td>504587.75</td>\n",
       "      <td>1009175.50</td>\n",
       "      <td>1513763.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>prediction_unit_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>15.40</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68.00</td>\n",
       "      <td>2018352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.05</td>\n",
       "      <td>19.59</td>\n",
       "      <td>16.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               column    dtype  size_mb  max_dec_len  min        max  \\\n",
       "0              county    int64    15.40           -1 0.00      15.00   \n",
       "1         is_business    int64    15.40           -1 0.00       1.00   \n",
       "2        product_type    int64    15.40           -1 0.00       3.00   \n",
       "3              target  float64    15.40            3 0.00   15480.27   \n",
       "4      is_consumption    int64    15.40           -1 0.00       1.00   \n",
       "5            datetime   object    15.40           -1  NaN        NaN   \n",
       "6       data_block_id    int64    15.40           -1 0.00     637.00   \n",
       "7              row_id    int64    15.40           -1 0.00 2018351.00   \n",
       "8  prediction_unit_id    int64    15.40           -1 0.00      68.00   \n",
       "\n",
       "   not_na_count unique                  top freq       mean       std  \\\n",
       "0       2018352    NaN                  NaN  NaN       7.30      4.78   \n",
       "1       2018352    NaN                  NaN  NaN       0.54      0.50   \n",
       "2       2018352    NaN                  NaN  NaN       1.90      1.08   \n",
       "3       2017824    NaN                  NaN  NaN     274.86    909.50   \n",
       "4       2018352    NaN                  NaN  NaN       0.50      0.50   \n",
       "5       2018352  15312  2022-11-27 12:00:00  138        NaN       NaN   \n",
       "6       2018352    NaN                  NaN  NaN     321.87    182.63   \n",
       "7       2018352    NaN                  NaN  NaN 1009175.50 582648.18   \n",
       "8       2018352    NaN                  NaN  NaN      33.05     19.59   \n",
       "\n",
       "        25%        50%        75%  \n",
       "0      3.00       7.00      11.00  \n",
       "1      0.00       1.00       1.00  \n",
       "2      1.00       2.00       3.00  \n",
       "3      0.38      31.13     180.21  \n",
       "4      0.00       0.50       1.00  \n",
       "5       NaN        NaN        NaN  \n",
       "6    166.00     323.00     479.00  \n",
       "7 504587.75 1009175.50 1513763.25  \n",
       "8     16.00      33.00      50.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_show_info(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276e470-db61-40b8-b140-9d06e4661c6a",
   "metadata": {},
   "source": [
    "- There are a few missing values (528/2,018,352 < 0.1%) and no duplicates in the dataframe. Only the `target` feature has missing values.\n",
    "- The categorical features `county`, `is_business`, `product_type`, and `is_consumption` can be converted to the categorical data type. Their values can be renamed to improve clarity and understanding.\n",
    "- The `target` feature can be converted to `float32` because its values range from 0.0 to 15,480.27, and the standard deviation (910.20) is relatively large compared to the mean (274.86), indicating a wide distribution of values. Given the dataset size (2,017,824 records), the precision of the fractional part becomes less significant, and `float32` provides adequate precision while reducing memory usage.\n",
    "- The `datetime` feature can be converted to `datetime64[ns]` for proper handling of data.\n",
    "- The `data_block_id` feature can be converted to `uint16` (range: 0 through 65,535) as its maximum value is small.\n",
    "- The `row_id` feature is similar to the index values in the current default sorting. For now, it can be converted to `uint32` (range: 0 through 4,294,967,295) as its range fits well within this data type, and the use of `int64` is unnecessary because it supports negative numbers, which are irrelevant in this case.\n",
    "- The `prediction_unit_id` feature can be converted to `uint8` (range: 0 through 255). Although new combinations may appear in the future, this data type is sufficient to uniquely represent all future combinations of current county, is_business, and product_type (16 * 2 * 4 = 96)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116376df-986a-4875-bbaf-cea7a4691065",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a7bef3-191a-4c37-92ab-2b54f5aaa4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after transformation: 44 MB.\n"
     ]
    }
   ],
   "source": [
    "# Rename to avoid confusion and improve readability\n",
    "train_df = categorical_mapper(train_df, CATEGORICAL_DICT)\n",
    "\n",
    "# Change data types to reduce memory usage\n",
    "train_df = train_df.astype(\n",
    "    {\n",
    "        \"target\": \"float32\",\n",
    "        \"data_block_id\": \"uint16\",\n",
    "        \"row_id\": \"uint32\",\n",
    "        \"prediction_unit_id\": \"uint8\",\n",
    "        \"datetime\": \"datetime64[ns]\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Size after transformation: {total_size(train_df)} MB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a38920-b145-4834-b3ee-4e6d1c2cf9c8",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73cb832-7f59-466f-8bf8-c3f29cca04f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>target</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>datetime</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>prediction_unit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178938</th>\n",
       "      <td>Harjumaa</td>\n",
       "      <td>not_business</td>\n",
       "      <td>fixed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>production</td>\n",
       "      <td>2021-10-31 03:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>178938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178939</th>\n",
       "      <td>Harjumaa</td>\n",
       "      <td>not_business</td>\n",
       "      <td>fixed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>consumption</td>\n",
       "      <td>2021-10-31 03:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>178939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178940</th>\n",
       "      <td>Harjumaa</td>\n",
       "      <td>not_business</td>\n",
       "      <td>general_service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>production</td>\n",
       "      <td>2021-10-31 03:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>178940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178941</th>\n",
       "      <td>Harjumaa</td>\n",
       "      <td>not_business</td>\n",
       "      <td>general_service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>consumption</td>\n",
       "      <td>2021-10-31 03:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>178941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178942</th>\n",
       "      <td>Harjumaa</td>\n",
       "      <td>not_business</td>\n",
       "      <td>spot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>production</td>\n",
       "      <td>2021-10-31 03:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>178942</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          county   is_business     product_type  target is_consumption  \\\n",
       "178938  Harjumaa  not_business            fixed     NaN     production   \n",
       "178939  Harjumaa  not_business            fixed     NaN    consumption   \n",
       "178940  Harjumaa  not_business  general_service     NaN     production   \n",
       "178941  Harjumaa  not_business  general_service     NaN    consumption   \n",
       "178942  Harjumaa  not_business             spot     NaN     production   \n",
       "\n",
       "                  datetime  data_block_id  row_id  prediction_unit_id  \n",
       "178938 2021-10-31 03:00:00             60  178938                   0  \n",
       "178939 2021-10-31 03:00:00             60  178939                   0  \n",
       "178940 2021-10-31 03:00:00             60  178940                   1  \n",
       "178941 2021-10-31 03:00:00             60  178941                   1  \n",
       "178942 2021-10-31 03:00:00             60  178942                   2  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display rows with missing values from the dataframe\n",
    "train_df[train_df.isna().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540205db-12b9-4799-9270-d659285802f8",
   "metadata": {},
   "source": [
    "The `datetime` values for rows with missing target values start from '2021-10-31 03:00:00', rather than from '2021-09-01 00:00:00'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abafc092-d591-48f0-b690-f6f042dd8a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2021-10-31 03:00:00', '2022-03-27 03:00:00', '2022-10-30 03:00:00',\n",
       " '2023-03-26 03:00:00']\n",
       "Length: 4, dtype: datetime64[ns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create array with timestamps corresponding to rows with missing\n",
    "# target values\n",
    "na_datetimes = train_df[train_df.isna().any(axis=1)].datetime.unique()\n",
    "na_datetimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5904abf-b0e6-4553-8d34-29876715901e",
   "metadata": {},
   "source": [
    "All missing values correspond to the start or end of daylight saving time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879cdba-8ed4-4dc5-92e7-7ff9510f7b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that all values for these timestamps are missing\n",
    "train_df.isna().values.sum() == (\n",
    "    train_df.loc[\n",
    "        train_df[\"datetime\"].isin(na_datetimes), [\"target\"]\n",
    "    ].shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6496441-199b-4f92-88de-130257f60e99",
   "metadata": {},
   "source": [
    "All target values at these timestamps are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d4c88b-6973-4caf-86d4-22fc6e56d005",
   "metadata": {},
   "source": [
    "### Consistency and Relationship Validation\n",
    "#### Row Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165075d2-d32b-47c1-81d3-877f37ac378f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if row_id values are equal to index values\n",
    "(train_df[\"row_id\"] != train_df.index).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c933c4-19d6-431c-a0d4-f573a5583a99",
   "metadata": {},
   "source": [
    "All `row_id` values are equal to index values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2f0e13-ea49-40f3-bf67-f90ab25c624d",
   "metadata": {},
   "source": [
    "#### Datetime and data_block_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f268a-47c2-44a4-b0a0-ffb3b8e65b20",
   "metadata": {},
   "source": [
    "For predictions made for day D + 1, all historical consumption and production data should have `data_block_id` values equal to D - 1. This is because the `data_block_id` represents the data available at a specific time. Data for day D is unavailable at the time of prediction, as it corresponds to the current day, and no historical data exists for it yet.\n",
    "\n",
    "To validate this, the `datetime` and `data_block_id` columns require a check to ensure that, in chronological order, both date and ID values progress uniformly. If a single date corresponds to multiple `data_block_id` values, it will be evident because the differences between consecutive rows in these two columns will not be consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21aaedd-2da4-4966-880f-50304a7d8f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime\n",
      "0 days    2017714\n",
      "1 days        637\n",
      "NaT             1\n",
      "Name: count, dtype: int64\n",
      "data_block_id\n",
      "0.00    2017714\n",
      "1.00        637\n",
      "NaN           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create variables to store the differences between the current and\n",
    "# previous row for all rows in datetime and data_block_id\n",
    "train_date_diff = train_df[\"datetime\"].dt.date.diff()\n",
    "train_id_diff = train_df[\"data_block_id\"].diff()\n",
    "\n",
    "# Print unique values to verify that default order reflects sorting\n",
    "# from oldest to newest without skips\n",
    "print(train_date_diff.value_counts(dropna=False))\n",
    "print(train_id_diff.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec5185-1db8-4b0f-ad40-a02158da4c6f",
   "metadata": {},
   "source": [
    "- `NaT` and `NaN` values correspond to the first row in both columns, where no previous row data is available for comparison.\n",
    "- A value of '0' indicates that the current and previous rows belong to the same day.\n",
    "- A value of '1' indicates the transition from one day to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5effd833-7188-40e0-af43-7b4c5a2bf0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference nan: no mismatches.\n",
      "Difference 0.0: no mismatches.\n",
      "Difference 1.0: no mismatches.\n"
     ]
    }
   ],
   "source": [
    "for difference in train_id_diff.unique():\n",
    "    mismatched_indices_check(train_date_diff, train_id_diff, difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5844145-bb47-4d99-9c87-f651c87667ee",
   "metadata": {},
   "source": [
    "The default order of the raw data for this dataframe is sorted by datetime, and the `data_block_id` reflects the actual data availability, with no errors observed in the `datetime` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eb884e-139d-45f0-b097-00b97bfd7db1",
   "metadata": {},
   "source": [
    "#### Categorical Features and Their Identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abbc69f-e0a9-4365-9120-c2ea83e07d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that each combination of county, product_type, and\n",
    "# is_business corresponds to exactly one unique prediction_unit_id\n",
    "(\n",
    "    train_df.groupby(\n",
    "        [\n",
    "            \"county\",\n",
    "            \"product_type\",\n",
    "            \"is_business\",\n",
    "        ],\n",
    "        observed=True,\n",
    "    )[\"prediction_unit_id\"].nunique()\n",
    "    != 1\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d8fe47-e778-438d-9512-c9adfc418174",
   "metadata": {},
   "source": [
    "All combinations of `county`, `is_business`, and `product_type` correspond to a single `prediction_unit_id`, with no errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70137672-8297-45a9-a357-3e0ff989d2ec",
   "metadata": {},
   "source": [
    "## gas_prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f2c74-d559-458c-9a78-5c9e92138fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HEAD >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>lowest_price_per_mwh</th>\n",
       "      <th>highest_price_per_mwh</th>\n",
       "      <th>origin_date</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>45.23</td>\n",
       "      <td>46.32</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-02</td>\n",
       "      <td>45.62</td>\n",
       "      <td>46.29</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-03</td>\n",
       "      <td>45.85</td>\n",
       "      <td>46.40</td>\n",
       "      <td>2021-09-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-04</td>\n",
       "      <td>46.30</td>\n",
       "      <td>46.80</td>\n",
       "      <td>2021-09-03</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-05</td>\n",
       "      <td>46.30</td>\n",
       "      <td>46.58</td>\n",
       "      <td>2021-09-04</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  forecast_date  lowest_price_per_mwh  highest_price_per_mwh origin_date  \\\n",
       "0    2021-09-01                 45.23                  46.32  2021-08-31   \n",
       "1    2021-09-02                 45.62                  46.29  2021-09-01   \n",
       "2    2021-09-03                 45.85                  46.40  2021-09-02   \n",
       "3    2021-09-04                 46.30                  46.80  2021-09-03   \n",
       "4    2021-09-05                 46.30                  46.58  2021-09-04   \n",
       "\n",
       "   data_block_id  \n",
       "0              1  \n",
       "1              2  \n",
       "2              3  \n",
       "3              4  \n",
       "4              5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TAIL >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>lowest_price_per_mwh</th>\n",
       "      <th>highest_price_per_mwh</th>\n",
       "      <th>origin_date</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>29.10</td>\n",
       "      <td>34.10</td>\n",
       "      <td>2023-05-25</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>2023-05-27</td>\n",
       "      <td>28.30</td>\n",
       "      <td>34.10</td>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>2023-05-28</td>\n",
       "      <td>28.10</td>\n",
       "      <td>34.10</td>\n",
       "      <td>2023-05-27</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>2023-05-29</td>\n",
       "      <td>28.16</td>\n",
       "      <td>36.98</td>\n",
       "      <td>2023-05-28</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>2023-05-30</td>\n",
       "      <td>29.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>2023-05-29</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    forecast_date  lowest_price_per_mwh  highest_price_per_mwh origin_date  \\\n",
       "632    2023-05-26                 29.10                  34.10  2023-05-25   \n",
       "633    2023-05-27                 28.30                  34.10  2023-05-26   \n",
       "634    2023-05-28                 28.10                  34.10  2023-05-27   \n",
       "635    2023-05-29                 28.16                  36.98  2023-05-28   \n",
       "636    2023-05-30                 29.00                  34.00  2023-05-29   \n",
       "\n",
       "     data_block_id  \n",
       "632            633  \n",
       "633            634  \n",
       "634            635  \n",
       "635            636  \n",
       "636            637  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MISSING VALUES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No missing values.\n",
      "\n",
      "DUPLICATES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No duplicate rows.\n",
      "\n",
      "TOTAL SIZE >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Total DataFrame size: 0 MB.\n",
      "\n",
      "SUMMARY >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>max_dec_len</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>not_na_count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forecast_date</td>\n",
       "      <td>object</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>637</td>\n",
       "      <td>637</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lowest_price_per_mwh</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>28.10</td>\n",
       "      <td>250.00</td>\n",
       "      <td>637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.04</td>\n",
       "      <td>47.55</td>\n",
       "      <td>60.00</td>\n",
       "      <td>85.21</td>\n",
       "      <td>109.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>highest_price_per_mwh</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>34.00</td>\n",
       "      <td>305.00</td>\n",
       "      <td>637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.75</td>\n",
       "      <td>54.74</td>\n",
       "      <td>67.53</td>\n",
       "      <td>93.47</td>\n",
       "      <td>130.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>origin_date</td>\n",
       "      <td>object</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>637</td>\n",
       "      <td>637</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data_block_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>637.00</td>\n",
       "      <td>637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>319.00</td>\n",
       "      <td>184.03</td>\n",
       "      <td>160.00</td>\n",
       "      <td>319.00</td>\n",
       "      <td>478.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  column    dtype  size_mb  max_dec_len   min    max  \\\n",
       "0          forecast_date   object     0.00           -1   NaN    NaN   \n",
       "1   lowest_price_per_mwh  float64     0.00            2 28.10 250.00   \n",
       "2  highest_price_per_mwh  float64     0.00            2 34.00 305.00   \n",
       "3            origin_date   object     0.00           -1   NaN    NaN   \n",
       "4          data_block_id    int64     0.00           -1  1.00 637.00   \n",
       "\n",
       "   not_na_count unique         top freq   mean    std    25%    50%    75%  \n",
       "0           637    637  2021-09-01    1    NaN    NaN    NaN    NaN    NaN  \n",
       "1           637    NaN         NaN  NaN  95.04  47.55  60.00  85.21 109.00  \n",
       "2           637    NaN         NaN  NaN 107.75  54.74  67.53  93.47 130.74  \n",
       "3           637    637  2021-08-31    1    NaN    NaN    NaN    NaN    NaN  \n",
       "4           637    NaN         NaN  NaN 319.00 184.03 160.00 319.00 478.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_show_info(gas_prices_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb7db5-4144-4ba4-8124-1e8794b88c25",
   "metadata": {},
   "source": [
    "- There are no missing values or duplicates in the dataframe.\n",
    "- The `data_block_id` values start from 1, unlike the `data_block_id` values in train_df, which start from 0. This difference exists because </u>[`[lowest/highest]_price_per_mwh` are end-of-day prices and aren't available in the late morning when forecasts are made](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers/discussion/453355#2515054)</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d22ee4-948f-4d37-a90b-dfe11be0fa14",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ef5dc-7d5f-4f05-b46d-ee52791e3c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after transformation: 0 MB.\n"
     ]
    }
   ],
   "source": [
    "# Change data types to reduce memory usage\n",
    "gas_prices_df = gas_prices_df.astype(\n",
    "    {\n",
    "        \"forecast_date\": \"datetime64[ns]\",\n",
    "        \"lowest_price_per_mwh\": \"float32\",\n",
    "        \"highest_price_per_mwh\": \"float32\",\n",
    "        \"origin_date\": \"datetime64[ns]\",\n",
    "        \"data_block_id\": \"uint16\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Rename to distinct from datetime-like features from other DFs\n",
    "gas_prices_df = gas_prices_df.rename(\n",
    "    columns={\n",
    "        \"forecast_date\": \"gas_forecast_date\",\n",
    "        \"origin_date\": \"gas_origin_date\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Size after transformation: {total_size(gas_prices_df)} MB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c6c68f-f43b-4457-b4b2-caf1379641bc",
   "metadata": {},
   "source": [
    "### Consistency and Relationship Validation\n",
    "#### Origin and forecast dates\n",
    "Due to the strong correlation between the two datetime columns (at least based on the description and a few observed rows), it's necessary to verify if this correlation holds true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b8c99-8b05-4406-8fa4-a13ffe01b079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gas_origin_date\n",
      "1 days    636\n",
      "NaT         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check that each origin date is the next day compared to the previous\n",
    "# one\n",
    "\n",
    "gas_date_diff = gas_prices_df[\"gas_origin_date\"].diff()\n",
    "print(gas_date_diff.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac223506-6fec-481d-9eb8-bc8dfc36cd1b",
   "metadata": {},
   "source": [
    "- Yes, all values are chronological days without skips. The `NaT` value corresponds to the first date, where no previous date exists for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9254055c-50b3-4702-8057-0b5862e6b10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any forecast dates are not exactly one day after origin dates\n",
    "(\n",
    "    gas_prices_df[\"gas_origin_date\"]\n",
    "    + pd.Timedelta(days=1)\n",
    "    != gas_prices_df[\"gas_forecast_date\"]\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f40e67-c764-4985-b86d-904044194ddd",
   "metadata": {},
   "source": [
    "- All `gas_origin_date` values are correct and represent the day before their corresponding `gas_forecast_date` values. This means that correlation between these features is 1, and one of them can likely be deleted.\n",
    "- The raw data in this dataframe is sorted chronologically by datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a83fe-b2d0-4909-96ea-d77ec3d3a3d9",
   "metadata": {},
   "source": [
    "#### Origin date and data_block_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f248ed1-f98b-4c91-aa71-3c3f73073720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_block_id\n",
      "1.00    636\n",
      "NaN       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "gas_id_diff = gas_prices_df[\"data_block_id\"].diff()\n",
    "print(gas_id_diff.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252e0e15-83ad-4f2f-8148-767be995779f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference nan: no mismatches.\n",
      "Difference 1.0: no mismatches.\n"
     ]
    }
   ],
   "source": [
    "for difference in gas_id_diff.unique():\n",
    "    mismatched_indices_check(gas_date_diff, gas_id_diff, difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522bb44a-1e9d-45fd-bf7f-33d8b473820b",
   "metadata": {},
   "source": [
    "- Similar to `gas_origin_date`, the first value is missing, and all subsequent values have a difference of 1. Since the differences are consistent across both columns, it can be concluded that there are no errors between `gas_origin_date` and `data_block_id`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc05598f-23b8-4c4d-9348-195317dc2dba",
   "metadata": {},
   "source": [
    "## client_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de931d3-3a4d-450b-a38c-df9047d00dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HEAD >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type</th>\n",
       "      <th>county</th>\n",
       "      <th>eic_count</th>\n",
       "      <th>installed_capacity</th>\n",
       "      <th>is_business</th>\n",
       "      <th>date</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>952.89</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>166.40</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>688</td>\n",
       "      <td>7207.88</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>400.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1411.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_type  county  eic_count  installed_capacity  is_business  \\\n",
       "0             1       0        108              952.89            0   \n",
       "1             2       0         17              166.40            0   \n",
       "2             3       0        688             7207.88            0   \n",
       "3             0       0          5              400.00            1   \n",
       "4             1       0         43             1411.00            1   \n",
       "\n",
       "         date  data_block_id  \n",
       "0  2021-09-01              2  \n",
       "1  2021-09-01              2  \n",
       "2  2021-09-01              2  \n",
       "3  2021-09-01              2  \n",
       "4  2021-09-01              2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TAIL >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type</th>\n",
       "      <th>county</th>\n",
       "      <th>eic_count</th>\n",
       "      <th>installed_capacity</th>\n",
       "      <th>is_business</th>\n",
       "      <th>date</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41914</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>51</td>\n",
       "      <td>415.60</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-29</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41915</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>161</td>\n",
       "      <td>2035.75</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-29</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41916</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>620.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-29</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41917</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>624.50</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-29</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41918</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>55</td>\n",
       "      <td>2188.20</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-29</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_type  county  eic_count  installed_capacity  is_business  \\\n",
       "41914             1      15         51              415.60            0   \n",
       "41915             3      15        161             2035.75            0   \n",
       "41916             0      15         15              620.00            1   \n",
       "41917             1      15         20              624.50            1   \n",
       "41918             3      15         55             2188.20            1   \n",
       "\n",
       "             date  data_block_id  \n",
       "41914  2023-05-29            637  \n",
       "41915  2023-05-29            637  \n",
       "41916  2023-05-29            637  \n",
       "41917  2023-05-29            637  \n",
       "41918  2023-05-29            637  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MISSING VALUES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No missing values.\n",
      "\n",
      "DUPLICATES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No duplicate rows.\n",
      "\n",
      "TOTAL SIZE >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Total DataFrame size: 2 MB.\n",
      "\n",
      "SUMMARY >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>max_dec_len</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>not_na_count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>product_type</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>41919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>county</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>41919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.30</td>\n",
       "      <td>4.78</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eic_count</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1517.00</td>\n",
       "      <td>41919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.35</td>\n",
       "      <td>144.06</td>\n",
       "      <td>13.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>installed_capacity</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>15</td>\n",
       "      <td>5.50</td>\n",
       "      <td>19314.31</td>\n",
       "      <td>41919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1450.77</td>\n",
       "      <td>2422.23</td>\n",
       "      <td>321.90</td>\n",
       "      <td>645.20</td>\n",
       "      <td>1567.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is_business</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>41919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>date</td>\n",
       "      <td>object</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41919</td>\n",
       "      <td>636</td>\n",
       "      <td>2022-11-26</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data_block_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>637.00</td>\n",
       "      <td>41919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>322.90</td>\n",
       "      <td>182.08</td>\n",
       "      <td>167.00</td>\n",
       "      <td>324.00</td>\n",
       "      <td>480.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               column    dtype  size_mb  max_dec_len  min      max  \\\n",
       "0        product_type    int64     0.32           -1 0.00     3.00   \n",
       "1              county    int64     0.32           -1 0.00    15.00   \n",
       "2           eic_count    int64     0.32           -1 5.00  1517.00   \n",
       "3  installed_capacity  float64     0.32           15 5.50 19314.31   \n",
       "4         is_business    int64     0.32           -1 0.00     1.00   \n",
       "5                date   object     0.32           -1  NaN      NaN   \n",
       "6       data_block_id    int64     0.32           -1 2.00   637.00   \n",
       "\n",
       "   not_na_count unique         top freq    mean     std    25%    50%     75%  \n",
       "0         41919    NaN         NaN  NaN    1.90    1.08   1.00   2.00    3.00  \n",
       "1         41919    NaN         NaN  NaN    7.30    4.78   3.00   7.00   11.00  \n",
       "2         41919    NaN         NaN  NaN   73.35  144.06  13.00  32.00   70.00  \n",
       "3         41919    NaN         NaN  NaN 1450.77 2422.23 321.90 645.20 1567.15  \n",
       "4         41919    NaN         NaN  NaN    0.54    0.50   0.00   1.00    1.00  \n",
       "5         41919    636  2022-11-26   69     NaN     NaN    NaN    NaN     NaN  \n",
       "6         41919    NaN         NaN  NaN  322.90  182.08 167.00 324.00  480.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_show_info(client_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed2c661-ba53-4858-b61b-fababe96d55f",
   "metadata": {},
   "source": [
    "- There are no missing values or duplicates in the dataframe.\n",
    "- The `data_block_id` values start from 2 instead of 0 or 1, as mentioned earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37133253-bdda-4121-a185-856ee26f650d",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c71bd98-3e38-4c5f-97a4-bfd9c1b7e8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'is_consumption' not found in dataframe, skipping.\n",
      "Size after transformation: 0 MB.\n"
     ]
    }
   ],
   "source": [
    "# Rename to avoid confusion and improve readability\n",
    "client_df = categorical_mapper(client_df, CATEGORICAL_DICT)\n",
    "\n",
    "# Change data types to reduce memory usage\n",
    "client_df = client_df.astype(\n",
    "    {\n",
    "        \"eic_count\": \"uint32\",\n",
    "        \"installed_capacity\": \"float32\",\n",
    "        \"date\": \"datetime64[ns]\",\n",
    "        \"data_block_id\": \"uint16\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Rename to distinct from datetime-like features from other DFs\n",
    "client_df = client_df.rename(columns={\"date\": \"client_date\"})\n",
    "\n",
    "print(f\"Size after transformation: {total_size(client_df)} MB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd668c-fb8c-40fd-9ba4-1b915b83d911",
   "metadata": {},
   "source": [
    "### Consistency and Relationship Validation\n",
    "#### Date and data_block_id\n",
    "As with the previous dataframes, it is necessary to validate the correlation between `client_date` and `data_block_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b63cf9-15d2-4f24-b2a0-1999d15b760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_date\n",
      "0 days    41283\n",
      "1 days      635\n",
      "NaT           1\n",
      "Name: count, dtype: int64\n",
      "data_block_id\n",
      "0.00    41283\n",
      "1.00      635\n",
      "NaN         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create variables to store the differences between the current and\n",
    "# previous row for all rows in client_date and data_block_id\n",
    "client_date_diff = client_df[\"client_date\"].dt.date.diff()\n",
    "client_id_diff = client_df[\"data_block_id\"].diff()\n",
    "\n",
    "\n",
    "# Print unique values to verify that default order reflects sorting\n",
    "# from oldest to newest without skips\n",
    "print(client_date_diff.value_counts(dropna=False))\n",
    "print(client_id_diff.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2dcd03-99b7-4f13-95f1-890aefd19bf5",
   "metadata": {},
   "source": [
    "- `NaT` and `NaN` values correspond to the first row in both columns, where no previous row data is available for comparison.\n",
    "- A value of '0' indicates that the current and previous rows belong to the same day.\n",
    "- A value of '1' indicates the transition from one day to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89eda7a-2f9b-44ca-ab7c-1ddc5cd526a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference nan: no mismatches.\n",
      "Difference 0.0: no mismatches.\n",
      "Difference 1.0: no mismatches.\n"
     ]
    }
   ],
   "source": [
    "for difference in client_id_diff.unique():\n",
    "    mismatched_indices_check(client_date_diff, client_id_diff, difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae831531-752d-4ca8-902e-c428007961f0",
   "metadata": {},
   "source": [
    "- The default order of the raw data for this dataframe is sorted by datetime, and the `data_block_id` reflects the actual data availability, with no errors observed in the `client_date` column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d83cf3c-9401-442d-bae5-290c9e14e973",
   "metadata": {},
   "source": [
    "## electricity_prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c7771-33b8-4c10-b6b4-f031d455512a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HEAD >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>euros_per_mwh</th>\n",
       "      <th>origin_date</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>92.51</td>\n",
       "      <td>2021-08-31 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-01 01:00:00</td>\n",
       "      <td>88.90</td>\n",
       "      <td>2021-08-31 01:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-01 02:00:00</td>\n",
       "      <td>87.35</td>\n",
       "      <td>2021-08-31 02:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-01 03:00:00</td>\n",
       "      <td>86.88</td>\n",
       "      <td>2021-08-31 03:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-01 04:00:00</td>\n",
       "      <td>88.43</td>\n",
       "      <td>2021-08-31 04:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         forecast_date  euros_per_mwh          origin_date  data_block_id\n",
       "0  2021-09-01 00:00:00          92.51  2021-08-31 00:00:00              1\n",
       "1  2021-09-01 01:00:00          88.90  2021-08-31 01:00:00              1\n",
       "2  2021-09-01 02:00:00          87.35  2021-08-31 02:00:00              1\n",
       "3  2021-09-01 03:00:00          86.88  2021-08-31 03:00:00              1\n",
       "4  2021-09-01 04:00:00          88.43  2021-08-31 04:00:00              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TAIL >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>euros_per_mwh</th>\n",
       "      <th>origin_date</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15281</th>\n",
       "      <td>2023-05-30 19:00:00</td>\n",
       "      <td>82.10</td>\n",
       "      <td>2023-05-29 19:00:00</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15282</th>\n",
       "      <td>2023-05-30 20:00:00</td>\n",
       "      <td>150.85</td>\n",
       "      <td>2023-05-29 20:00:00</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15283</th>\n",
       "      <td>2023-05-30 21:00:00</td>\n",
       "      <td>82.10</td>\n",
       "      <td>2023-05-29 21:00:00</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15284</th>\n",
       "      <td>2023-05-30 22:00:00</td>\n",
       "      <td>82.09</td>\n",
       "      <td>2023-05-29 22:00:00</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15285</th>\n",
       "      <td>2023-05-30 23:00:00</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>2023-05-29 23:00:00</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             forecast_date  euros_per_mwh          origin_date  data_block_id\n",
       "15281  2023-05-30 19:00:00          82.10  2023-05-29 19:00:00            637\n",
       "15282  2023-05-30 20:00:00         150.85  2023-05-29 20:00:00            637\n",
       "15283  2023-05-30 21:00:00          82.10  2023-05-29 21:00:00            637\n",
       "15284  2023-05-30 22:00:00          82.09  2023-05-29 22:00:00            637\n",
       "15285  2023-05-30 23:00:00          -1.29  2023-05-29 23:00:00            637"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MISSING VALUES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No missing values.\n",
      "\n",
      "DUPLICATES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No duplicate rows.\n",
      "\n",
      "TOTAL SIZE >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Total DataFrame size: 0 MB.\n",
      "\n",
      "SUMMARY >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>max_dec_len</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>not_na_count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forecast_date</td>\n",
       "      <td>object</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15286</td>\n",
       "      <td>15286</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>euros_per_mwh</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2</td>\n",
       "      <td>-10.06</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>15286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157.06</td>\n",
       "      <td>121.15</td>\n",
       "      <td>85.29</td>\n",
       "      <td>128.28</td>\n",
       "      <td>199.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>origin_date</td>\n",
       "      <td>object</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15286</td>\n",
       "      <td>15286</td>\n",
       "      <td>2021-08-31 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_block_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>637.00</td>\n",
       "      <td>15286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>318.99</td>\n",
       "      <td>183.89</td>\n",
       "      <td>160.00</td>\n",
       "      <td>319.00</td>\n",
       "      <td>478.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          column    dtype  size_mb  max_dec_len    min     max  not_na_count  \\\n",
       "0  forecast_date   object     0.12           -1    NaN     NaN         15286   \n",
       "1  euros_per_mwh  float64     0.12            2 -10.06 4000.00         15286   \n",
       "2    origin_date   object     0.12           -1    NaN     NaN         15286   \n",
       "3  data_block_id    int64     0.12           -1   1.00  637.00         15286   \n",
       "\n",
       "  unique                  top freq   mean    std    25%    50%    75%  \n",
       "0  15286  2021-09-01 00:00:00    1    NaN    NaN    NaN    NaN    NaN  \n",
       "1    NaN                  NaN  NaN 157.06 121.15  85.29 128.28 199.80  \n",
       "2  15286  2021-08-31 00:00:00    1    NaN    NaN    NaN    NaN    NaN  \n",
       "3    NaN                  NaN  NaN 318.99 183.89 160.00 319.00 478.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_show_info(electricity_prices_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e19efa-97a7-461f-a349-a1aaab1a2bc3",
   "metadata": {},
   "source": [
    "- There are no missing values or duplicates in the dataframe.\n",
    "- The `data_block_id` values start from 1.\n",
    "- The minimum value of the `euros_per_mwh` column is negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0431754-2c7e-4bb2-950e-0c784961306e",
   "metadata": {},
   "source": [
    "### Non-positive Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c2d28-1315-43e2-b010-dcda1ca0d7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electricity_prices_df[electricity_prices_df[\"euros_per_mwh\"] <= 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e9d81-64b2-437f-8658-8d8a156a0015",
   "metadata": {},
   "source": [
    "According to the [<u>official comment</u>](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers/discussion/454932#2523730), such prices are not an error.\n",
    "\n",
    "[<u>From Wikipedia</u>](https://en.wikipedia.org/wiki/Negative_pricing): negative pricing can occur when demand for a product drops or supply increases to an extent that owners or suppliers are prepared to pay others to accept it, in effect setting the price to a negative number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f68560-19e4-4cd6-b567-db034d5735da",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a822d526-6132-4206-bc9d-d6d39cc3f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data types to reduce memory usage\n",
    "electricity_prices_df = electricity_prices_df.astype(\n",
    "    {\n",
    "        \"forecast_date\": \"datetime64[ns]\",\n",
    "        \"euros_per_mwh\": \"float32\",\n",
    "        \"origin_date\": \"datetime64[ns]\",\n",
    "        \"data_block_id\": \"uint16\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Rename to distinct from datetime-like features from other DFs\n",
    "electricity_prices_df = electricity_prices_df.rename(\n",
    "    columns={\n",
    "        \"forecast_date\": \"electricity_forecast_datetime\",\n",
    "        \"origin_date\": \"electricity_origin_datetime\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229fdca-c53e-498a-93fe-6db5a3dcee54",
   "metadata": {},
   "source": [
    "### Consistency and Relationship Validation\n",
    "As with `electricity_prices_df`, it is necessary to validate the correlation between origin date, forecast date, and `data_block_id`.\n",
    "#### Origin and forecast dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61db965b-9986-4363-8c17-c1cf29ae112e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electricity_origin_datetime\n",
      "0 days 01:00:00    15283\n",
      "0 days 02:00:00        2\n",
      "NaT                    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check that each electricity_origin_date is the next hour compared\n",
    "# to the previous one\n",
    "print(\n",
    "    electricity_prices_df[\"electricity_origin_datetime\"]\n",
    "    .diff()\n",
    "    .value_counts(dropna=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ce105-379c-4349-bde1-a6ecaac260e7",
   "metadata": {},
   "source": [
    "There are also values with a 2-hour difference. This might indicate an issue with data collection or other inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b4597-7d6a-4832-9c4a-261ecf548801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>electricity_forecast_datetime</th>\n",
       "      <th>euros_per_mwh</th>\n",
       "      <th>electricity_origin_datetime</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>2022-03-27 03:00:00</td>\n",
       "      <td>100.07</td>\n",
       "      <td>2022-03-26 03:00:00</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13705</th>\n",
       "      <td>2023-03-26 03:00:00</td>\n",
       "      <td>40.12</td>\n",
       "      <td>2023-03-25 03:00:00</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      electricity_forecast_datetime  euros_per_mwh  \\\n",
       "4970            2022-03-27 03:00:00         100.07   \n",
       "13705           2023-03-26 03:00:00          40.12   \n",
       "\n",
       "      electricity_origin_datetime  data_block_id  \n",
       "4970          2022-03-26 03:00:00            208  \n",
       "13705         2023-03-25 03:00:00            572  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electricity_prices_df[\n",
    "    electricity_prices_df[\"electricity_origin_datetime\"].diff()\n",
    "    == pd.Timedelta(2, \"hour\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dee1054-ed4f-4f12-86bc-e6854210912e",
   "metadata": {},
   "source": [
    "The 2-hour time difference occurs at 03:00:00 on the dates 2022-03-27 and 2023-03-26, corresponding to the transition to daylight saving time. This transition results in missing records for the previous hour.\n",
    "\n",
    "Nevertheless, despite these missing values, the data remains consistent on a daily basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bc218b-d518-43cc-b1d8-67d6d488a0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any forecast dates are not exactly one day after origin dates\n",
    "(\n",
    "    electricity_prices_df[\"electricity_origin_datetime\"]\n",
    "    + pd.Timedelta(days=1)\n",
    "    != electricity_prices_df[\"electricity_forecast_datetime\"]\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc31320-e82b-42d5-91b7-6ac58f1577b8",
   "metadata": {},
   "source": [
    "- All `electricity_origin_datetime` values represent the day before their corresponding `electricity_forecast_datetime` values.\n",
    "- The raw data in this dataframe is sorted chronologically by datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb2a93f-cf52-4dc4-90e5-55708e3a2fb4",
   "metadata": {},
   "source": [
    "#### Origin date and data_block_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69292ea4-4a96-46fd-8999-ed02f8c71fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electricity_origin_datetime\n",
      "0 days    14649\n",
      "1 days      636\n",
      "NaT           1\n",
      "Name: count, dtype: int64\n",
      "data_block_id\n",
      "0.00    14649\n",
      "1.00      636\n",
      "NaN         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create variables to store the differences between the current and\n",
    "# previous row for all rows in electricity_origin_datetime and\n",
    "# data_block_id\n",
    "electricity_date_diff = electricity_prices_df[\n",
    "    \"electricity_origin_datetime\"\n",
    "].dt.date.diff()\n",
    "electricity_id_diff = electricity_prices_df[\"data_block_id\"].diff()\n",
    "\n",
    "# Print unique values to verify that default order reflects sorting\n",
    "# from oldest to newest without skips\n",
    "print(electricity_date_diff.value_counts(dropna=False))\n",
    "print(electricity_id_diff.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb14b95-b710-4962-98d8-878d75db61e0",
   "metadata": {},
   "source": [
    "- `NaT` and `NaN` values correspond to the first row in both columns, where no previous row data is available for comparison.\n",
    "- A value of '0' indicates that the current and previous rows belong to the same day.\n",
    "- A value of '1' indicates the transition from one day to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d1f66-64df-4c89-a7d4-1df37ddae839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference nan: no mismatches.\n",
      "Difference 0.0: no mismatches.\n",
      "Difference 1.0: no mismatches.\n"
     ]
    }
   ],
   "source": [
    "for difference in electricity_id_diff.unique():\n",
    "    mismatched_indices_check(\n",
    "        electricity_date_diff, electricity_id_diff, difference\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85706d86-e8f5-40f4-8bab-49a96ad3aa28",
   "metadata": {},
   "source": [
    "- The default order of the raw data for this dataframe is sorted by datetime, and the `data_block_id` reflects the actual data availability, with no errors observed in the `electricity_origin_datetime` column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8737f2cc-ed66-4ca8-9f32-695a1f30a724",
   "metadata": {},
   "source": [
    "## forecast_weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e027ae6-fc3e-42e4-89e9-78a947cfc32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HEAD >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>origin_datetime</th>\n",
       "      <th>hours_ahead</th>\n",
       "      <th>temperature</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>cloudcover_high</th>\n",
       "      <th>cloudcover_low</th>\n",
       "      <th>cloudcover_mid</th>\n",
       "      <th>cloudcover_total</th>\n",
       "      <th>10_metre_u_wind_component</th>\n",
       "      <th>10_metre_v_wind_component</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>forecast_datetime</th>\n",
       "      <th>direct_solar_radiation</th>\n",
       "      <th>surface_solar_radiation_downwards</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>total_precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.60</td>\n",
       "      <td>21.70</td>\n",
       "      <td>2021-09-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>15.66</td>\n",
       "      <td>11.55</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01 03:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.60</td>\n",
       "      <td>22.20</td>\n",
       "      <td>2021-09-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>13.00</td>\n",
       "      <td>10.69</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4.46e-03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01 03:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.60</td>\n",
       "      <td>22.70</td>\n",
       "      <td>2021-09-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>14.21</td>\n",
       "      <td>11.67</td>\n",
       "      <td>0.73</td>\n",
       "      <td>5.62e-03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.45</td>\n",
       "      <td>-7.42</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01 03:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57.60</td>\n",
       "      <td>23.20</td>\n",
       "      <td>2021-09-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>14.84</td>\n",
       "      <td>12.26</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.07</td>\n",
       "      <td>6.26e-04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.09</td>\n",
       "      <td>-9.16</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01 03:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.60</td>\n",
       "      <td>23.70</td>\n",
       "      <td>2021-09-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>15.29</td>\n",
       "      <td>12.46</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.53e-05</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.27</td>\n",
       "      <td>-8.98</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01 03:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude      origin_datetime  hours_ahead  temperature  \\\n",
       "0     57.60      21.70  2021-09-01 02:00:00            1        15.66   \n",
       "1     57.60      22.20  2021-09-01 02:00:00            1        13.00   \n",
       "2     57.60      22.70  2021-09-01 02:00:00            1        14.21   \n",
       "3     57.60      23.20  2021-09-01 02:00:00            1        14.84   \n",
       "4     57.60      23.70  2021-09-01 02:00:00            1        15.29   \n",
       "\n",
       "   dewpoint  cloudcover_high  cloudcover_low  cloudcover_mid  \\\n",
       "0     11.55             0.90            0.02            0.00   \n",
       "1     10.69             0.89        4.46e-03            0.00   \n",
       "2     11.67             0.73        5.62e-03            0.00   \n",
       "3     12.26             0.34            0.07        6.26e-04   \n",
       "4     12.46             0.10            0.09        1.53e-05   \n",
       "\n",
       "   cloudcover_total  10_metre_u_wind_component  10_metre_v_wind_component  \\\n",
       "0              0.91                      -0.41                      -9.11   \n",
       "1              0.89                       0.21                      -5.36   \n",
       "2              0.73                       1.45                      -7.42   \n",
       "3              0.39                       1.09                      -9.16   \n",
       "4              0.18                       1.27                      -8.98   \n",
       "\n",
       "   data_block_id    forecast_datetime  direct_solar_radiation  \\\n",
       "0              1  2021-09-01 03:00:00                    0.00   \n",
       "1              1  2021-09-01 03:00:00                    0.00   \n",
       "2              1  2021-09-01 03:00:00                    0.00   \n",
       "3              1  2021-09-01 03:00:00                    0.00   \n",
       "4              1  2021-09-01 03:00:00                    0.00   \n",
       "\n",
       "   surface_solar_radiation_downwards  snowfall  total_precipitation  \n",
       "0                               0.00      0.00                 0.00  \n",
       "1                               0.00      0.00                 0.00  \n",
       "2                               0.00      0.00                 0.00  \n",
       "3                               0.00      0.00                 0.00  \n",
       "4                               0.00      0.00                 0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TAIL >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>origin_datetime</th>\n",
       "      <th>hours_ahead</th>\n",
       "      <th>temperature</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>cloudcover_high</th>\n",
       "      <th>cloudcover_low</th>\n",
       "      <th>cloudcover_mid</th>\n",
       "      <th>cloudcover_total</th>\n",
       "      <th>10_metre_u_wind_component</th>\n",
       "      <th>10_metre_v_wind_component</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>forecast_datetime</th>\n",
       "      <th>direct_solar_radiation</th>\n",
       "      <th>surface_solar_radiation_downwards</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>total_precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3424507</th>\n",
       "      <td>59.70</td>\n",
       "      <td>26.20</td>\n",
       "      <td>2023-05-30 02:00:00</td>\n",
       "      <td>48</td>\n",
       "      <td>10.15</td>\n",
       "      <td>5.66</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4.06e-03</td>\n",
       "      <td>0.31</td>\n",
       "      <td>6.89</td>\n",
       "      <td>-3.26</td>\n",
       "      <td>637</td>\n",
       "      <td>2023-06-01 02:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424508</th>\n",
       "      <td>59.70</td>\n",
       "      <td>26.70</td>\n",
       "      <td>2023-05-30 02:00:00</td>\n",
       "      <td>48</td>\n",
       "      <td>10.26</td>\n",
       "      <td>5.92</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.91</td>\n",
       "      <td>6.89</td>\n",
       "      <td>-3.77</td>\n",
       "      <td>637</td>\n",
       "      <td>2023-06-01 02:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424509</th>\n",
       "      <td>59.70</td>\n",
       "      <td>27.20</td>\n",
       "      <td>2023-05-30 02:00:00</td>\n",
       "      <td>48</td>\n",
       "      <td>10.47</td>\n",
       "      <td>6.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.53</td>\n",
       "      <td>6.21</td>\n",
       "      <td>-4.70</td>\n",
       "      <td>637</td>\n",
       "      <td>2023-06-01 02:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424510</th>\n",
       "      <td>59.70</td>\n",
       "      <td>27.70</td>\n",
       "      <td>2023-05-30 02:00:00</td>\n",
       "      <td>48</td>\n",
       "      <td>10.69</td>\n",
       "      <td>7.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.81</td>\n",
       "      <td>-4.34</td>\n",
       "      <td>637</td>\n",
       "      <td>2023-06-01 02:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424511</th>\n",
       "      <td>59.70</td>\n",
       "      <td>28.20</td>\n",
       "      <td>2023-05-30 02:00:00</td>\n",
       "      <td>48</td>\n",
       "      <td>11.23</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.72</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>637</td>\n",
       "      <td>2023-06-01 02:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         latitude  longitude      origin_datetime  hours_ahead  temperature  \\\n",
       "3424507     59.70      26.20  2023-05-30 02:00:00           48        10.15   \n",
       "3424508     59.70      26.70  2023-05-30 02:00:00           48        10.26   \n",
       "3424509     59.70      27.20  2023-05-30 02:00:00           48        10.47   \n",
       "3424510     59.70      27.70  2023-05-30 02:00:00           48        10.69   \n",
       "3424511     59.70      28.20  2023-05-30 02:00:00           48        11.23   \n",
       "\n",
       "         dewpoint  cloudcover_high  cloudcover_low  cloudcover_mid  \\\n",
       "3424507      5.66             0.06            0.26        4.06e-03   \n",
       "3424508      5.92             0.11            0.90            0.20   \n",
       "3424509      6.07             0.00            0.39            0.45   \n",
       "3424510      7.01             0.00            0.51            1.00   \n",
       "3424511      7.07             0.70            0.29            0.93   \n",
       "\n",
       "         cloudcover_total  10_metre_u_wind_component  \\\n",
       "3424507              0.31                       6.89   \n",
       "3424508              0.91                       6.89   \n",
       "3424509              0.53                       6.21   \n",
       "3424510              1.00                       5.81   \n",
       "3424511              0.99                       2.72   \n",
       "\n",
       "         10_metre_v_wind_component  data_block_id    forecast_datetime  \\\n",
       "3424507                      -3.26            637  2023-06-01 02:00:00   \n",
       "3424508                      -3.77            637  2023-06-01 02:00:00   \n",
       "3424509                      -4.70            637  2023-06-01 02:00:00   \n",
       "3424510                      -4.34            637  2023-06-01 02:00:00   \n",
       "3424511                      -0.92            637  2023-06-01 02:00:00   \n",
       "\n",
       "         direct_solar_radiation  surface_solar_radiation_downwards  snowfall  \\\n",
       "3424507                    0.00                               0.00      0.00   \n",
       "3424508                    0.00                               0.00      0.00   \n",
       "3424509                    0.00                               0.00      0.00   \n",
       "3424510                    0.00                               0.00      0.00   \n",
       "3424511                    0.00                               0.00      0.00   \n",
       "\n",
       "         total_precipitation  \n",
       "3424507                 0.00  \n",
       "3424508                 0.00  \n",
       "3424509                 0.00  \n",
       "3424510                 0.00  \n",
       "3424511                 0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MISSING VALUES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "surface_solar_radiation_downwards    2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DUPLICATES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No duplicate rows.\n",
      "\n",
      "TOTAL SIZE >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Total DataFrame size: 470 MB.\n",
      "\n",
      "SUMMARY >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>max_dec_len</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>not_na_count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>latitude</td>\n",
       "      <td>float64</td>\n",
       "      <td>26.13</td>\n",
       "      <td>1</td>\n",
       "      <td>57.60</td>\n",
       "      <td>59.70</td>\n",
       "      <td>3424512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.65</td>\n",
       "      <td>0.69</td>\n",
       "      <td>58.12</td>\n",
       "      <td>58.65</td>\n",
       "      <td>59.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>longitude</td>\n",
       "      <td>float64</td>\n",
       "      <td>26.13</td>\n",
       "      <td>1</td>\n",
       "      <td>21.70</td>\n",
       "      <td>28.20</td>\n",
       "      <td>3424512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.95</td>\n",
       "      <td>2.02</td>\n",
       "      <td>23.20</td>\n",
       "      <td>24.95</td>\n",
       "      <td>26.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>origin_datetime</td>\n",
       "      <td>object</td>\n",
       "      <td>26.13</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3424512</td>\n",
       "      <td>637</td>\n",
       "      <td>2021-09-01 02:00:00</td>\n",
       "      <td>5376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hours_ahead</td>\n",
       "      <td>int64</td>\n",
       "      <td>26.13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>3424512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.50</td>\n",
       "      <td>13.85</td>\n",
       "      <td>12.75</td>\n",
       "      <td>24.50</td>\n",
       "      <td>36.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>temperature</td>\n",
       "      <td>float64</td>\n",
       "      <td>26.13</td>\n",
       "      <td>20</td>\n",
       "      <td>-27.50</td>\n",
       "      <td>31.81</td>\n",
       "      <td>3424512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.74</td>\n",
       "      <td>7.84</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4.87</td>\n",
       "      <td>11.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dewpoint</td>\n",
       "      <td>float64</td>\n",
       "      <td>26.13</td>\n",
       "      <td>20</td>\n",
       "      <td>-29.68</td>\n",
       "      <td>23.68</td>\n",
       "      <td>3424512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.41</td>\n",
       "      <td>7.12</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>1.84</td>\n",
       "      <td>7.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cloudcover_high</td>\n",
       "      <td>float64</td>\n",
       "      <td>26.13</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3424512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cloudcover_low</td>\n",
       "      <td>float64</td>\n",
       "      <td>26.13</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3424512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.44</td>\n",
       "      <td>3.36e-04</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cloudcover_mid</td>\n",
       "      <td>float64</td>\n",
       "      <td>26.13</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3424512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cloudcover_total</td>\n",
       "      <td>float64</td>\n",
       "      <td>26.13</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3424512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10_metre_u_wind_component</td>\n",
       "      <td>float64</td>\n",
       "      <td>26.13</td>\n",
       "      <td>20</td>\n",
       "      <td>-17.58</td>\n",
       "      <td>22.57</td>\n",
       "      <td>3424512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.26</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>1.47</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10_metre_v_wind_component</td>\n",
       "      <td>float64</td>\n",
       "      <td>26.13</td>\n",
       "      <td>19</td>\n",
       "      <td>-22.12</td>\n",
       "      <td>19.31</td>\n",
       "      <td>3424512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.73</td>\n",
       "      <td>4.22</td>\n",
       "      <td>-1.98</td>\n",
       "      <td>0.94</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data_block_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>26.13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>637.00</td>\n",
       "      <td>3424512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>319.00</td>\n",
       "      <td>183.89</td>\n",
       "      <td>160.00</td>\n",
       "      <td>319.00</td>\n",
       "      <td>478.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>forecast_datetime</td>\n",
       "      <td>object</td>\n",
       "      <td>26.13</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3424512</td>\n",
       "      <td>15310</td>\n",
       "      <td>2022-10-30 03:00:00</td>\n",
       "      <td>448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>direct_solar_radiation</td>\n",
       "      <td>float64</td>\n",
       "      <td>26.13</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>954.42</td>\n",
       "      <td>3424512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151.19</td>\n",
       "      <td>256.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>212.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>surface_solar_radiation_downwards</td>\n",
       "      <td>float64</td>\n",
       "      <td>26.13</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>848.71</td>\n",
       "      <td>3424510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.76</td>\n",
       "      <td>187.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>144.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>snowfall</td>\n",
       "      <td>float64</td>\n",
       "      <td>26.13</td>\n",
       "      <td>20</td>\n",
       "      <td>-3.81e-06</td>\n",
       "      <td>4.83e-03</td>\n",
       "      <td>3424512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.53e-05</td>\n",
       "      <td>1.22e-04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>total_precipitation</td>\n",
       "      <td>float64</td>\n",
       "      <td>26.13</td>\n",
       "      <td>20</td>\n",
       "      <td>-1.53e-05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3424512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.86e-05</td>\n",
       "      <td>2.78e-04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.77e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               column    dtype  size_mb  max_dec_len  \\\n",
       "0                            latitude  float64    26.13            1   \n",
       "1                           longitude  float64    26.13            1   \n",
       "2                     origin_datetime   object    26.13           -1   \n",
       "3                         hours_ahead    int64    26.13           -1   \n",
       "4                         temperature  float64    26.13           20   \n",
       "5                            dewpoint  float64    26.13           20   \n",
       "6                     cloudcover_high  float64    26.13           20   \n",
       "7                      cloudcover_low  float64    26.13           20   \n",
       "8                      cloudcover_mid  float64    26.13           20   \n",
       "9                    cloudcover_total  float64    26.13           20   \n",
       "10          10_metre_u_wind_component  float64    26.13           20   \n",
       "11          10_metre_v_wind_component  float64    26.13           19   \n",
       "12                      data_block_id    int64    26.13           -1   \n",
       "13                  forecast_datetime   object    26.13           -1   \n",
       "14             direct_solar_radiation  float64    26.13           20   \n",
       "15  surface_solar_radiation_downwards  float64    26.13           19   \n",
       "16                           snowfall  float64    26.13           20   \n",
       "17                total_precipitation  float64    26.13           20   \n",
       "\n",
       "         min      max  not_na_count unique                  top  freq  \\\n",
       "0      57.60    59.70       3424512    NaN                  NaN   NaN   \n",
       "1      21.70    28.20       3424512    NaN                  NaN   NaN   \n",
       "2        NaN      NaN       3424512    637  2021-09-01 02:00:00  5376   \n",
       "3       1.00    48.00       3424512    NaN                  NaN   NaN   \n",
       "4     -27.50    31.81       3424512    NaN                  NaN   NaN   \n",
       "5     -29.68    23.68       3424512    NaN                  NaN   NaN   \n",
       "6       0.00     1.00       3424512    NaN                  NaN   NaN   \n",
       "7       0.00     1.00       3424512    NaN                  NaN   NaN   \n",
       "8       0.00     1.00       3424512    NaN                  NaN   NaN   \n",
       "9       0.00     1.00       3424512    NaN                  NaN   NaN   \n",
       "10    -17.58    22.57       3424512    NaN                  NaN   NaN   \n",
       "11    -22.12    19.31       3424512    NaN                  NaN   NaN   \n",
       "12      1.00   637.00       3424512    NaN                  NaN   NaN   \n",
       "13       NaN      NaN       3424512  15310  2022-10-30 03:00:00   448   \n",
       "14     -0.77   954.42       3424512    NaN                  NaN   NaN   \n",
       "15     -0.33   848.71       3424510    NaN                  NaN   NaN   \n",
       "16 -3.81e-06 4.83e-03       3424512    NaN                  NaN   NaN   \n",
       "17 -1.53e-05     0.02       3424512    NaN                  NaN   NaN   \n",
       "\n",
       "       mean      std      25%    50%      75%  \n",
       "0     58.65     0.69    58.12  58.65    59.17  \n",
       "1     24.95     2.02    23.20  24.95    26.70  \n",
       "2       NaN      NaN      NaN    NaN      NaN  \n",
       "3     24.50    13.85    12.75  24.50    36.25  \n",
       "4      5.74     7.84     0.26   4.87    11.15  \n",
       "5      2.41     7.12    -2.36   1.84     7.30  \n",
       "6      0.39     0.44     0.00   0.09     0.98  \n",
       "7      0.43     0.44 3.36e-04   0.23     1.00  \n",
       "8      0.36     0.42     0.00   0.10     0.90  \n",
       "9      0.68     0.40     0.26   0.98     1.00  \n",
       "10     1.26     4.00    -1.47   1.47     3.81  \n",
       "11     0.73     4.22    -1.98   0.94     3.51  \n",
       "12   319.00   183.89   160.00 319.00   478.00  \n",
       "13      NaN      NaN      NaN    NaN      NaN  \n",
       "14   151.19   256.51     0.00   0.00   212.84  \n",
       "15   110.76   187.44     0.00   0.60   144.17  \n",
       "16 2.53e-05 1.22e-04     0.00   0.00     0.00  \n",
       "17 7.86e-05 2.78e-04     0.00   0.00 2.77e-05  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_show_info(forecast_weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b630472b-23a3-447a-8d9b-7c40cf51c0ac",
   "metadata": {},
   "source": [
    "- There are 2 missing values and zero duplicates in the dataframe. Only the `surface_solar_radiation_downwards` column contains missing values. \n",
    "- The `data_block_id` values start from 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9226e72c-48a3-4c88-a410-88f95cc16e87",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe1b4f5-fe85-4b9a-a8b5-8776910ee5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_weather_df[[\"latitude\", \"longitude\"]] = forecast_weather_df[\n",
    "    [\"latitude\", \"longitude\"]\n",
    "].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf18d22-962f-4e93-9c22-4d71171abd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save unique forecast locations for later comparison with historical\n",
    "# data\n",
    "f_unique_coords = unique_locations(forecast_weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4184db55-84c3-403b-971e-5815b7f7627a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after transformation: 254 MB.\n"
     ]
    }
   ],
   "source": [
    "forecast_weather_df[[\"latitude\", \"longitude\"]] = forecast_weather_df[\n",
    "    [\"latitude\", \"longitude\"]\n",
    "].mul(10)\n",
    "\n",
    "forecast_weather_df = forecast_weather_df.astype(\n",
    "    {\n",
    "        \"latitude\": \"uint16\",\n",
    "        \"longitude\": \"uint16\",\n",
    "        \"origin_datetime\": \"datetime64[ns]\",\n",
    "        \"temperature\": \"float32\",\n",
    "        \"dewpoint\": \"float32\",\n",
    "        \"cloudcover_high\": \"float32\",\n",
    "        \"cloudcover_low\": \"float32\",\n",
    "        \"cloudcover_mid\": \"float32\",\n",
    "        \"cloudcover_total\": \"float32\",\n",
    "        \"10_metre_u_wind_component\": \"float32\",\n",
    "        \"10_metre_v_wind_component\": \"float32\",\n",
    "        \"data_block_id\": \"uint16\",\n",
    "        \"forecast_datetime\": \"datetime64[ns]\",\n",
    "        \"direct_solar_radiation\": \"float32\",\n",
    "        \"surface_solar_radiation_downwards\": \"float32\",\n",
    "        \"snowfall\": \"float32\",\n",
    "        \"total_precipitation\": \"float32\",\n",
    "    }\n",
    ")\n",
    "\n",
    "forecast_weather_df[\"hours_ahead\"] = pd.to_timedelta(\n",
    "    forecast_weather_df[\"hours_ahead\"], \"h\"\n",
    ")\n",
    "\n",
    "print(f\"Size after transformation: {total_size(forecast_weather_df)} MB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3cf0b7-9b50-47d3-9a4e-ef0874058921",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52033f48-4a41-4348-818b-5c4746715f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>origin_datetime</th>\n",
       "      <th>hours_ahead</th>\n",
       "      <th>temperature</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>cloudcover_high</th>\n",
       "      <th>cloudcover_low</th>\n",
       "      <th>cloudcover_mid</th>\n",
       "      <th>cloudcover_total</th>\n",
       "      <th>10_metre_u_wind_component</th>\n",
       "      <th>10_metre_v_wind_component</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>forecast_datetime</th>\n",
       "      <th>direct_solar_radiation</th>\n",
       "      <th>surface_solar_radiation_downwards</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>total_precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1849670</th>\n",
       "      <td>597</td>\n",
       "      <td>237</td>\n",
       "      <td>2022-08-11 02:00:00</td>\n",
       "      <td>0 days 03:00:00</td>\n",
       "      <td>19.04</td>\n",
       "      <td>16.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>5.91</td>\n",
       "      <td>7.62</td>\n",
       "      <td>345</td>\n",
       "      <td>2022-08-11 05:00:00</td>\n",
       "      <td>17.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849782</th>\n",
       "      <td>597</td>\n",
       "      <td>237</td>\n",
       "      <td>2022-08-11 02:00:00</td>\n",
       "      <td>0 days 04:00:00</td>\n",
       "      <td>18.80</td>\n",
       "      <td>16.99</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5.42</td>\n",
       "      <td>8.10</td>\n",
       "      <td>345</td>\n",
       "      <td>2022-08-11 06:00:00</td>\n",
       "      <td>206.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         latitude  longitude     origin_datetime     hours_ahead  temperature  \\\n",
       "1849670       597        237 2022-08-11 02:00:00 0 days 03:00:00        19.04   \n",
       "1849782       597        237 2022-08-11 02:00:00 0 days 04:00:00        18.80   \n",
       "\n",
       "         dewpoint  cloudcover_high  cloudcover_low  cloudcover_mid  \\\n",
       "1849670     16.85             0.91            0.00            0.00   \n",
       "1849782     16.99             0.84            0.00            0.00   \n",
       "\n",
       "         cloudcover_total  10_metre_u_wind_component  \\\n",
       "1849670              0.91                       5.91   \n",
       "1849782              0.84                       5.42   \n",
       "\n",
       "         10_metre_v_wind_component  data_block_id   forecast_datetime  \\\n",
       "1849670                       7.62            345 2022-08-11 05:00:00   \n",
       "1849782                       8.10            345 2022-08-11 06:00:00   \n",
       "\n",
       "         direct_solar_radiation  surface_solar_radiation_downwards  snowfall  \\\n",
       "1849670                   17.10                                NaN      0.00   \n",
       "1849782                  206.41                                NaN      0.00   \n",
       "\n",
       "         total_precipitation  \n",
       "1849670                 0.00  \n",
       "1849782                 0.00  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_weather_df[forecast_weather_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04cc04f-32d7-4bc6-85a3-33f9e8d8b0f0",
   "metadata": {},
   "source": [
    "- Since there are only two missing values, it could be due to a local issue lasting for just 2 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf762ee-0c72-49b7-8654-56a1fa94b1b5",
   "metadata": {},
   "source": [
    "### Consistency and Relationship Validation\n",
    "Ensure `origin_datetime`, `forecast_datetime`, `hours_ahead` values are coherent within respective `latitude` and `longitude` groups.\n",
    "#### Origin datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c47428-ac46-46d4-a323-59bca3929c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origin_datetime\n",
       "True     111\n",
       "False      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sameness check\n",
    "forecast_geo_gb = forecast_weather_df.groupby([\"latitude\", \"longitude\"])\n",
    "same_groups(forecast_geo_gb, \"origin_datetime\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4921cbdd-020a-4d7c-84f7-326b7bce5151",
   "metadata": {},
   "source": [
    "This dataframe contains 112 unique combinations of `latitude` and `longitude`, representing distinct geographical points for weather forecasts. Only one `False` value corresponds to the first group, indicating that all other location points have identical subsequences of `origin_datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f6ff0f-a89d-40e1-b523-ad6c1dd245e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origin_datetime\n",
       "02:00:00    1843968\n",
       "01:00:00    1580544\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forecast creation times\n",
    "forecast_weather_df[\"origin_datetime\"].dt.time.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03160b7-3f66-48fa-bfed-89a964df3799",
   "metadata": {},
   "source": [
    "All forecasts are made at either 1 AM or 2 AM, likely due to shifts associated with transitions to and from daylight saving time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffc3f13-51cb-492a-8849-c2201f376e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origin_datetime\n",
       "0 days 00:00:00    29939\n",
       "1 days 00:00:00      632\n",
       "0 days 23:00:00        2\n",
       "1 days 01:00:00        2\n",
       "NaT                    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select latitude and longitude values for the first entry of the\n",
    "# geographical group, as the sequences of origin_datetime values are\n",
    "# identical across each group\n",
    "lat0, lon0 = forecast_weather_df.iloc[0][[\"latitude\", \"longitude\"]]\n",
    "fw_subset_df = forecast_weather_df[\n",
    "    (forecast_weather_df[\"latitude\"] == lat0)\n",
    "    & (forecast_weather_df[\"longitude\"] == lon0)\n",
    "]\n",
    "\n",
    "# Calculate the differences between consecutive origin_datetime values\n",
    "# for the selected geographical group\n",
    "fod_diff = fw_subset_df[\"origin_datetime\"].diff()\n",
    "\n",
    "# Display the counts of unique differences between consecutive\n",
    "# origin_datetime entries\n",
    "fod_diff.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7174e10f-fff4-4200-a8c9-8bddc46c2903",
   "metadata": {},
   "source": [
    "- `0 days 00:00:00`: rows corresponding to the same location and day, but with different `hours_ahead` values.\n",
    "- `1 days 00:00:00`: indicates a shift from previous origin day.\n",
    "- `0 days 23:00:00`: likely caused by a transition to daylight saving time.\n",
    "- `1 days 01:00:00`: likely caused by a transition from daylight saving time.\n",
    "- `NaT`: corresponds to the first rows in each group.\n",
    "\n",
    "Based on these differences, it can be concluded that the data in this dataframe is sorted by `origin_datetime` by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce26318f-f8c2-40d1-a079-a03563369bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_datetime</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>327936</th>\n",
       "      <td>2021-11-01 01:00:00</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118208</th>\n",
       "      <td>2022-03-28 02:00:00</td>\n",
       "      <td>1 days 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284800</th>\n",
       "      <td>2022-10-31 01:00:00</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075072</th>\n",
       "      <td>2023-03-27 02:00:00</td>\n",
       "      <td>1 days 01:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            origin_datetime      difference\n",
       "327936  2021-11-01 01:00:00 0 days 23:00:00\n",
       "1118208 2022-03-28 02:00:00 1 days 01:00:00\n",
       "2284800 2022-10-31 01:00:00 0 days 23:00:00\n",
       "3075072 2023-03-27 02:00:00 1 days 01:00:00"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select rows where differences in origin_datetime are not 0, 1 day, or\n",
    "# NaT\n",
    "unusual_diff_df = fw_subset_df[\n",
    "    (fod_diff != pd.Timedelta(0))\n",
    "    & (fod_diff != pd.Timedelta(1, \"d\"))\n",
    "    & (~fod_diff.isna())\n",
    "][[\"origin_datetime\"]]\n",
    "\n",
    "# Merge the filtered timestamps with their corresponding time\n",
    "# differences\n",
    "pd.merge(\n",
    "    unusual_diff_df,\n",
    "    fod_diff[unusual_diff_df.index].rename(\"difference\"),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab673bc-b932-42a0-94fd-0fa67c760103",
   "metadata": {},
   "source": [
    "Yes, the autumn shift corresponds to a switch to winter time, and the spring shift corresponds to a switch to summer time. Specifically:\n",
    "- The `origin_datetime` hour is `02:00:00` during the following periods:\n",
    "  - From `2021-09-01` to `2021-10-31`\n",
    "  - From `2022-03-28` to `2022-10-30`\n",
    "  - From `2023-03-27` to `2023-05-30`\n",
    "- The `origin_datetime` hour is `01:00:00` during the following periods:\n",
    "  - From `2021-11-01` to `2022-03-27`\n",
    "  - From `2022-10-31` to `2023-03-26`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ac02d1-b632-4aee-93fa-b7901f38b1a8",
   "metadata": {},
   "source": [
    "#### Forecast datetime\n",
    "From the data description:\n",
    "- `forecast_datetime` - The timestamp of the predicted weather. Generated from `origin_datetime` plus `hours_ahead`. This represents the start of the 1-hour period for which weather data are forecasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d493e884-f1d9-4d25-8339-a7c0083481dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forecast_datetime\n",
      "True     111\n",
      "False      1\n",
      "Name: count, dtype: int64\n",
      "hours_ahead\n",
      "True     111\n",
      "False      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sameness check for other two datetime features\n",
    "for column in (\"forecast_datetime\", \"hours_ahead\"):\n",
    "    print(same_groups(forecast_geo_gb, column).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d59d05-ab69-442d-b4b4-57c770afea97",
   "metadata": {},
   "source": [
    "As with `origin_datetime`, for each geographical group, the sequence of `forecast_datetime` or `hours_ahead` values is identical across the locations. Therefore, it is sufficient to check the `forecast_datetime` and `hours_ahead` features using data from just one location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c40908-f95a-40b3-b80c-3d0871c47474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2021-10-30 02:00:00', '2021-10-31 02:00:00', '2022-03-26 01:00:00',\n",
       " '2022-03-27 01:00:00', '2022-10-29 02:00:00', '2022-10-30 02:00:00',\n",
       " '2023-03-25 01:00:00', '2023-03-26 01:00:00']\n",
       "Length: 8, dtype: datetime64[ns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the equality stated in the dataset description:\n",
    "# origin_datetime + hours_ahead = forecast_datetime\n",
    "unusual_sum_df = fw_subset_df[\n",
    "    fw_subset_df[\"origin_datetime\"]\n",
    "    + fw_subset_df[\"hours_ahead\"]\n",
    "    != fw_subset_df[\"forecast_datetime\"]\n",
    "]\n",
    "unusual_sum_df[\"origin_datetime\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd542c-df3c-4424-b708-ae846d2cb828",
   "metadata": {},
   "source": [
    "Values that do not satisfy the condition occur only within the 48 hours preceding a switch to or from DST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0b25e-d1cd-4a7f-bc28-9d2a95dcdf7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that entries not satisfying the condition will satisfy it after\n",
    "# adding or subtracting respectively.\n",
    "# For autumn,\n",
    "# origin_datetime + hours_ahead == forecast_datetime + 1 hour.\n",
    "# For spring,\n",
    "# origin_datetime + hours_ahead == forecast_datetime - 1 hour.\n",
    "\n",
    "(unusual_sum_df[\"origin_datetime\"]\n",
    " + unusual_sum_df[\"hours_ahead\"]\n",
    " != unusual_sum_df[\"forecast_datetime\"]\n",
    " + pd.to_timedelta(np.where(\n",
    "     unusual_sum_df[\"origin_datetime\"].dt.month == 10,  # October\n",
    "     1,  # Add 1 hour for autumn switch to DST (October)\n",
    "     -1  # Subtract 1 hour for spring switch from DST (March)\n",
    " ), 'h')\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7836cb2-1896-457d-b85a-500b054791fa",
   "metadata": {},
   "source": [
    "All conditions are satisfied after the corresponding addition or subtraction. This means that all previously unsatisfied sums of `origin_datetime` and `hours_ahead` differ from `forecast_datetime` by exactly 1 hour due to the switch to or from DST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc74b68-571d-49bd-b6a5-5a2d748b8904",
   "metadata": {},
   "source": [
    "#### data_block_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e686d6e-4fcd-40c5-8f02-174c2c7b99da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_block_id\n",
      "0.00    2017714\n",
      "1.00        637\n",
      "NaN           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create variables to store the differences between the current and\n",
    "# previous row for all rows in datetime and data_block_id\n",
    "\n",
    "fw_id_diff = forecast_weather_df[\"data_block_id\"].diff()\n",
    "fw_date_diff = forecast_weather_df[\"origin_datetime\"].dt.date.diff()\n",
    "\n",
    "print(train_id_diff.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edca246-f7fa-47ab-9a70-2977a2cc6012",
   "metadata": {},
   "source": [
    "- A value of '0' indicates that the current and previous rows belong to the same day.\n",
    "- A value of '1' indicates the transition from one day to the next.\n",
    "- `NaN` values correspond to the first row in both columns, where no previous row data is available for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90fa65f-b7b9-41f9-9c3a-9561378ea030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference nan: no mismatches.\n",
      "Difference 0.0: no mismatches.\n",
      "Difference 1.0: no mismatches.\n"
     ]
    }
   ],
   "source": [
    "for difference in fw_id_diff.unique():\n",
    "    mismatched_indices_check(fw_date_diff, fw_id_diff, difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0566c0-c418-4c03-9341-8aeed4ee05b5",
   "metadata": {},
   "source": [
    "The default order of the raw data for this dataframe is sorted by datetime, and the `data_block_id` reflects the actual data availability, with no errors observed in the `origin_datetime` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92af9350-9faf-43a3-8ac3-338aaae7f13f",
   "metadata": {},
   "source": [
    "## historical_weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9920a6bd-e99c-4fe1-97d7-62b6c0e66975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HEAD >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temperature</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>rain</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>surface_pressure</th>\n",
       "      <th>cloudcover_total</th>\n",
       "      <th>cloudcover_low</th>\n",
       "      <th>cloudcover_mid</th>\n",
       "      <th>cloudcover_high</th>\n",
       "      <th>windspeed_10m</th>\n",
       "      <th>winddirection_10m</th>\n",
       "      <th>shortwave_radiation</th>\n",
       "      <th>direct_solar_radiation</th>\n",
       "      <th>diffuse_radiation</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>14.20</td>\n",
       "      <td>11.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1015.90</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>7.08</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.60</td>\n",
       "      <td>21.70</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>13.90</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1010.70</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.11</td>\n",
       "      <td>359</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.60</td>\n",
       "      <td>22.20</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1015.00</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.33</td>\n",
       "      <td>355</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.60</td>\n",
       "      <td>22.70</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>14.60</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1017.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.08</td>\n",
       "      <td>297</td>\n",
       "      <td>358.00</td>\n",
       "      <td>277.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>57.60</td>\n",
       "      <td>23.20</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>15.70</td>\n",
       "      <td>12.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1014.00</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.42</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.60</td>\n",
       "      <td>23.70</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  temperature  dewpoint  rain  snowfall  \\\n",
       "0  2021-09-01 00:00:00        14.20     11.60  0.00      0.00   \n",
       "1  2021-09-01 00:00:00        13.90     11.50  0.00      0.00   \n",
       "2  2021-09-01 00:00:00        14.00     12.50  0.00      0.00   \n",
       "3  2021-09-01 00:00:00        14.60     11.50  0.00      0.00   \n",
       "4  2021-09-01 00:00:00        15.70     12.90  0.00      0.00   \n",
       "\n",
       "   surface_pressure  cloudcover_total  cloudcover_low  cloudcover_mid  \\\n",
       "0           1015.90                31              31               0   \n",
       "1           1010.70                33              37               0   \n",
       "2           1015.00                31              34               0   \n",
       "3           1017.30                 0               0               0   \n",
       "4           1014.00                22              25               0   \n",
       "\n",
       "   cloudcover_high  windspeed_10m  winddirection_10m  shortwave_radiation  \\\n",
       "0               11           7.08                  8                 0.00   \n",
       "1                0           5.11                359                 0.00   \n",
       "2                0           6.33                355                 0.00   \n",
       "3                0           8.08                297               358.00   \n",
       "4                0           8.42                  5                 0.00   \n",
       "\n",
       "   direct_solar_radiation  diffuse_radiation  latitude  longitude  \\\n",
       "0                    0.00               0.00     57.60      21.70   \n",
       "1                    0.00               0.00     57.60      22.20   \n",
       "2                    0.00               0.00     57.60      22.70   \n",
       "3                  277.00              81.00     57.60      23.20   \n",
       "4                    0.00               0.00     57.60      23.70   \n",
       "\n",
       "   data_block_id  \n",
       "0           1.00  \n",
       "1           1.00  \n",
       "2           1.00  \n",
       "3           1.00  \n",
       "4           1.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TAIL >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temperature</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>rain</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>surface_pressure</th>\n",
       "      <th>cloudcover_total</th>\n",
       "      <th>cloudcover_low</th>\n",
       "      <th>cloudcover_mid</th>\n",
       "      <th>cloudcover_high</th>\n",
       "      <th>windspeed_10m</th>\n",
       "      <th>winddirection_10m</th>\n",
       "      <th>shortwave_radiation</th>\n",
       "      <th>direct_solar_radiation</th>\n",
       "      <th>diffuse_radiation</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1710797</th>\n",
       "      <td>2023-05-30 10:00:00</td>\n",
       "      <td>11.70</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1018.90</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>253</td>\n",
       "      <td>567.00</td>\n",
       "      <td>392.00</td>\n",
       "      <td>175.00</td>\n",
       "      <td>59.70</td>\n",
       "      <td>26.20</td>\n",
       "      <td>637.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710798</th>\n",
       "      <td>2023-05-30 10:00:00</td>\n",
       "      <td>12.30</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1019.00</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>263</td>\n",
       "      <td>581.00</td>\n",
       "      <td>407.00</td>\n",
       "      <td>174.00</td>\n",
       "      <td>59.70</td>\n",
       "      <td>26.70</td>\n",
       "      <td>637.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710799</th>\n",
       "      <td>2023-05-30 10:00:00</td>\n",
       "      <td>9.80</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1019.20</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>285</td>\n",
       "      <td>609.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>177.00</td>\n",
       "      <td>59.70</td>\n",
       "      <td>27.20</td>\n",
       "      <td>637.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710800</th>\n",
       "      <td>2023-05-30 10:00:00</td>\n",
       "      <td>11.70</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1019.00</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>307</td>\n",
       "      <td>658.00</td>\n",
       "      <td>521.00</td>\n",
       "      <td>137.00</td>\n",
       "      <td>59.70</td>\n",
       "      <td>27.70</td>\n",
       "      <td>637.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710801</th>\n",
       "      <td>2023-05-30 10:00:00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1016.10</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>304</td>\n",
       "      <td>672.00</td>\n",
       "      <td>550.00</td>\n",
       "      <td>122.00</td>\n",
       "      <td>59.70</td>\n",
       "      <td>28.20</td>\n",
       "      <td>637.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime  temperature  dewpoint  rain  snowfall  \\\n",
       "1710797  2023-05-30 10:00:00        11.70      4.60  0.00      0.00   \n",
       "1710798  2023-05-30 10:00:00        12.30      3.50  0.00      0.00   \n",
       "1710799  2023-05-30 10:00:00         9.80      3.00  0.00      0.00   \n",
       "1710800  2023-05-30 10:00:00        11.70      1.60  0.00      0.00   \n",
       "1710801  2023-05-30 10:00:00        12.00      1.40  0.00      0.00   \n",
       "\n",
       "         surface_pressure  cloudcover_total  cloudcover_low  cloudcover_mid  \\\n",
       "1710797           1018.90                40               9              54   \n",
       "1710798           1019.00                46               4              70   \n",
       "1710799           1019.20                41               4              62   \n",
       "1710800           1019.00                44               0              73   \n",
       "1710801           1016.10                38               0              63   \n",
       "\n",
       "         cloudcover_high  windspeed_10m  winddirection_10m  \\\n",
       "1710797                0           1.06                253   \n",
       "1710798                0           0.81                263   \n",
       "1710799                0           1.97                285   \n",
       "1710800                0           3.50                307   \n",
       "1710801                0           3.25                304   \n",
       "\n",
       "         shortwave_radiation  direct_solar_radiation  diffuse_radiation  \\\n",
       "1710797               567.00                  392.00             175.00   \n",
       "1710798               581.00                  407.00             174.00   \n",
       "1710799               609.00                  432.00             177.00   \n",
       "1710800               658.00                  521.00             137.00   \n",
       "1710801               672.00                  550.00             122.00   \n",
       "\n",
       "         latitude  longitude  data_block_id  \n",
       "1710797     59.70      26.20         637.00  \n",
       "1710798     59.70      26.70         637.00  \n",
       "1710799     59.70      27.20         637.00  \n",
       "1710800     59.70      27.70         637.00  \n",
       "1710801     59.70      28.20         637.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MISSING VALUES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No missing values.\n",
      "\n",
      "DUPLICATES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No duplicate rows.\n",
      "\n",
      "TOTAL SIZE >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Total DataFrame size: 234 MB.\n",
      "\n",
      "SUMMARY >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>max_dec_len</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>not_na_count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datetime</td>\n",
       "      <td>object</td>\n",
       "      <td>13.05</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1710802</td>\n",
       "      <td>15275</td>\n",
       "      <td>2022-11-12 15:00:00</td>\n",
       "      <td>114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>temperature</td>\n",
       "      <td>float64</td>\n",
       "      <td>13.05</td>\n",
       "      <td>1</td>\n",
       "      <td>-23.70</td>\n",
       "      <td>32.60</td>\n",
       "      <td>1710802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.74</td>\n",
       "      <td>8.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.10</td>\n",
       "      <td>11.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dewpoint</td>\n",
       "      <td>float64</td>\n",
       "      <td>13.05</td>\n",
       "      <td>1</td>\n",
       "      <td>-25.90</td>\n",
       "      <td>23.80</td>\n",
       "      <td>1710802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.24</td>\n",
       "      <td>7.22</td>\n",
       "      <td>-2.60</td>\n",
       "      <td>1.70</td>\n",
       "      <td>7.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rain</td>\n",
       "      <td>float64</td>\n",
       "      <td>13.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.80</td>\n",
       "      <td>1710802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>snowfall</td>\n",
       "      <td>float64</td>\n",
       "      <td>13.05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1710802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>surface_pressure</td>\n",
       "      <td>float64</td>\n",
       "      <td>13.05</td>\n",
       "      <td>1</td>\n",
       "      <td>942.90</td>\n",
       "      <td>1049.30</td>\n",
       "      <td>1710802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1009.28</td>\n",
       "      <td>13.09</td>\n",
       "      <td>1001.50</td>\n",
       "      <td>1010.40</td>\n",
       "      <td>1018.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cloudcover_total</td>\n",
       "      <td>int64</td>\n",
       "      <td>13.05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1710802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.91</td>\n",
       "      <td>37.77</td>\n",
       "      <td>25.00</td>\n",
       "      <td>72.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cloudcover_low</td>\n",
       "      <td>int64</td>\n",
       "      <td>13.05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1710802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.69</td>\n",
       "      <td>40.75</td>\n",
       "      <td>3.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>94.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cloudcover_mid</td>\n",
       "      <td>int64</td>\n",
       "      <td>13.05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1710802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.41</td>\n",
       "      <td>38.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>72.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cloudcover_high</td>\n",
       "      <td>int64</td>\n",
       "      <td>13.05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1710802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.05</td>\n",
       "      <td>41.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>85.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>windspeed_10m</td>\n",
       "      <td>float64</td>\n",
       "      <td>13.05</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.75</td>\n",
       "      <td>1710802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.85</td>\n",
       "      <td>2.48</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>6.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>winddirection_10m</td>\n",
       "      <td>int64</td>\n",
       "      <td>13.05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>360.00</td>\n",
       "      <td>1710802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197.87</td>\n",
       "      <td>89.94</td>\n",
       "      <td>139.00</td>\n",
       "      <td>208.00</td>\n",
       "      <td>263.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>shortwave_radiation</td>\n",
       "      <td>float64</td>\n",
       "      <td>13.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>849.00</td>\n",
       "      <td>1710802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.49</td>\n",
       "      <td>179.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>140.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>direct_solar_radiation</td>\n",
       "      <td>float64</td>\n",
       "      <td>13.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>754.00</td>\n",
       "      <td>1710802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.45</td>\n",
       "      <td>133.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>47.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>diffuse_radiation</td>\n",
       "      <td>float64</td>\n",
       "      <td>13.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>388.00</td>\n",
       "      <td>1710802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.04</td>\n",
       "      <td>61.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>74.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>latitude</td>\n",
       "      <td>float64</td>\n",
       "      <td>13.05</td>\n",
       "      <td>1</td>\n",
       "      <td>57.60</td>\n",
       "      <td>59.70</td>\n",
       "      <td>1710802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.65</td>\n",
       "      <td>0.69</td>\n",
       "      <td>57.90</td>\n",
       "      <td>58.50</td>\n",
       "      <td>59.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>longitude</td>\n",
       "      <td>float64</td>\n",
       "      <td>13.05</td>\n",
       "      <td>1</td>\n",
       "      <td>21.70</td>\n",
       "      <td>28.20</td>\n",
       "      <td>1710802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.95</td>\n",
       "      <td>2.02</td>\n",
       "      <td>23.20</td>\n",
       "      <td>24.70</td>\n",
       "      <td>26.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>data_block_id</td>\n",
       "      <td>float64</td>\n",
       "      <td>13.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>637.00</td>\n",
       "      <td>1710802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>319.27</td>\n",
       "      <td>183.73</td>\n",
       "      <td>160.00</td>\n",
       "      <td>319.00</td>\n",
       "      <td>478.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    column    dtype  size_mb  max_dec_len    min     max  \\\n",
       "0                 datetime   object    13.05           -1    NaN     NaN   \n",
       "1              temperature  float64    13.05            1 -23.70   32.60   \n",
       "2                 dewpoint  float64    13.05            1 -25.90   23.80   \n",
       "3                     rain  float64    13.05            1   0.00   16.80   \n",
       "4                 snowfall  float64    13.05            2   0.00    2.66   \n",
       "5         surface_pressure  float64    13.05            1 942.90 1049.30   \n",
       "6         cloudcover_total    int64    13.05           -1   0.00  100.00   \n",
       "7           cloudcover_low    int64    13.05           -1   0.00  100.00   \n",
       "8           cloudcover_mid    int64    13.05           -1   0.00  100.00   \n",
       "9          cloudcover_high    int64    13.05           -1   0.00  100.00   \n",
       "10           windspeed_10m  float64    13.05           16   0.00   21.75   \n",
       "11       winddirection_10m    int64    13.05           -1   0.00  360.00   \n",
       "12     shortwave_radiation  float64    13.05            1   0.00  849.00   \n",
       "13  direct_solar_radiation  float64    13.05            1   0.00  754.00   \n",
       "14       diffuse_radiation  float64    13.05            1   0.00  388.00   \n",
       "15                latitude  float64    13.05            1  57.60   59.70   \n",
       "16               longitude  float64    13.05            1  21.70   28.20   \n",
       "17           data_block_id  float64    13.05            1   1.00  637.00   \n",
       "\n",
       "    not_na_count unique                  top freq    mean    std     25%  \\\n",
       "0        1710802  15275  2022-11-12 15:00:00  114     NaN    NaN     NaN   \n",
       "1        1710802    NaN                  NaN  NaN    5.74   8.03    0.00   \n",
       "2        1710802    NaN                  NaN  NaN    2.24   7.22   -2.60   \n",
       "3        1710802    NaN                  NaN  NaN    0.05   0.21    0.00   \n",
       "4        1710802    NaN                  NaN  NaN    0.02   0.07    0.00   \n",
       "5        1710802    NaN                  NaN  NaN 1009.28  13.09 1001.50   \n",
       "6        1710802    NaN                  NaN  NaN   60.91  37.77   25.00   \n",
       "7        1710802    NaN                  NaN  NaN   46.69  40.75    3.00   \n",
       "8        1710802    NaN                  NaN  NaN   34.41  38.33    0.00   \n",
       "9        1710802    NaN                  NaN  NaN   36.05  41.36    0.00   \n",
       "10       1710802    NaN                  NaN  NaN    4.85   2.48    3.00   \n",
       "11       1710802    NaN                  NaN  NaN  197.87  89.94  139.00   \n",
       "12       1710802    NaN                  NaN  NaN  106.49 179.94    0.00   \n",
       "13       1710802    NaN                  NaN  NaN   64.45 133.41    0.00   \n",
       "14       1710802    NaN                  NaN  NaN   42.04  61.95    0.00   \n",
       "15       1710802    NaN                  NaN  NaN   58.65   0.69   57.90   \n",
       "16       1710802    NaN                  NaN  NaN   24.95   2.02   23.20   \n",
       "17       1710802    NaN                  NaN  NaN  319.27 183.73  160.00   \n",
       "\n",
       "       50%     75%  \n",
       "0      NaN     NaN  \n",
       "1     5.10   11.20  \n",
       "2     1.70    7.20  \n",
       "3     0.00    0.00  \n",
       "4     0.00    0.00  \n",
       "5  1010.40 1018.00  \n",
       "6    72.00  100.00  \n",
       "7    39.00   94.00  \n",
       "8    16.00   72.00  \n",
       "9    10.00   85.00  \n",
       "10    4.50    6.28  \n",
       "11  208.00  263.00  \n",
       "12    1.00  140.00  \n",
       "13    0.00   47.00  \n",
       "14    1.00   74.00  \n",
       "15   58.50   59.10  \n",
       "16   24.70   26.70  \n",
       "17  319.00  478.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_show_info(historical_weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7de862-eb2e-4746-bd1e-3c4d6957f12d",
   "metadata": {},
   "source": [
    "- The `data_block_id` column type is `float64`, unlike in other dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b3b870-e0ed-4ee2-8879-265009971f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "# Checking if all values in data_block_id are \n",
    "# integers to avoid errors and allow conversion to int type\n",
    "\n",
    "print(np.unique(historical_weather_df.data_block_id.unique() %1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14a2630-f93e-4df8-8c0a-5bcfe7b072f3",
   "metadata": {},
   "source": [
    "No anomalous values; all have a remainder of 0 and can be converted to `uint16` type (which can store values from 0 to 65535), as the minimum value is 1 and the maximum is 637."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661bf2db-f164-49f7-996a-ca11fa3ddda0",
   "metadata": {},
   "source": [
    "- There are no missing values or duplicates in the dataframe.\n",
    "- The `data_block_id` is `float64` because the data in the original file is in \"n.0\" format.\n",
    "- The `data_block_id` values start from 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea286927-6a59-4770-95c5-7ceee7ab1f4e",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef928f21-d548-40f2-a3ad-f7565237f939",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_weather_df[[\"latitude\", \"longitude\"]] = historical_weather_df[\n",
    "    [\"latitude\", \"longitude\"]\n",
    "].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2211a709-a42b-4c6b-b052-0f3144a06d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save unique historical weather locations for later comparison with\n",
    "# forecast locations\n",
    "h_unique_coords = unique_locations(historical_weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8781f68b-e47b-4c8b-a5aa-33b50d38fa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after transformation: 81 MB.\n"
     ]
    }
   ],
   "source": [
    "historical_weather_df[[\"latitude\", \"longitude\"]] = historical_weather_df[\n",
    "    [\"latitude\", \"longitude\"]\n",
    "].mul(10)\n",
    "historical_weather_df = historical_weather_df.astype(\n",
    "    {\n",
    "        \"datetime\": \"datetime64[ns]\",\n",
    "        \"temperature\": \"float32\",\n",
    "        \"dewpoint\": \"float32\",\n",
    "        \"rain\": \"float32\",\n",
    "        \"snowfall\": \"float32\",\n",
    "        \"surface_pressure\": \"float32\",\n",
    "        \"cloudcover_total\": \"uint8\",\n",
    "        \"cloudcover_low\": \"uint8\",\n",
    "        \"cloudcover_mid\": \"uint8\",\n",
    "        \"cloudcover_high\": \"uint8\",\n",
    "        \"windspeed_10m\": \"float32\",\n",
    "        \"winddirection_10m\": \"uint16\",\n",
    "        \"shortwave_radiation\": \"uint16\",\n",
    "        \"direct_solar_radiation\": \"uint16\",\n",
    "        \"diffuse_radiation\": \"uint16\",\n",
    "        \"latitude\": \"uint16\",\n",
    "        \"longitude\": \"uint16\",\n",
    "        \"data_block_id\": \"uint16\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Size after transformation: {total_size(historical_weather_df)} MB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b34275-39c0-4fb0-9bb6-8dfaadc9f14b",
   "metadata": {},
   "source": [
    "### Consistency and Relationship Validation\n",
    "Ensure `datetime` values are coherent within respective `latitude` and `longitude` groups.\n",
    "#### Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af1d1f5-71bd-4608-badb-3a153dc49e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "True     110\n",
       "False      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sameness check\n",
    "historical_geo_gb = historical_weather_df.groupby([\"latitude\", \"longitude\"])\n",
    "sg_hw = same_groups(historical_geo_gb, \"datetime\")\n",
    "sg_hw.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291080aa-d3ba-46b4-88bc-d5b1fb425d04",
   "metadata": {},
   "source": [
    "Unlike in `forecast_weather_df`, this dataframe contains 2 unique `datetime` sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24634f8-9de0-4bee-9a31-699997355ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(576, 217),\n",
       "            (576, 232)],\n",
       "           names=['latitude', 'longitude'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify indices of the first entries with differing datetime\n",
    "# combinations\n",
    "dupl_coord = sg_hw[~sg_hw].index\n",
    "dupl_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073e0178-7188-4264-bed1-2b82f6ff5b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude 576, longitude 217:\n",
      "duplicates 110,\n",
      "length of timestamp sequence: 15275.\n",
      "\n",
      "Latitude 576, longitude 232:\n",
      "duplicates 2,\n",
      "length of timestamp sequence: 15276.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the number of duplicates for both combinations\n",
    "hist_geo_datetime = historical_geo_gb[\"datetime\"].agg(tuple)\n",
    "\n",
    "for latitude, longitude in dupl_coord:\n",
    "    duplicates_count = (\n",
    "        hist_geo_datetime == hist_geo_datetime[latitude, longitude]\n",
    "    ).sum()\n",
    "    seq_l = len(hist_geo_datetime[latitude, longitude])\n",
    "    print(\n",
    "        f\"Latitude {latitude}, longitude {longitude}:\\n\",\n",
    "        f\"duplicates {duplicates_count},\\n\",\n",
    "        f\"length of timestamp sequence: {seq_l}.\\n\",\n",
    "        sep=\"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f94b2-73f6-4a9e-8aa9-d52700d178bf",
   "metadata": {},
   "source": [
    "The second datetime combination has only two duplicated entries. The tuple lengths differ by one element, likely due to a skipped or duplicated value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf826cab-fc35-417e-9343-5a89b62a48db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2021-09-01 00:00:00\n",
       "1       2021-09-01 01:00:00\n",
       "2       2021-09-01 02:00:00\n",
       "3       2021-09-01 03:00:00\n",
       "4       2021-09-01 04:00:00\n",
       "                ...        \n",
       "15270   2023-05-30 06:00:00\n",
       "15271   2023-05-30 07:00:00\n",
       "15272   2023-05-30 08:00:00\n",
       "15273   2023-05-30 09:00:00\n",
       "15274   2023-05-30 10:00:00\n",
       "Name: datetime, Length: 15275, dtype: datetime64[ns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_s = historical_weather_df[\n",
    "    (historical_weather_df[\"latitude\"] == dupl_coord[0][0])\n",
    "    & (historical_weather_df[\"longitude\"] == dupl_coord[0][1])\n",
    "].datetime.reset_index(drop=True)\n",
    "first_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776b6bcd-b0a6-432a-b684-f2b21fd5072c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2021-09-01 00:00:00\n",
       "1       2021-09-01 01:00:00\n",
       "2       2021-09-01 02:00:00\n",
       "3       2021-09-01 03:00:00\n",
       "4       2021-09-01 04:00:00\n",
       "                ...        \n",
       "15271   2023-05-30 06:00:00\n",
       "15272   2023-05-30 07:00:00\n",
       "15273   2023-05-30 08:00:00\n",
       "15274   2023-05-30 09:00:00\n",
       "15275   2023-05-30 10:00:00\n",
       "Name: datetime, Length: 15276, dtype: datetime64[ns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_s = historical_weather_df[\n",
    "    (historical_weather_df[\"latitude\"] == dupl_coord[1][0])\n",
    "    & (historical_weather_df[\"longitude\"] == dupl_coord[1][1])\n",
    "].datetime.reset_index(drop=True)\n",
    "second_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba7ee2c-3e11-46a1-9e7b-5a65dcf786c8",
   "metadata": {},
   "source": [
    "The first and last values are the same in both series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2961f9dc-fec8-4d78-82de-f4d911afedc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10504"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the first index where values differ. The last element of the\n",
    "# second series is excluded due to the length mismatch.\n",
    "np.argmax(first_s != second_s[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b9635-76c0-49d5-9449-6b5c3fea1942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude 576, Longitude 217:\n",
      "10503   2022-11-12 15:00:00\n",
      "10504   2022-11-12 16:00:00\n",
      "10505   2022-11-12 17:00:00\n",
      "Name: datetime, dtype: datetime64[ns]\n",
      "\n",
      "Latitude 576, Longitude 232:\n",
      "10503   2022-11-12 15:00:00\n",
      "10504   2022-11-12 15:00:00\n",
      "10505   2022-11-12 16:00:00\n",
      "Name: datetime, dtype: datetime64[ns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, s in enumerate((first_s, second_s)):\n",
    "    print(\n",
    "        f\"Latitude {dupl_coord[idx][0]}, Longitude {dupl_coord[idx][1]}:\\n\"\n",
    "        f\"{s[10503:10506]}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64541d68-1670-41a8-b951-c896b14093b3",
   "metadata": {},
   "source": [
    "Duplicated values do not seem unusual, so it is necessary to compare other values at these timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83c4ed1-ab05-43bc-9205-2f03141bd633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temperature</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>rain</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>surface_pressure</th>\n",
       "      <th>cloudcover_total</th>\n",
       "      <th>cloudcover_low</th>\n",
       "      <th>cloudcover_mid</th>\n",
       "      <th>cloudcover_high</th>\n",
       "      <th>windspeed_10m</th>\n",
       "      <th>winddirection_10m</th>\n",
       "      <th>shortwave_radiation</th>\n",
       "      <th>direct_solar_radiation</th>\n",
       "      <th>diffuse_radiation</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1176336</th>\n",
       "      <td>2022-11-12 15:00:00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1023.10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>6.78</td>\n",
       "      <td>149</td>\n",
       "      <td>117</td>\n",
       "      <td>71</td>\n",
       "      <td>46</td>\n",
       "      <td>576</td>\n",
       "      <td>217</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime  temperature  dewpoint  rain  snowfall  \\\n",
       "1176336 2022-11-12 15:00:00        13.00     10.40  0.00      0.00   \n",
       "\n",
       "         surface_pressure  cloudcover_total  cloudcover_low  cloudcover_mid  \\\n",
       "1176336           1023.10                 4               0               0   \n",
       "\n",
       "         cloudcover_high  windspeed_10m  winddirection_10m  \\\n",
       "1176336               12           6.78                149   \n",
       "\n",
       "         shortwave_radiation  direct_solar_radiation  diffuse_radiation  \\\n",
       "1176336                  117                      71                 46   \n",
       "\n",
       "         latitude  longitude  data_block_id  \n",
       "1176336       576        217            439  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temperature</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>rain</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>surface_pressure</th>\n",
       "      <th>cloudcover_total</th>\n",
       "      <th>cloudcover_low</th>\n",
       "      <th>cloudcover_mid</th>\n",
       "      <th>cloudcover_high</th>\n",
       "      <th>windspeed_10m</th>\n",
       "      <th>winddirection_10m</th>\n",
       "      <th>shortwave_radiation</th>\n",
       "      <th>direct_solar_radiation</th>\n",
       "      <th>diffuse_radiation</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1176339</th>\n",
       "      <td>2022-11-12 15:00:00</td>\n",
       "      <td>14.80</td>\n",
       "      <td>12.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1017.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7.19</td>\n",
       "      <td>309</td>\n",
       "      <td>526</td>\n",
       "      <td>403</td>\n",
       "      <td>123</td>\n",
       "      <td>576</td>\n",
       "      <td>232</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176340</th>\n",
       "      <td>2022-11-12 15:00:00</td>\n",
       "      <td>15.40</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1014.40</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7.11</td>\n",
       "      <td>349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>232</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime  temperature  dewpoint  rain  snowfall  \\\n",
       "1176339 2022-11-12 15:00:00        14.80     12.40  0.00      0.00   \n",
       "1176340 2022-11-12 15:00:00        15.40     13.00  0.00      0.00   \n",
       "\n",
       "         surface_pressure  cloudcover_total  cloudcover_low  cloudcover_mid  \\\n",
       "1176339           1017.00                 4               0               7   \n",
       "1176340           1014.40                 4               2               4   \n",
       "\n",
       "         cloudcover_high  windspeed_10m  winddirection_10m  \\\n",
       "1176339                0           7.19                309   \n",
       "1176340                0           7.11                349   \n",
       "\n",
       "         shortwave_radiation  direct_solar_radiation  diffuse_radiation  \\\n",
       "1176339                  526                     403                123   \n",
       "1176340                    0                       0                  0   \n",
       "\n",
       "         latitude  longitude  data_block_id  \n",
       "1176339       576        232            439  \n",
       "1176340       576        232            439  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for lat, lon in dupl_coord:\n",
    "    display(\n",
    "        historical_weather_df[\n",
    "            (historical_weather_df[\"latitude\"] == lat)\n",
    "            & (historical_weather_df[\"longitude\"] == lon)\n",
    "            & (\n",
    "                historical_weather_df[\"datetime\"]\n",
    "                == pd.Timestamp(\"2022-11-12 15:00:00\")\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f9c8f-725f-45d5-8cf7-5da0527a0e6b",
   "metadata": {},
   "source": [
    "Features with non-zero values display minimal variation, whereas those with zero values show significant differences. This issue can be addressed by either discarding one of the entries or computing the arithmetic mean. Introducing a flag column for only one duplicate is unwarranted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f340339b-684e-4574-8ade-6a6cc7e1e0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude 576, longitude 217:\n",
      "datetime\n",
      "0 days 01:00:00    15274\n",
      "NaT                    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Latitude 576, longitude 232:\n",
      "datetime\n",
      "0 days 01:00:00    15274\n",
      "NaT                    1\n",
      "0 days 00:00:00        1\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the counts of unique differences between consecutive datetime\n",
    "# values for both series.\n",
    "\n",
    "for lat, lon in dupl_coord:\n",
    "    diff_counts = (\n",
    "        historical_weather_df[\n",
    "            (historical_weather_df[\"latitude\"] == lat)\n",
    "            & (historical_weather_df[\"longitude\"] == lon)\n",
    "        ][\"datetime\"]\n",
    "        .diff()\n",
    "        .value_counts(dropna=False)\n",
    "    )\n",
    "    print(f\"Latitude {lat}, longitude {lon}:\\n{diff_counts}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fb95f5-0a7c-4ce0-8275-b5d8c19ac0ad",
   "metadata": {},
   "source": [
    "- `NaT`: corresponds to the first row in each group.\n",
    "- `0 days 01:00:00`: indicates the transition from one hour to the next.\n",
    "- `0 days 00:00:00`: indicate duplicates.\n",
    "\n",
    "Based on these differences, it can be concluded that the data in this dataframe is sorted by `datetime` by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059b3ee6-b744-4729-bacf-f6e77c319d93",
   "metadata": {},
   "source": [
    "#### data_block_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edef438-9017-4802-ab0b-ea8fd9bfba48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_block_id\n",
       "0.00    1710165\n",
       "1.00        636\n",
       "NaN           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_weather_df.data_block_id.diff().value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8495cdb8-8bdb-426c-b48d-71c94a695ee4",
   "metadata": {},
   "source": [
    "All `data_block_id` values also increase incrementally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f1a11-c115-44ad-b10c-b768d0ed4c28",
   "metadata": {},
   "source": [
    "## station_county_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aad6d7-9159-4978-a1b6-b4c06744319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HEAD >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_name</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21.70</td>\n",
       "      <td>57.60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21.70</td>\n",
       "      <td>57.90</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21.70</td>\n",
       "      <td>58.20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21.70</td>\n",
       "      <td>58.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21.70</td>\n",
       "      <td>58.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  county_name  longitude  latitude  county\n",
       "0         NaN      21.70     57.60     NaN\n",
       "1         NaN      21.70     57.90     NaN\n",
       "2         NaN      21.70     58.20     NaN\n",
       "3         NaN      21.70     58.50     NaN\n",
       "4         NaN      21.70     58.80     NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TAIL >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_name</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.20</td>\n",
       "      <td>58.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.20</td>\n",
       "      <td>58.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.20</td>\n",
       "      <td>59.10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.20</td>\n",
       "      <td>59.40</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.20</td>\n",
       "      <td>59.70</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    county_name  longitude  latitude  county\n",
       "107         NaN      28.20     58.50     NaN\n",
       "108         NaN      28.20     58.80     NaN\n",
       "109         NaN      28.20     59.10     NaN\n",
       "110         NaN      28.20     59.40     NaN\n",
       "111         NaN      28.20     59.70     NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MISSING VALUES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "county_name    63\n",
       "county         63\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DUPLICATES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No duplicate rows.\n",
      "\n",
      "TOTAL SIZE >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Total DataFrame size: 0 MB.\n",
      "\n",
      "SUMMARY >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>max_dec_len</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>not_na_count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>county_name</td>\n",
       "      <td>object</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>15</td>\n",
       "      <td>Harjumaa</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>longitude</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>21.70</td>\n",
       "      <td>28.20</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.95</td>\n",
       "      <td>2.02</td>\n",
       "      <td>23.20</td>\n",
       "      <td>24.95</td>\n",
       "      <td>26.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>latitude</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15</td>\n",
       "      <td>57.60</td>\n",
       "      <td>59.70</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.65</td>\n",
       "      <td>0.69</td>\n",
       "      <td>58.12</td>\n",
       "      <td>58.65</td>\n",
       "      <td>59.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>county</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.06</td>\n",
       "      <td>4.87</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        column    dtype  size_mb  max_dec_len   min   max  not_na_count  \\\n",
       "0  county_name   object     0.00           -1   NaN   NaN            49   \n",
       "1    longitude  float64     0.00            1 21.70 28.20           112   \n",
       "2     latitude  float64     0.00           15 57.60 59.70           112   \n",
       "3       county  float64     0.00            1  0.00 15.00            49   \n",
       "\n",
       "  unique       top freq  mean  std   25%   50%   75%  \n",
       "0     15  Harjumaa    6   NaN  NaN   NaN   NaN   NaN  \n",
       "1    NaN       NaN  NaN 24.95 2.02 23.20 24.95 26.70  \n",
       "2    NaN       NaN  NaN 58.65 0.69 58.12 58.65 59.17  \n",
       "3    NaN       NaN  NaN  7.06 4.87  3.00  7.00 11.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_show_info(station_county_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e07df2b-bc2e-4221-8452-574b4602c768",
   "metadata": {},
   "source": [
    "- More than half of the values are missing in two columns. This is likely because the dataframe covers the outer areas around Estonia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3751f18-1c92-4bf5-a4ed-94c07ccab992",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc293ae-2879-423b-8caa-198a41b40314",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_county_mapping[[\"latitude\", \"longitude\"]] = station_county_mapping[\n",
    "    [\"latitude\", \"longitude\"]\n",
    "].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f322767-81f5-4149-9513-f5e503a7a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save unique station mapping locations for later comparison with\n",
    "# historical and forecast data\n",
    "# s_unique_coords = unique_locations(station_county_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73ba20-55a6-4e46-a2b1-70e0fe9d67e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after transformation: 0 MB.\n"
     ]
    }
   ],
   "source": [
    "station_county_mapping = station_county_mapping[\n",
    "    [\"county_name\", \"county\", \"latitude\", \"longitude\"]\n",
    "]\n",
    "# station_county_mapping[[\"latitude\", \"longitude\"]] = (\n",
    "    # station_county_mapping[[\"latitude\", \"longitude\"]].mul(10)\n",
    "# )\n",
    "station_county_mapping = station_county_mapping.astype(\n",
    "    {\n",
    "        \"county_name\": \"category\",\n",
    "        # \"latitude\": \"uint16\",\n",
    "        # \"longitude\": \"uint16\",\n",
    "        \"county\": \"category\",\n",
    "    }\n",
    ").sort_values([\"latitude\", \"longitude\"])\n",
    "\n",
    "print(f\"Size after transformation: {total_size(station_county_mapping)} MB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54c344f-8138-4ee5-88a3-9760bd791bf6",
   "metadata": {},
   "source": [
    "## county_id_to_name_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d68c097-0470-4f60-a6a1-a0ec3c01b3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Harjumaa\n",
       "1           Hiiumaa\n",
       "2       Ida-virumaa\n",
       "3          JÃ¤rvamaa\n",
       "4         JÃµgevamaa\n",
       "5     LÃ¤Ã¤ne-virumaa\n",
       "6          LÃ¤Ã¤nemaa\n",
       "7          PÃ¤rnumaa\n",
       "8          PÃµlvamaa\n",
       "9          Raplamaa\n",
       "10         Saaremaa\n",
       "11         Tartumaa\n",
       "12          Unknown\n",
       "13         Valgamaa\n",
       "14      Viljandimaa\n",
       "15          VÃµrumaa\n",
       "dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_id_to_name_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d464b8-4691-4b01-a232-ac102d8a0fd1",
   "metadata": {},
   "source": [
    "The value `Unknown` can be interpreted in multiple ways. Firstly, it may represent missing values. Secondly, it could indicate a business that spans a very large area and is physically located in multiple counties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5bd7e-08b1-4cad-bb42-4c8a35c90bdc",
   "metadata": {},
   "source": [
    "## Data Merging\n",
    "### Locations\n",
    "\n",
    "Verify that all unique locations in `forecast_weather_df`, `historical_weather_df`, and `station_county_mapping` match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffbfff3-8df9-4e3f-8de6-a0c3e4ed72b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude     0\n",
       "longitude    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f_unique_coords != h_unique_coords).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da4c92-edd4-49b1-bbed-aa3f96370cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.60</td>\n",
       "      <td>21.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>57.60</td>\n",
       "      <td>22.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>57.60</td>\n",
       "      <td>22.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>57.60</td>\n",
       "      <td>23.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>57.60</td>\n",
       "      <td>23.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>59.70</td>\n",
       "      <td>26.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>59.70</td>\n",
       "      <td>26.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>59.70</td>\n",
       "      <td>27.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>59.70</td>\n",
       "      <td>27.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>59.70</td>\n",
       "      <td>28.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     latitude  longitude\n",
       "0       57.60      21.70\n",
       "8       57.60      22.20\n",
       "16      57.60      22.70\n",
       "24      57.60      23.20\n",
       "32      57.60      23.70\n",
       "..        ...        ...\n",
       "79      59.70      26.20\n",
       "87      59.70      26.70\n",
       "95      59.70      27.20\n",
       "103     59.70      27.70\n",
       "111     59.70      28.20\n",
       "\n",
       "[112 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_county_mapping[[\"latitude\", \"longitude\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f6b4e-c208-4b54-a746-033476368b5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled (both index and columns) DataFrame objects",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_506/1246722009.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# (f_unique_coords != s_unique_coords).sum()\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m f_unique_coords != station_county_mapping[[\u001b[33m\"latitude\"\u001b[39m, \u001b[33m\"longitude\"\u001b[39m]]\n",
      "\u001b[32m~/.cache/pypoetry/virtualenvs/jlpe-9TtSrW0h-py3.12/lib/python3.12/site-packages/pandas/core/ops/common.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m                     \u001b[38;5;28;01mreturn\u001b[39;00m NotImplemented\n\u001b[32m     73\u001b[39m \n\u001b[32m     74\u001b[39m         other = item_from_zerodim(other)\n\u001b[32m     75\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m method(self, other)\n",
      "\u001b[32m~/.cache/pypoetry/virtualenvs/jlpe-9TtSrW0h-py3.12/lib/python3.12/site-packages/pandas/core/arraylike.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     42\u001b[39m     @unpack_zerodim_and_defer(\u001b[33m\"__ne__\"\u001b[39m)\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __ne__(self, other):\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._cmp_method(other, operator.ne)\n",
      "\u001b[32m~/.cache/pypoetry/virtualenvs/jlpe-9TtSrW0h-py3.12/lib/python3.12/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   7894\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _cmp_method(self, other, op):\n\u001b[32m   7895\u001b[39m         axis: Literal[\u001b[32m1\u001b[39m] = \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# only relevant for Series other case\u001b[39;00m\n\u001b[32m   7896\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m7897\u001b[39m         self, other = self._align_for_op(other, axis, flex=\u001b[38;5;28;01mFalse\u001b[39;00m, level=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   7898\u001b[39m \n\u001b[32m   7899\u001b[39m         \u001b[38;5;66;03m# See GH#4537 for discussion of scalar op behavior\u001b[39;00m\n\u001b[32m   7900\u001b[39m         new_data = self._dispatch_frame_op(other, op, axis=axis)\n",
      "\u001b[32m~/.cache/pypoetry/virtualenvs/jlpe-9TtSrW0h-py3.12/lib/python3.12/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, other, axis, flex, level)\u001b[39m\n\u001b[32m   8192\u001b[39m                     left, right = left.align(\n\u001b[32m   8193\u001b[39m                         right, join=\u001b[33m\"outer\"\u001b[39m, level=level, copy=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   8194\u001b[39m                     )\n\u001b[32m   8195\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m8196\u001b[39m                     raise ValueError(\n\u001b[32m   8197\u001b[39m                         \u001b[33m\"Can only compare identically-labeled (both index and columns) \"\u001b[39m\n\u001b[32m   8198\u001b[39m                         \u001b[33m\"DataFrame objects\"\u001b[39m\n\u001b[32m   8199\u001b[39m                     )\n",
      "\u001b[31mValueError\u001b[39m: Can only compare identically-labeled (both index and columns) DataFrame objects"
     ]
    }
   ],
   "source": [
    "# (f_unique_coords != s_unique_coords).sum()\n",
    "# f_unique_coords != station_county_mapping[[\"latitude\", \"longitude\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8532828b-2b1b-451a-a5a4-91a4196c0d9a",
   "metadata": {},
   "source": [
    "Coordinates of all points from the three dataframes are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faa1e50-c28e-4719-8d32-08cbea1818ca",
   "metadata": {},
   "source": [
    "#### Visualize all unique location points on an Estonia map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed87118-fb49-4e44-ad67-e7077f4ac904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract county names and their centroid coordinates for labeling\n",
    "region_names, centroid_lats, centroid_lons = [], [], []\n",
    "\n",
    "for feature in estonia_geojson[\"features\"]:\n",
    "    region_name = (\n",
    "        feature[\"properties\"].get(\"name\")\n",
    "        or feature[\"properties\"].get(\"NAME\")\n",
    "        or \"Unknown\"\n",
    "    )\n",
    "    geom = shape(feature[\"geometry\"])\n",
    "    centroid = geom.centroid\n",
    "    region_names.append(region_name)\n",
    "    centroid_lats.append(centroid.y)\n",
    "    centroid_lons.append(centroid.x)\n",
    "\n",
    "    print(region_name, ', ', centroid.y, ', ', centroid.x, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191bee71-3904-4c21-9528-2e3dab8f1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_unique_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c60e41-c862-4bfb-920a-d3133bbda1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_map(\n",
    "    data_frame=f_unique_coords,\n",
    "    lat=\"latitude\",\n",
    "    lon=\"longitude\",\n",
    "    zoom=6.4,\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    map=dict(\n",
    "        layers=[\n",
    "            dict(\n",
    "                sourcetype=\"geojson\",\n",
    "                source=estonia_geojson,\n",
    "                type=\"line\",\n",
    "                color=\"black\",\n",
    "                line=dict(width=0.5),\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scattermap(\n",
    "        lat=centroid_lats,\n",
    "        lon=centroid_lons,\n",
    "        mode=\"text\",\n",
    "        text=region_names,\n",
    "        textfont=dict(size=12, color=\"black\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "# fig.write_image(\"map.png\")\n",
    "# from IPython.display import Image\n",
    "# Image(\"map.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a31a11-f18a-4da8-b43e-09723caba285",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_county_mapping.loc[station_county_mapping['latitude'] == 579]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fda6984-3301-4f97-a173-0701434e73d6",
   "metadata": {},
   "source": [
    "### DataFrames Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f22ce9-f979-4e67-a077-f3398f4bb291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left=train_df, right=gas_prices_df, how='left', on=['data_block_id'], validate='m:1')\n",
    "df = pd.merge(left=df, right=client_df, how='left', on=['product_type', 'county', 'is_business', 'data_block_id'], validate='m:1')\n",
    "electricity_prices_df['datetime'] = electricity_prices_df['electricity_origin_datetime'] + pd.Timedelta(2, 'd')\n",
    "df = pd.merge(left=df, right=electricity_prices_df, how='left', on=['datetime'], validate='m:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f143528-d8a4-42d4-804f-d46457bb0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(f_unique_coords != h_unique_coords).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02285f23-3873-4854-bc02-ab2ac65012cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(f_unique_coords != s_unique_coords).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067586de-fb36-40e8-b996-8adf839dafe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.merge(left=train_df, right=gas_prices_df, how='left', on=['data_block_id'], validate='m:1')\n",
    "# test_df = pd.merge(left=test_df, right=client_df, how='left', on=['product_type', 'county', 'is_business', 'data_block_id'], validate='m:1')\n",
    "# electricity_prices_df['datetime'] = electricity_prices_df['electricity_origin_datetime'] + pd.Timedelta(2, 'd')\n",
    "# test_df = pd.merge(left=test_df, right=electricity_prices_df, how='left', on=['datetime'], validate='m:1')\n",
    "\n",
    "# forecast_weather_df\n",
    "# historical_weather_df\n",
    "# station_county_mapping\n",
    "# county_id_to_name_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6768f81-058e-4424-b932-32c682d77d71",
   "metadata": {},
   "source": [
    "# 4. EDA\n",
    "## Target\n",
    "### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c78a3d-03ee-4f5f-8a6d-eebb94736a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new time-related features based on datetime\n",
    "\n",
    "# df[\"hour\"] = df[\"datetime\"].dt.hour.astype(\"uint8\")\n",
    "# df[\"day_of_week\"] = df[\"datetime\"].dt.day_of_week.astype(\"uint8\")\n",
    "# df[\"day\"] = df[\"datetime\"].dt.day.astype(\"uint16\")\n",
    "# df[\"week_of_year\"] = df[\"datetime\"].dt.isocalendar().week.astype(\"int8\")\n",
    "# df[\"month\"] = df[\"datetime\"].dt.month.astype(\"int8\")\n",
    "df[\"month\"] = df[\"datetime\"].dt.month.astype(\"category\")\n",
    "# df[\"quarter\"] = df[\"datetime\"].dt.quarter.astype(\"int8\")\n",
    "# df[\"year\"] = df[\"datetime\"].dt.year.astype(\"uint16\")\n",
    "df[\"year\"] = df[\"datetime\"].dt.year.astype(\"category\")\n",
    "\n",
    "# df[\"date\"] = df[\"datetime\"].dt.date\n",
    "df[\"date\"] = df[\"datetime\"].dt.date.astype(\"category\")\n",
    "df[\"year_week\"] = df['datetime'].dt.strftime('%Y-%W').astype(\"category\")\n",
    "df[\"year_month\"] = df['datetime'].dt.strftime('%Y-%m').astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779643df-d453-4315-bbee-0112c335787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating target's discrete intervals\n",
    "bins = 10\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "target_bins_percentage = round(\n",
    "    pd.cut(np.array(df.target), bins, precision=0).value_counts()\n",
    "    / df.shape[0]\n",
    "    * 100,\n",
    "    2,\n",
    ")\n",
    "\n",
    "# Due to rounding, the sum of percentages is not exactly 100.0, so\n",
    "# adjust the first value to ensure the total sum is 100.0.\n",
    "target_bins_percentage[0] += 100 - target_bins_percentage.sum()\n",
    "target_bins_percentage = [f\"{i:.2f}%\" for i in target_bins_percentage]\n",
    "\n",
    "target_max = df.target.max()\n",
    "ticks = range(0, int(target_max) + 1, int(target_max / bins))\n",
    "\n",
    "ax = sns.histplot(\n",
    "    df.target,\n",
    "    bins=bins,\n",
    "    kde=True,\n",
    "    linewidth=0.5,\n",
    ")\n",
    "\n",
    "# Adding group percentage to the top of each bar\n",
    "ax.bar_label(ax.containers[0], target_bins_percentage, padding=6, fontsize=11)\n",
    "\n",
    "plt.xticks(ticks=ticks, rotation=0)\n",
    "\n",
    "# Using a logarithmic scale for the y-axis for better visualization\n",
    "# of small quantities of target values\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.title(\n",
    "    f\"Histogram of {bins} discrete bins of the target values with KDE-line\",\n",
    "    fontsize=13\n",
    ")\n",
    "plt.xlabel(\"Target values\", fontsize=10)\n",
    "plt.ylabel(\"Count, log scale\", fontsize=10, rotation=0, labelpad=45)\n",
    "plt.grid(False, axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127b5ac5-fe6d-42e8-bbbe-4912c562dacc",
   "metadata": {},
   "source": [
    "- The target distribution is non-normal and right-skewed, likely because many prosumers are individuals with contracts for their homes, resulting in lower consumption/generation values.\n",
    "- The first discrete bin contains more values than all the other bins combined, with the KDE line confirming that most values are concentrated below 500 (which corresponds to roughly the lower third of the range of the first bin on the x-axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa9a5ed-8d33-48e7-b4ee-8ad8a40aeda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = 3  # The number of boxenplot levels\n",
    "\n",
    "# list with data for additional lines and text started from .25 because\n",
    "# lower corresponding percentiles are the same\n",
    "\n",
    "levels_list = [0.25] + np.cumsum(\n",
    "    [0.5 / pow(2, i) for i in range(levels + 1)]\n",
    ").tolist()\n",
    "levels_values = df.target.describe(levels_list)[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c42b314-83d3-42dc-9d62-ce61fa2fde2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 8))\n",
    "ax = sns.boxenplot(\n",
    "    df,\n",
    "    y=\"target\",\n",
    "    linewidth=0,\n",
    "    k_depth=levels,\n",
    "    flier_kws={\n",
    "        \"marker\": \".\",\n",
    "        \"s\": 0.1,\n",
    "    },\n",
    ")\n",
    "\n",
    "ax.set_xlim(ax.get_xlim()[0], ax.get_xlim()[1])\n",
    "\n",
    "plt.hlines(\n",
    "    levels_values.values,\n",
    "    0,\n",
    "    ax.get_xlim()[1],\n",
    "    \"tab:orange\",\n",
    "    lw=1.2,\n",
    ")\n",
    "\n",
    "for ix, l in enumerate(levels_values):\n",
    "    plt.text(\n",
    "        ax.get_xlim()[1] + 0.03,\n",
    "        levels_values.values[ix],\n",
    "        f\"{levels_values.index[ix]}: {levels_values.values[ix]:.2f}\",\n",
    "        fontsize=11,\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "    )\n",
    "\n",
    "ax.set_ylim(-0.1, 30_000)\n",
    "plt.yscale(\"symlog\", linthresh=1)\n",
    "plt.title(f\"Boxenplot of the target values with {levels} levels\", fontsize=13)\n",
    "plt.ylabel(\"Target values, log scale\", fontsize=10, rotation=0, labelpad=65)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df2c8d5-4405-47b7-b54f-92943f139cc0",
   "metadata": {},
   "source": [
    "- Q<sub>1</sub> â‰ˆ 0.38\n",
    "- Q<sub>2</sub> â‰ˆ 31.13\n",
    "- Q<sub>3</sub> â‰ˆ 180.21\n",
    "\n",
    "There are only two levels on the Q<sub>1</sub> side of the boxenplot (as opposed to three levels on the Q<sub>3</sub> side), which means that there is a huge number of identical values that cannot be separated. That is, two different percentiles (6.25% and 12.5%) have the same value, which equal to the minimum value - 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b8e51-1fbd-469e-8c2b-8b58785bba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.target.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e0b346-07d0-4a33-aa46-6a7a3f7b035d",
   "metadata": {},
   "source": [
    "Zero values are the most common and occur in more than 10% of the cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe34465-1880-4666-bcef-c29f0bf9f5d4",
   "metadata": {},
   "source": [
    "### Target Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ba38f7-9470-4c78-a812-69af3ed2b272",
   "metadata": {},
   "source": [
    "Since the target variable represents two different types of energy usage, it might be clearer to plot them separately rather than as a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f274c067-8a86-4adf-983e-22b734a4e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class imbalance\n",
    "df['is_consumption'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0039849a-9a59-4fa5-a222-d3701273e83a",
   "metadata": {},
   "source": [
    "Both classes have equal numbers of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ea5416-7d14-47f0-808b-82c29bf29dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumption values are multiplied by (-1) for better visualisation\n",
    "df[\"modified_target\"] = np.where(\n",
    "    df[\"is_consumption\"] == \"consumption\",\n",
    "    df[\"target\"].mul(-1),\n",
    "    df[\"target\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f46883-d283-46f4-8c0c-27d0b5500ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13, 8))\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x=\"datetime\",\n",
    "    y=\"modified_target\",\n",
    "    hue=\"is_consumption\",\n",
    "    s=2,\n",
    ")\n",
    "\n",
    "consumption_patch = circle_label(\"tab:blue\", \"Consumption\",)\n",
    "production_patch = circle_label(\"tab:orange\", \"Production\")\n",
    "\n",
    "plt.legend(\n",
    "    handles=[production_patch, consumption_patch],\n",
    "    title=\"Target type\",\n",
    "    title_fontsize=12,\n",
    "    bbox_to_anchor=(1, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0,\n",
    "    frameon=False,\n",
    "    fontsize=11,\n",
    ")\n",
    "\n",
    "ax.xaxis.set_major_locator(MonthLocator(interval=2))\n",
    "ax.yaxis.set_major_locator(MultipleLocator(2000))\n",
    "\n",
    "plt.title(\"Target values over time\", fontsize=13)\n",
    "plt.xlabel(\"Date\", fontsize=10)\n",
    "plt.ylabel(\"Target\", fontsize=10, rotation=0, labelpad=30)\n",
    "plt.grid(color=\"grey\", linewidth=0.5, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae56b4b-3871-40b2-9ea1-119ebb5f71ac",
   "metadata": {},
   "source": [
    "Notable observations and assumptions:\n",
    "\n",
    "- Electricity consumption and production values have been increasing year over year.\n",
    "- The plot shows a wider range of values for consumption, likely because many production values are 0 or near 0. As a result, target consumption values tend to be higher in terms of descriptive statistics.\n",
    "- Seasonal cycles: Production values approach zero during winter and increase toward midsummer, while consumption behaves oppositely, peaking in winter and decreasing in summer.\n",
    "- Weekly cycles: Both consumption and production target values exhibit cyclic patterns, likely tied to working days and weekends.\n",
    "- A decrease in maximum values and the presence of 'voids' for high consumption values are observed around the New Year holidays, which could suggest a pause in business operations during this period (i.e., target values with `is_business` = True).\n",
    "\n",
    "Given the high point density near 0 and the prevalence of high values, creating a symlog variant of the scatterplot with values grouped by year-week would be beneficial. Furthermore, using color differentiation by `product_type` instead of `is_consumption` would enhance the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8728006f-495d-4f19-928a-bb07588869f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13, 8))\n",
    "sns.scatterplot(\n",
    "    df.groupby([\"date\", \"is_consumption\", \"product_type\"], observed=True)[\n",
    "        \"modified_target\"\n",
    "    ]\n",
    "    .mean()\n",
    "    .reset_index(name=\"modified_target\"),\n",
    "    x=\"date\",\n",
    "    y=\"modified_target\",\n",
    "    hue=\"product_type\",\n",
    "    s=13,\n",
    ")\n",
    "\n",
    "plt.legend(\n",
    "    title=\"Contract type\",\n",
    "    title_fontsize=12,\n",
    "    bbox_to_anchor=(1, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0,\n",
    "    markerscale=3,\n",
    "    frameon=False,\n",
    "    fontsize=11,\n",
    ")\n",
    "\n",
    "ax.xaxis.set_major_locator(MonthLocator(interval=2))\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.yscale(\"symlog\", linthresh=11)\n",
    "\n",
    "plt.title(\n",
    "    \"Average energy consumption (below 0) or production (above 0) per \"\n",
    "    \"day for each contract type\",\n",
    "    fontsize=13,\n",
    ")\n",
    "plt.xlabel(\"Date\", fontsize=10)\n",
    "plt.ylabel(\"Target, log scale\", fontsize=10, rotation=0, labelpad=30)\n",
    "plt.grid(alpha=0.3, c=\"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b08194-8fc1-4dba-8ab1-66f925b738bd",
   "metadata": {},
   "source": [
    "- Seasonal variations in daily average consumption values are significantly smaller in relative terms (i.e., the percentage change between summer and winter) compared to production. This is likely because energy production by prosumers is severely limited in winter due to low temperatures, shorter daylight hours, and a lower angle of sunlight.\n",
    "- The lowest daily average consumption values are observed for general_service contracts, followed by fixed, combined, and spot contracts. While there are small overlaps in consumption levels on certain dates, these four series are still visually distinguishable.\n",
    "- The range of daily average energy production values follows a similar pattern, but with more overlaps: the lowest values are found in general_service, the highest in spot, while fixed and combined contracts fall somewhere in between.\n",
    "\n",
    "Additionally, it would be useful to analyze production and consumption across different counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9580d10-fd58-4b41-bbe1-65b24d7bbf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    df.groupby(\n",
    "        [\"is_consumption\", \"county\", \"year_week\", \"date\"], observed=True\n",
    "    )[\"modified_target\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"modified_target\"),\n",
    "    col=\"county\",\n",
    "    hue=\"is_consumption\",\n",
    "    col_wrap=8,\n",
    "    height=1.8,\n",
    ")\n",
    "\n",
    "g.map_dataframe(\n",
    "    sns.scatterplot, x=\"date\", y=\"modified_target\", s=3, edgecolor=\"none\"\n",
    ")\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    ax.xaxis.set_major_locator(MonthLocator(interval=6))\n",
    "    ax.xaxis.set_major_formatter(DateFormatter(\"%m.%y\"))\n",
    "    ax.tick_params(axis=\"x\", rotation=30)\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(1000))\n",
    "\n",
    "g.set_axis_labels(\"Date\", \"Target\")\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "g.add_legend(\n",
    "    title=\"Target type\",\n",
    "    label_order=[\"production\", \"consumption\"],\n",
    "    markerscale=4,\n",
    "    bbox_to_anchor=(.9, .9),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0,\n",
    "    frameon=False,\n",
    "    fontsize=11,\n",
    ")\n",
    "g.legend.get_title().set_fontsize(12)\n",
    "g.figure.suptitle(\n",
    "    \"Average energy consumption (below 0) or production (above 0) per \"\n",
    "    \"week for each county\",\n",
    "    fontsize=13\n",
    ")\n",
    "g.figure.subplots_adjust(top=0.825, wspace=0.15, hspace=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea44e12-b377-484f-a07d-cca11dd291e5",
   "metadata": {},
   "source": [
    "- Harjumaa and Tartumaa have the highest average energy production and consumption levels, likely due to the presence of large-scale energy consumers and producers in these counties. It is also probable that many consumers in these areas have combined or fixed contract types.\n",
    "- Some counties, such as Hiiumaa, exhibit low and relatively stable energy production and/or consumption levels.\n",
    "- Certain counties display abrupt changes in the graphs that do not repeat. For example, Valgamaa experiences a sharp increase in electricity production toward the end of the observation period, Ida-Virumaa sees the emergence of new consumption levels during the first half of the period, and Unknown county undergoes a sharp decline in consumption levels (which later returns to a previous level), whereas in Valgamaa, the decline does not reverse. These changes are most likely due to fluctuations in the number of installed solar panels and batteries.\n",
    "- Seasonal patterns are evident in almost all graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e45b76-f4da-40cd-b8e4-764689545823",
   "metadata": {},
   "source": [
    "### Time series gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9863ba0b-c14c-4aa2-a26d-085922e2bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_missing = df[\n",
    "    [\n",
    "        \"county\",\n",
    "        \"is_business\",\n",
    "        \"product_type\",\n",
    "        \"target\",\n",
    "        \"is_consumption\",\n",
    "        \"datetime\",\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "df_for_missing[\"hour_stamp\"] = (\n",
    "    (df_for_missing[\"datetime\"] - df_for_missing[\"datetime\"].min())\n",
    "    // pd.Timedelta(hours=1)\n",
    ").astype(int)\n",
    "\n",
    "df_for_missing[\"group_index\"] = df_for_missing.groupby(\n",
    "    [\"county\", \"is_business\", \"product_type\", \"is_consumption\"], observed=True\n",
    ").ngroup()\n",
    "\n",
    "n_hours = df_for_missing[\"hour_stamp\"].max() + 1\n",
    "n_groups = df_for_missing[\"group_index\"].nunique()\n",
    "\n",
    "missmap = np.full((n_groups, n_hours), np.nan)\n",
    "\n",
    "hour_idx = df_for_missing[\"hour_stamp\"].to_numpy()\n",
    "group_idx = df_for_missing[\"group_index\"].to_numpy()\n",
    "values = (df_for_missing[\"target\"] != 0).astype(int)\n",
    "\n",
    "missmap[group_idx, hour_idx] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5203a545-d5f6-4434-a44e-fa8d3b6c7df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories = (\n",
    "    df.groupby(\n",
    "        [\n",
    "            \"county\",\n",
    "            \"is_business\",\n",
    "            \"product_type\",\n",
    "            \"is_consumption\",\n",
    "        ],\n",
    "        observed=True,\n",
    "    )[\"target\"]\n",
    "    .count()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_categories[\"group_index\"] = (\n",
    "    df_categories[[\"county\", \"product_type\", \"is_business\", \"is_consumption\"]]\n",
    "    .astype(str)\n",
    "    .agg(\"-\".join, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adb4071-c3cd-4572-b5ef-676f9a861238",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(17, 8))\n",
    "sns.barplot(\n",
    "    data=df_categories,\n",
    "    x=\"group_index\",\n",
    "    y=\"target\",\n",
    "    hue=\"county\",\n",
    "    palette=PALETTE,\n",
    "    width=1,\n",
    "    native_scale=False,\n",
    "    linewidth=.4,\n",
    ")\n",
    "\n",
    "plt.legend(\n",
    "    title=\"County\",\n",
    "    title_fontsize=12,\n",
    "    bbox_to_anchor=(1, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0,\n",
    "    markerscale=3,\n",
    "    frameon=False,\n",
    "    fontsize=11,\n",
    ")\n",
    "plt.title('Number of records for each categorical combination', fontsize=13)\n",
    "plt.grid(False)\n",
    "plt.xticks(rotation=90, fontsize=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ccf1b2-251b-45b2-b0f5-1f5d76c63475",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .7\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "sns.heatmap(\n",
    "    missmap,\n",
    "    cmap=sns.color_palette([\"tab:blue\", \"tab:orange\"]),\n",
    "    cbar=False,\n",
    "    alpha=alpha,\n",
    ")\n",
    "\n",
    "legend_patches = [\n",
    "    mpatches.Patch(\n",
    "        facecolor=\"white\",\n",
    "        label=\"Missing value\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.5,\n",
    "    ),\n",
    "    mpatches.Patch(\n",
    "        facecolor=\"tab:blue\",\n",
    "        alpha=alpha,\n",
    "        label=\"Zero value\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.5,\n",
    "    ),\n",
    "    mpatches.Patch(\n",
    "        facecolor=\"tab:orange\",\n",
    "        alpha=alpha,\n",
    "        label=\"Not zero value\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.5,\n",
    "    ),\n",
    "]\n",
    "plt.legend(\n",
    "    handles=legend_patches,\n",
    "    title=\"Data Presence\",\n",
    "    title_fontsize=12,\n",
    "    bbox_to_anchor=(1, 1),\n",
    "    loc=\"upper left\",\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "plt.title(\n",
    "    \"Heatmap of time series gaps for all combinations of categorical features\",\n",
    "    fontsize=13,\n",
    ")\n",
    "\n",
    "xticks_locs = np.linspace(\n",
    "    0, missmap.shape[1] - 1, num=len(df.year_month.unique()), dtype=int\n",
    ")\n",
    "\n",
    "ax.set_xticks(xticks_locs)\n",
    "ax.set_xticklabels(df.year_month.unique(), rotation=45, ha=\"right\")\n",
    "\n",
    "plt.xlabel(\"Date\", fontsize=10)\n",
    "plt.ylabel(\"Group index\", fontsize=10)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96c7e00-28aa-4745-91de-3e9432b91843",
   "metadata": {},
   "source": [
    "The plot shows that time series across different groups have varying start and end dates. While most begin at the earliest date in the dataframe, some start later (and some groups share same first date but not first in the dataframe). Additionally, missing data is unevenly distributed, and the overall data volume varies between groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea6e0d8c-be64-4b5b-94b4-08ebfe3072bd",
   "metadata": {},
   "source": [
    "### Compare different aggregations of weather forecast - historical weather.\n",
    "### Unknown county\n",
    "### Missing values\n",
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abed618a-d92a-4a17-a9ac-5c8b1a68211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hours = df.copy()\n",
    "\n",
    "# hours_ago = (\n",
    "#     [i for i in range(1, 25)]\n",
    "#     + [24 * i for i in range(2, 8)]\n",
    "#     + [168 * i for i in range(2, 9)]\n",
    "#     + [672 * i for i in range(3, 13)]\n",
    "# )\n",
    "# for h in hours_ago:\n",
    "#     df_hours[f\"tm_{h}h\"] = df_hours[\"modified_target\"].shift(h)\n",
    "# df_hours.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a35937-f580-488f-ae59-ef17e4fc5fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"tm_1h\"] = df[\"modified_target\"].shift(1)\n",
    "# def add_lags(df):\n",
    "#     target_map = df['PJME_MW'].to_dict()\n",
    "#     df['lag1'] = (df.index - pd.Timedelta('364 days')).map(target_map)\n",
    "#     df['lag2'] = (df.index - pd.Timedelta('728 days')).map(target_map)\n",
    "#     df['lag3'] = (df.index - pd.Timedelta('1092 days')).map(target_map)\n",
    "#     return df\n",
    "# df_label = pd.get_dummies(df_label, drop_first=True)\n",
    "# df_label.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a961c50-b70a-454a-acfb-911ff580a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_label.drop(\n",
    "#     columns=[\n",
    "#         \"target\",\n",
    "#         \"data_block_id\",\n",
    "#         \"row_id\",\n",
    "#         \"prediction_unit_id\",\n",
    "#         \"modified_target\",\n",
    "#     ],\n",
    "#     axis=1,\n",
    "# )\n",
    "\n",
    "# y = df_label[\"modified_target\"].values\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.20, random_state=RAND\n",
    "# )\n",
    "\n",
    "# st = StandardScaler()\n",
    "# X_train_std = st.fit_transform(X_train)\n",
    "# X_test_std = st.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab19d1-f223-4c57-b205-fc5dc087d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def r2_adjusted(\n",
    "#     y_true: np.ndarray, y_pred: np.ndarray, X_test: np.ndarray | int\n",
    "# ) -> float:\n",
    "#     \"\"\"ÐšÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚ Ð´ÐµÑ‚ÐµÑ€Ð¼Ð¸Ð½Ð°Ñ†Ð¸Ð¸ (Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð°Ñ Ñ€ÐµÐ³Ñ€ÐµÑÑÐ¸Ñ)\"\"\"\n",
    "#     N_objects = len(y_true)\n",
    "\n",
    "#     if isinstance(X_test, np.ndarray):\n",
    "#         N_features = X_test.shape[1]\n",
    "#     else:\n",
    "#         N_features = X_test\n",
    "\n",
    "#     #     N_features = X_test.shape[1]\n",
    "#     r2 = r2_score(y_true, y_pred)\n",
    "#     return 1 - (1 - r2) * (N_objects - 1) / (N_objects - N_features - 1)\n",
    "\n",
    "\n",
    "# def mpe(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "#     \"\"\"Mean percentage error\"\"\"\n",
    "#     return np.mean((y_true - y_pred) / y_true, axis=0) * 100\n",
    "\n",
    "\n",
    "# def mape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "#     \"\"\"Mean absolute percentage error\"\"\"\n",
    "#     return np.mean(np.abs((y_pred - y_true) / y_true), axis=0) * 100\n",
    "\n",
    "\n",
    "# def wape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "#     \"\"\"Weighted Absolute Percent Error\"\"\"\n",
    "#     return np.sum(np.abs(y_pred - y_true)) / np.sum(y_true) * 100\n",
    "\n",
    "\n",
    "# def huber_loss(\n",
    "#     y_true: np.ndarray | pd.DataFrame,\n",
    "#     y_pred: np.ndarray | pd.DataFrame,\n",
    "#     delta: float = 1.345,\n",
    "# ):\n",
    "#     \"\"\"Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð¥ÑŒÑŽÐ±ÐµÑ€Ð°\"\"\"\n",
    "\n",
    "#     if isinstance(y_true, pd.DataFrame):\n",
    "#         y_true = y_true.squeeze().to_numpy()\n",
    "#     if isinstance(y_pred, pd.DataFrame):\n",
    "#         y_pred = y_pred.squeeze().to_numpy()\n",
    "\n",
    "#     assert len(y_true) == len(y_pred), \"Ð Ð°Ð·Ð½Ñ‹Ðµ Ñ€Ð°Ð·Ð¼ÐµÑ€Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…\"\n",
    "#     huber_sum = 0\n",
    "#     for i in range(len(y_true)):\n",
    "#         if abs(y_true[i] - y_pred[i]) <= delta:\n",
    "#             huber_sum += 0.5 * (y_true[i] - y_pred[i]) ** 2\n",
    "#         else:\n",
    "#             huber_sum += delta * (abs(y_true[i] - y_pred[i]) - 0.5 * delta)\n",
    "#     huber_sum /= len(y_true)\n",
    "#     return huber_sum\n",
    "\n",
    "\n",
    "# def logcosh(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "#     \"\"\"Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð›Ð¾Ð³-ÐšÐ¾Ñˆ\"\"\"\n",
    "#     return np.sum(np.log(np.cosh(y_true - y_pred)))\n",
    "\n",
    "\n",
    "# def rmsle(y_true: np.ndarray, y_pred: np.ndarray) -> np.float64:\n",
    "#     \"\"\"\n",
    "#     Root Mean Squared Log Error (RMSLE) metric\n",
    "#     Ð›Ð¾Ð³Ð°Ñ€Ð¸Ñ„Ð¼Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° ÑÑ€ÐµÐ´Ð½ÐµÐ¹ ÐºÐ²Ð°Ð´Ñ€Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾Ð¹ Ð¾ÑˆÐ¸Ð±ÐºÐ¸\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "#     except:\n",
    "#         return None\n",
    "\n",
    "\n",
    "# def get_metrics(\n",
    "#     y_test: np.ndarray,\n",
    "#     y_pred: np.ndarray,\n",
    "#     X_test: np.ndarray,\n",
    "#     name: str = None,\n",
    "#     delta: float = 1.345,\n",
    "# ):\n",
    "#     \"\"\"Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸\"\"\"\n",
    "#     df_metrics = pd.DataFrame()\n",
    "#     df_metrics[\"model\"] = [name]\n",
    "\n",
    "#     df_metrics[\"MAE\"] = mean_absolute_error(y_test, y_pred)\n",
    "#     df_metrics[\"MSE\"] = mean_squared_error(y_test, y_pred)\n",
    "#     df_metrics[\"Huber_loss\"] = huber_loss(y_test, y_pred, delta)\n",
    "#     df_metrics[\"Logcosh\"] = logcosh(y_test, y_pred)\n",
    "#     df_metrics[\"RMSE\"] = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#     df_metrics[\"RMSLE\"] = rmsle(y_test, y_pred)\n",
    "#     df_metrics[\"R2 adjusted\"] = r2_adjusted(y_test, y_pred, X_test)\n",
    "#     df_metrics[\"MPE_%\"] = mpe(y_test, y_pred)\n",
    "#     df_metrics[\"MAPE_%\"] = mape(y_test, y_pred)\n",
    "#     df_metrics[\"WAPE_%\"] = wape(y_test, y_pred)\n",
    "\n",
    "#     return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790fd79-1e77-4e6f-bb8d-af83f47a57cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sort_index().sort_values(\n",
    "#     [\"county\", \"is_business\", \"product_type\", \"is_consumption\"],\n",
    "#     kind=\"mergesort\",\n",
    "# )\n",
    "# df.sort_index()\n",
    "# tss = TimeSeriesSplit(n_splits=3, test_size=300_000)\n",
    "\n",
    "# a = {}\n",
    "# for i in range(1000):\n",
    "#     x = 0\n",
    "#     for j in range(20):\n",
    "#         x += np.random.choice([-1, 1])\n",
    "#     a[x] = a.get(x, 0) + 1\n",
    "\n",
    "\n",
    "# sns.barplot(x=list(a.keys()), y=list(a.values()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fc3653-4435-4e20-bee9-4da67b4ea8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min(data.keys())\n",
    "# max(data.keys())\n",
    "# len(data.keys())\n",
    "# {k: 0 for (k, 0) in range(min(data.keys()), max(data.keys())) if not in data.keys()}\n",
    "# {k: v*2 for (k,v) in dict1.items()}\n",
    "# {key:value for (key,value) in dictonary.items()}\n",
    "# zip()\n",
    "\n",
    "# for train_idx, val_idx in tss.split(df):\n",
    "# print('1 train:', train_idx)\n",
    "# display(df.iloc[train_idx].tail(5))\n",
    "# print('1 val:', val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76417d13-25db-4e88-9af6-04d9e23b6afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tss = TimeSeriesSplit(n_splits=3, test_size=300_000)\n",
    "# df = df.sort_index()\n",
    "\n",
    "# fig, axs = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "# fold = 0\n",
    "\n",
    "# for train_idx, val_idx in tss.split(df):\n",
    "#     train = df.iloc[train_idx]\n",
    "#     test = df.iloc[val_idx]\n",
    "#     train[\"modified_target\"].plot(\n",
    "#         ax=axs[fold],\n",
    "#         label=\"Training Set\",\n",
    "#         title=f\"Data Train/Test Split Fold {fold}\",\n",
    "#     )\n",
    "#     test[\"modified_target\"].plot(ax=axs[fold], label=\"Test Set\")\n",
    "#     axs[fold].axvline(test.index.min(), color=\"black\", ls=\"--\")\n",
    "#     fold += 1\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4637896-c557-496a-bad6-0f7734fa9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold = 0\n",
    "# preds = []\n",
    "# scores = []\n",
    "# for train_idx, val_idx in tss.split(df):\n",
    "#     train = df.iloc[train_idx]\n",
    "#     test = df.iloc[val_idx]\n",
    "\n",
    "#     reg = XGBRegressor(\n",
    "#         n_estimators=2000,\n",
    "#         early_stopping_rounds=50,\n",
    "#         objective=\"reg:squarederror\",\n",
    "#         enable_categorical=True,\n",
    "#         eval_metric=\"mae\",\n",
    "#         # max_depth=3,\n",
    "#         learning_rate=0.01,\n",
    "#         random_state=RAND,\n",
    "#     )\n",
    "#     FEATURES = [\n",
    "#         \"county\",\n",
    "#         \"is_business\",\n",
    "#         \"product_type\",\n",
    "#         # 'target',\n",
    "#         \"is_consumption\",\n",
    "#         # 'data_block_id',\n",
    "#         # 'row_id',\n",
    "#         # 'prediction_unit_id',\n",
    "#         \"hour\",\n",
    "#         \"day_of_week\",\n",
    "#         \"day\",\n",
    "#         \"week_of_year\",\n",
    "#         \"month\",\n",
    "#         \"quarter\",\n",
    "#         \"year\",\n",
    "#         # 'modified_target',\n",
    "#     ]\n",
    "#     TARGET = \"modified_target\"\n",
    "\n",
    "#     X_train = train[FEATURES]\n",
    "#     y_train = train[TARGET]\n",
    "\n",
    "#     X_test = test[FEATURES]\n",
    "#     y_test = test[TARGET]\n",
    "\n",
    "#     reg.fit(\n",
    "#         X_train,\n",
    "#         y_train,\n",
    "#         eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "#         verbose=20,\n",
    "#     )\n",
    "\n",
    "#     y_pred = reg.predict(X_test)\n",
    "#     preds.append(y_pred)\n",
    "#     score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#     scores.append(score)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
