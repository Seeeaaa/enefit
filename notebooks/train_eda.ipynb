{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d6b9c47-d0d8-4101-9f91-5ee2f0752041",
   "metadata": {},
   "source": [
    "# 1. Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f8e0aa-e4c4-43a5-aedb-02783adc467e",
   "metadata": {},
   "source": [
    "Data description sourced from the Kaggle competition page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a7d74-e3b1-4955-8eec-a3d7cab79fcd",
   "metadata": {},
   "source": [
    "### train.csv\n",
    "- `county` - An ID code for the county.\n",
    "- `is_business` - Boolean for whether or not the prosumer is a business.\n",
    "- `product_type` - ID code with the following mapping of codes to contract types: `{0: \"Combined\", 1: \"Fixed\", 2: \"General service\", 3: \"Spot\"}`.\n",
    "- `target` - The consumption or production amount for the relevant segment for the hour. The segments are defined by the `county`, `is_business`, and `product_type`.\n",
    "- `is_consumption` - Boolean for whether or not this row's target is consumption or production.\n",
    "- `datetime` - The Estonian time in EET (UTC+2) / EEST (UTC+3).\n",
    "- `data_block_id` - All rows sharing the same `data_block_id` will be available at the same forecast time. This is a function of what information is available when forecasts are actually made, at 11 AM each morning. For example, if the forecast weather `data_block_id` for predictins made on October 31st is 100 then the historic weather `data_block_id` for October 31st will be 101 as the historic weather data is only actually available the next day.\n",
    "- `row_id` - A unique identifier for the row.\n",
    "- `prediction_unit_id` - A unique identifier for the `county`, `is_business`, and `product_type` combination. *New prediction units can appear or disappear in the test set*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947b2733-ba9e-4bf5-bf78-6da083ca07a9",
   "metadata": {},
   "source": [
    "### gas_prices.csv\n",
    "\n",
    "- `origin_date` - The date when the day-ahead prices became available.\n",
    "- `forecast_date` - The date when the forecast prices should be relevant.\n",
    "- `[lowest/highest]_price_per_mwh` - The lowest/highest price of natural gas that on the day ahead market that trading day, in Euros per megawatt hour equivalent.\n",
    "- `data_block_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc39fed-e77a-44ad-ad57-d280adc83753",
   "metadata": {},
   "source": [
    "### client.csv\n",
    "- `product_type`\n",
    "- `county` - An ID code for the county. See `county_id_to_name_map.json` for the mapping of ID codes to county names.\n",
    "- `eic_count` - The aggregated number of consumption points (EICs - European Identifier Code).\n",
    "- `installed_capacity` - Installed photovoltaic solar panel capacity in kilowatts.\n",
    "- `is_business` - Boolean for whether or not the prosumer is a business.\n",
    "- `date`\n",
    "- `data_block_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c979aa5-2ad4-4541-a881-01ef1712c97d",
   "metadata": {},
   "source": [
    "### electricity_prices.csv\n",
    "- `origin_date`\n",
    "- `forecast_date` - Represents the start of the 1-hour period when the price is valid\n",
    "- `euros_per_mwh` - The price of electricity on the day ahead markets in euros per megawatt hour.\n",
    "- `data_block_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a73a1c7-c995-4b32-a389-aaef90094133",
   "metadata": {},
   "source": [
    "### forecast_weather.csv\n",
    "Weather forecasts that would have been available at prediction time. Sourced from the <u>[European Centre for Medium-Range Weather Forecasts](https://codes.ecmwf.int/grib/param-db/?filter=grib2)</u>.\n",
    "\n",
    "- `[latitude/longitude]` - The coordinates of the weather forecast.\n",
    "- `origin_datetime` - The timestamp of when the forecast was generated.\n",
    "- `hours_ahead` - The number of hours between the forecast generation and the forecast weather. Each forecast covers 48 hours in total.\n",
    "- `temperature` - The air temperature at 2 meters above ground in degrees Celsius. Estimated for the end of the 1-hour period.\n",
    "- `dewpoint` - The dew point temperature at 2 meters above ground in degrees Celsius. Estimated for the end of the 1-hour period.\n",
    "- `cloudcover_[low/mid/high/total]` - The percentage of the sky covered by clouds in the following altitude bands: 0-2 km, 2-6, 6+, and total. Estimated for the end of the 1-hour period.\n",
    "- `10_metre_[u/v]_wind_component` - The [eastward/northward] component of wind speed measured 10 meters above surface in meters per second. Estimated for the end of the 1-hour period.\n",
    "- `data_block_id`\n",
    "- `forecast_datetime` - The timestamp of the predicted weather. Generated from `origin_datetime` plus `hours_ahead`. This represents the start of the 1-hour period for which weather data are forecasted.\n",
    "- `direct_solar_radiation` - The direct solar radiation reaching the surface on a plane perpendicular to the direction of the Sun accumulated during the hour, in watt-hours per square meter.\n",
    "- `surface_solar_radiation_downwards` - The solar radiation, both direct and diffuse, that reaches a horizontal plane at the surface of the Earth, accumulated during the hour, in watt-hours per square meter.\n",
    "- `snowfall` - Snowfall over hour in units of meters of water equivalent.\n",
    "- `total_precipitation` - The accumulated liquid, comprising rain and snow that falls on Earth's surface over the described hour, in units of meters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a498a9-20bb-4ea3-942d-675b1eafb286",
   "metadata": {},
   "source": [
    "### historical_weather.csv\n",
    "<u>[Historic weather data](https://open-meteo.com/en/docs)</u>.\n",
    "\n",
    "- `datetime` - This represents the start of the 1-hour period for which weather data are measured.\n",
    "- `temperature` - Measured at the end of the 1-hour period.\n",
    "- `dewpoint` - Measured at the end of the 1-hour period.\n",
    "- `rain` - Different from the forecast conventions. The rain from large scale weather systems of the hour in millimeters.\n",
    "- `snowfall` - Different from the forecast conventions. Snowfall over the hour in centimeters.\n",
    "- `surface_pressure` - The air pressure at surface in hectopascals.\n",
    "- `cloudcover_[low/mid/high/total]` - Different from the forecast conventions. Cloud cover at 0-3 km, 3-8, 8+, and total.\n",
    "- `windspeed_10m` - Different from the forecast conventions. The wind speed at 10 meters above ground in meters per second.\n",
    "- `winddirection_10m` - Different from the forecast conventions. The wind direction at 10 meters above ground in degrees.\n",
    "- `shortwave_radiation` - Different from the forecast conventions. The global horizontal irradiation in watt-hours per square meter.\n",
    "- `direct_solar_radiation`\n",
    "- `diffuse_radiation` - Different from the forecast conventions. The diffuse solar irradiation in watt-hours per square meter.\n",
    "- `[latitude/longitude]` - The coordinates of the weather station.\n",
    "- `data_block_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e91539-52f2-4918-a49c-597e20e151c4",
   "metadata": {},
   "source": [
    "# 2. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8694e6f-4c39-4f4c-938a-d919b4fa6397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcet as cc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mtransforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from matplotlib import dates as mdates\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f971b-a00d-4c26-a23c-dfdeb274f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND = 10\n",
    "\n",
    "COLORS_LIST = (\n",
    "    cc.glasbey[:4]\n",
    "    + [cc.glasbey[8]]\n",
    "    + cc.glasbey[5:8]\n",
    "    + [cc.glasbey[4]]\n",
    "    + [cc.glasbey[12]]\n",
    "    + cc.glasbey[10:12]\n",
    "    + [cc.glasbey[9]]\n",
    "    + cc.glasbey[13:16]\n",
    ")\n",
    "PALETTE = sns.color_palette(COLORS_LIST)\n",
    "\n",
    "DATA_PATH = \"../raw_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a70352-098d-4da4-aae9-3522943f0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5be2f2-a57b-49c1-8884-45f825fc46fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{DATA_PATH}train.csv\")\n",
    "gas_prices_df = pd.read_csv(f\"{DATA_PATH}gas_prices.csv\")\n",
    "client_df = pd.read_csv(f\"{DATA_PATH}client.csv\")\n",
    "electricity_prices_df = pd.read_csv(f\"{DATA_PATH}electricity_prices.csv\")\n",
    "forecast_weather_df = pd.read_csv(f\"{DATA_PATH}forecast_weather.csv\")\n",
    "historical_weather_df = pd.read_csv(f\"{DATA_PATH}historical_weather.csv\")\n",
    "\n",
    "df_list = [\n",
    "    train_df,\n",
    "    gas_prices_df,\n",
    "    client_df,\n",
    "    electricity_prices_df,\n",
    "    forecast_weather_df,\n",
    "    historical_weather_df,\n",
    "]\n",
    "\n",
    "names_list = [\n",
    "    'train_df',\n",
    "    'gas_prices_df',\n",
    "    'client_df',\n",
    "    'electricity_prices_df',\n",
    "    'forecast_weather_df',\n",
    "    'historical_weather_df',\n",
    "]\n",
    "\n",
    "station_county_mapping = pd.read_csv(\n",
    "    f\"{DATA_PATH}weather_station_to_county_mapping.csv\"\n",
    ")\n",
    "county_id_to_name_map = pd.read_json(\n",
    "    f\"{DATA_PATH}county_id_to_name_map.json\",\n",
    "    typ=\"series\",\n",
    ").str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b065e0a-6cbd-4f8b-9c90-c4b66e8a5928",
   "metadata": {},
   "source": [
    "# 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9e7dc-7191-4882-8da4-58fe3030a175",
   "metadata": {},
   "source": [
    "From description:\n",
    "- `datetime` - The Estonian time in EET (UTC+2) / EEST (UTC+3).\n",
    "- `data_block_id` - All rows sharing the same `data_block_id` will be available at the same forecast time. This is a function of what information is available when forecasts are actually made, at 11 AM each morning. For example, if the forecast weather `data_block_id` for predictins made on October 31st is 100 then the historic weather `data_block_id` for October 31st will be 101 as the historic weather data is only actually available the next day.\n",
    "- `row_id` - A unique identifier for the row.\n",
    "- `prediction_unit_id` - A unique identifier for the `county`, `is_business`, and `product_type` combination. *New prediction units can appear or disappear in the test set*.\n",
    "\n",
    "Also competition host <u>[provided](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers/discussion/455833)</u> this scheme:\n",
    "***\n",
    "Let’s say we are on day D at 11am. We want to predict next day D+1 net consumption from 00 to 23 for every hours.\n",
    "<table style=\"border: 1px solid black; border-collapse: collapse; width: 100%;\">\n",
    "  <tr>\n",
    "    <th style=\"border: 1px solid black;\">Category</th>\n",
    "    <th style=\"border: 1px solid black;\">Weather forecast</th>\n",
    "    <th style=\"border: 1px solid black;\">Historical weather</th>\n",
    "    <th style=\"border: 1px solid black;\">Historical consumption and production / Client data</th>\n",
    "    <th style=\"border: 1px solid black;\">Electricity prices</th>\n",
    "    <th style=\"border: 1px solid black;\">Gas prices</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid black;\">Last available data</td>\n",
    "    <td style=\"border: 1px solid black;\">Forecast for every hours of D and D+1 (published on D)</td>\n",
    "    <td style=\"border: 1px solid black;\">Every hours until day D, 10 am</td>\n",
    "    <td style=\"border: 1px solid black;\">Every hours of Day D-1</td>\n",
    "    <td style=\"border: 1px solid black;\">Every hours of day D (published on D-1)</td>\n",
    "    <td style=\"border: 1px solid black;\">Data for day D (published on D-1)</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Prices are published everyday at 2 pm (so after 11 am), that is we do not have D+1 prices.\n",
    "The data_block_id already reflects this timeline of availability of the data. There is no need to apply additional lag if joining on data_block_id.\n",
    "***\n",
    "\n",
    "Later, I will explore whether there are any discrepancies in the correlations between `data_block_id` and `datetime`, or between `prediction_unit_id` and the `categorical features`. For now, I will analyze the data by:\n",
    "1. Checking all DataFrames using `describe()` and `info()`.\n",
    "2. Verifying the presence of missing values or duplicates.\n",
    "\n",
    "I will use the following functions for initial analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f1f9d-7938-4863-a3ee-85b470c4deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_centered_header(text: str) -> None:\n",
    "    \"\"\"\n",
    "    Prints a line of 100 characters with the given text centered in\n",
    "    it and filled with '<>'.\n",
    "    \"\"\"\n",
    "    total_length = 100\n",
    "    text = f\" {text.strip()} \"\n",
    "    side_length = (total_length - len(text)) // 2\n",
    "    print(\n",
    "        \"<\" * side_length\n",
    "        + text\n",
    "        + \">\" * (total_length - len(text) - side_length)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22058a79-8e71-4372-9b74-a4f77b4c2107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_show_info(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Display df summary, NaNs and duplicated values.\n",
    "    \"\"\"\n",
    "\n",
    "    print_centered_header(\"HEAD\")\n",
    "    display(df.head())\n",
    "\n",
    "    print_centered_header(\"INFO\")\n",
    "    df.info(show_counts=True)\n",
    "\n",
    "    print_centered_header(\"DESCRIBE\")\n",
    "    display(df.describe(include=\"all\"))\n",
    "\n",
    "    print_centered_header(\"MISSING VALUES\")\n",
    "    nan_counts = df.isna().sum()\n",
    "    nan_series = nan_counts[nan_counts > 0]\n",
    "    if nan_series.empty:\n",
    "        print('No missing values')\n",
    "    else:\n",
    "        display(nan_series)\n",
    "\n",
    "    print_centered_header(\"DUPLICATES\")\n",
    "    dup_counts = df.duplicated().sum()\n",
    "    if dup_counts:\n",
    "        display(dup_counts)\n",
    "    else:\n",
    "        print('No duplicate rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d370cf86-2a74-4eb8-ae1a-e76832270193",
   "metadata": {},
   "source": [
    "## train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26fa8d-480e-4216-814e-186a8ba13a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< HEAD >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>target</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>datetime</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>prediction_unit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96.59</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17.31</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   county  is_business  product_type  target  is_consumption  \\\n",
       "0       0            0             1    0.71               0   \n",
       "1       0            0             1   96.59               1   \n",
       "2       0            0             2    0.00               0   \n",
       "3       0            0             2   17.31               1   \n",
       "4       0            0             3    2.90               0   \n",
       "\n",
       "              datetime  data_block_id  row_id  prediction_unit_id  \n",
       "0  2021-09-01 00:00:00              0       0                   0  \n",
       "1  2021-09-01 00:00:00              0       1                   0  \n",
       "2  2021-09-01 00:00:00              0       2                   1  \n",
       "3  2021-09-01 00:00:00              0       3                   1  \n",
       "4  2021-09-01 00:00:00              0       4                   2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< INFO >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2018352 entries, 0 to 2018351\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   county              2018352 non-null  int64  \n",
      " 1   is_business         2018352 non-null  int64  \n",
      " 2   product_type        2018352 non-null  int64  \n",
      " 3   target              2017824 non-null  float64\n",
      " 4   is_consumption      2018352 non-null  int64  \n",
      " 5   datetime            2018352 non-null  object \n",
      " 6   data_block_id       2018352 non-null  int64  \n",
      " 7   row_id              2018352 non-null  int64  \n",
      " 8   prediction_unit_id  2018352 non-null  int64  \n",
      "dtypes: float64(1), int64(7), object(1)\n",
      "memory usage: 138.6+ MB\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< DESCRIBE >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>target</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>datetime</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>prediction_unit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2018352.00</td>\n",
       "      <td>2018352.00</td>\n",
       "      <td>2018352.00</td>\n",
       "      <td>2017824.00</td>\n",
       "      <td>2018352.00</td>\n",
       "      <td>2018352</td>\n",
       "      <td>2018352.00</td>\n",
       "      <td>2018352.00</td>\n",
       "      <td>2018352.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-27 12:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.30</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.90</td>\n",
       "      <td>274.86</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321.87</td>\n",
       "      <td>1009175.50</td>\n",
       "      <td>33.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.78</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.08</td>\n",
       "      <td>909.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182.63</td>\n",
       "      <td>582648.18</td>\n",
       "      <td>19.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.00</td>\n",
       "      <td>504587.75</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>31.13</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323.00</td>\n",
       "      <td>1009175.50</td>\n",
       "      <td>33.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>180.21</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>479.00</td>\n",
       "      <td>1513763.25</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>15480.27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>637.00</td>\n",
       "      <td>2018351.00</td>\n",
       "      <td>68.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           county  is_business  product_type     target  is_consumption  \\\n",
       "count  2018352.00   2018352.00    2018352.00 2017824.00      2018352.00   \n",
       "unique        NaN          NaN           NaN        NaN             NaN   \n",
       "top           NaN          NaN           NaN        NaN             NaN   \n",
       "freq          NaN          NaN           NaN        NaN             NaN   \n",
       "mean         7.30         0.54          1.90     274.86            0.50   \n",
       "std          4.78         0.50          1.08     909.50            0.50   \n",
       "min          0.00         0.00          0.00       0.00            0.00   \n",
       "25%          3.00         0.00          1.00       0.38            0.00   \n",
       "50%          7.00         1.00          2.00      31.13            0.50   \n",
       "75%         11.00         1.00          3.00     180.21            1.00   \n",
       "max         15.00         1.00          3.00   15480.27            1.00   \n",
       "\n",
       "                   datetime  data_block_id     row_id  prediction_unit_id  \n",
       "count               2018352     2018352.00 2018352.00          2018352.00  \n",
       "unique                15312            NaN        NaN                 NaN  \n",
       "top     2022-11-27 12:00:00            NaN        NaN                 NaN  \n",
       "freq                    138            NaN        NaN                 NaN  \n",
       "mean                    NaN         321.87 1009175.50               33.05  \n",
       "std                     NaN         182.63  582648.18               19.59  \n",
       "min                     NaN           0.00       0.00                0.00  \n",
       "25%                     NaN         166.00  504587.75               16.00  \n",
       "50%                     NaN         323.00 1009175.50               33.00  \n",
       "75%                     NaN         479.00 1513763.25               50.00  \n",
       "max                     NaN         637.00 2018351.00               68.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< MISSING VALUES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target    528\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< DUPLICATES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No duplicate rows\n"
     ]
    }
   ],
   "source": [
    "df_show_info(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276e470-db61-40b8-b140-9d06e4661c6a",
   "metadata": {},
   "source": [
    "- There is a small number of missing values (528/2,018,352 < 0.1%) and no duplicates in the DataFrame. Only the `target` feature contains missing values, which can likely be handled using interpolation or mean imputation to ensure data consistency.\n",
    "- The categorical features `county`, `is_business`, `product_type`, and `is_consumption` can be converted to the categorical data type. Additionally, their values can be renamed to improve clarity and understanding.\n",
    "- The `target` feature can be converted to `float32` for memory optimization.\n",
    "- The `datetime` feature can be converted to `datetime64[ns]`.\n",
    "- The `data_block_id` feature can be converted to `uint16` (range: 0 through 65,535) due to its small maximum value.\n",
    "- The `row_id` feature appears to be similar to the index values in the current default sorting. This feature could potentially be deleted in the future if it is not used for data merging later. For now, it can be converted to `uint32` (range: 0 through 4,294,967,295) as its range fits well within this data type. The use of `int64` is unnecessary because it supports negative numbers, which are irrelevant in this case.\n",
    "- The `prediction_unit_id` feature can be converted to `uint8` (range: 0 through 255). Although new combinations may appear in the future, this data type is sufficient to uniquely represent all future combinations of current county, is_business, and product_type (16 * 2 * 4 = 96)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116376df-986a-4875-bbaf-cea7a4691065",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2ccd3b-452a-498f-b5fc-9772917189ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename to avoid confusion and improve readability\n",
    "values_mapper = {\n",
    "    \"county\": county_id_to_name_map,\n",
    "    \"is_business\": {0: \"not_business\", 1: \"business\"},\n",
    "    \"is_consumption\": {0: \"production\", 1: \"consumption\"},\n",
    "    \"product_type\": {\n",
    "        0: \"combined\",\n",
    "        1: \"fixed\",\n",
    "        2: \"general_service\",\n",
    "        3: \"spot\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Check for unexpected values in columns to ensure mappings are up-to-date\n",
    "for column, mapping in values_mapper.items():\n",
    "    unexpected_values = set(train_df[column].unique()) - set(mapping.keys())\n",
    "    if unexpected_values:\n",
    "        print(f\"Unexpected values in {column}: {unexpected_values}\")\n",
    "\n",
    "for key, value in values_mapper.items():\n",
    "    train_df[key] = train_df[key].map(value).astype(\"category\")\n",
    "\n",
    "# Change data types to reduce memory usage\n",
    "train_df = train_df.astype(\n",
    "    {\n",
    "        \"target\": \"float32\",\n",
    "        \"data_block_id\": \"uint16\",\n",
    "        \"row_id\": \"uint32\",\n",
    "        \"prediction_unit_id\": \"uint8\",\n",
    "        \"datetime\": \"datetime64[ns]\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Rename to distinct from datetime-like features from other DFs\n",
    "train_df = train_df.rename(columns={\"datetime\": \"target_datetime\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a38920-b145-4834-b3ee-4e6d1c2cf9c8",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73cb832-7f59-466f-8bf8-c3f29cca04f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>target</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>target_datetime</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>prediction_unit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178938</th>\n",
       "      <td>Harjumaa</td>\n",
       "      <td>not_business</td>\n",
       "      <td>fixed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>production</td>\n",
       "      <td>2021-10-31 03:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>178938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178939</th>\n",
       "      <td>Harjumaa</td>\n",
       "      <td>not_business</td>\n",
       "      <td>fixed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>consumption</td>\n",
       "      <td>2021-10-31 03:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>178939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178940</th>\n",
       "      <td>Harjumaa</td>\n",
       "      <td>not_business</td>\n",
       "      <td>general_service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>production</td>\n",
       "      <td>2021-10-31 03:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>178940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178941</th>\n",
       "      <td>Harjumaa</td>\n",
       "      <td>not_business</td>\n",
       "      <td>general_service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>consumption</td>\n",
       "      <td>2021-10-31 03:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>178941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178942</th>\n",
       "      <td>Harjumaa</td>\n",
       "      <td>not_business</td>\n",
       "      <td>spot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>production</td>\n",
       "      <td>2021-10-31 03:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>178942</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          county   is_business     product_type  target is_consumption  \\\n",
       "178938  Harjumaa  not_business            fixed     NaN     production   \n",
       "178939  Harjumaa  not_business            fixed     NaN    consumption   \n",
       "178940  Harjumaa  not_business  general_service     NaN     production   \n",
       "178941  Harjumaa  not_business  general_service     NaN    consumption   \n",
       "178942  Harjumaa  not_business             spot     NaN     production   \n",
       "\n",
       "           target_datetime  data_block_id  row_id  prediction_unit_id  \n",
       "178938 2021-10-31 03:00:00             60  178938                   0  \n",
       "178939 2021-10-31 03:00:00             60  178939                   0  \n",
       "178940 2021-10-31 03:00:00             60  178940                   1  \n",
       "178941 2021-10-31 03:00:00             60  178941                   1  \n",
       "178942 2021-10-31 03:00:00             60  178942                   2  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.isna().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540205db-12b9-4799-9270-d659285802f8",
   "metadata": {},
   "source": [
    "- The `datetime` values for rows with missing target values start from '2021-10-31 03:00:00', rather than from '2021-09-01 00:00:00'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abafc092-d591-48f0-b690-f6f042dd8a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2021-10-31 03:00:00', '2022-03-27 03:00:00', '2022-10-30 03:00:00',\n",
       " '2023-03-26 03:00:00']\n",
       "Length: 4, dtype: datetime64[ns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_datetimes = train_df[train_df.isna().any(axis=1)].target_datetime.unique()\n",
    "na_datetimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5904abf-b0e6-4553-8d34-29876715901e",
   "metadata": {},
   "source": [
    "- All missing values correspond to the first/last hours of daylight saving time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879cdba-8ed4-4dc5-92e7-7ff9510f7b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().values.sum() == (\n",
    "    train_df.loc[train_df[\"target_datetime\"].isin(na_datetimes), [\"target\"]].shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6496441-199b-4f92-88de-130257f60e99",
   "metadata": {},
   "source": [
    "- All 528 target values at these timestamps are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d4c88b-6973-4caf-86d4-22fc6e56d005",
   "metadata": {},
   "source": [
    "### Consistency and Relationship Validation\n",
    "#### row_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165075d2-d32b-47c1-81d3-877f37ac378f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_df[\"row_id\"] != train_df.index).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c933c4-19d6-431c-a0d4-f573a5583a99",
   "metadata": {},
   "source": [
    "- All `row_id` values are equal to index values, so it is not a unique or necessary feature and can be deleted later if not required for data merging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2f0e13-ea49-40f3-bf67-f90ab25c624d",
   "metadata": {},
   "source": [
    "#### data_block_id and target_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f268a-47c2-44a4-b0a0-ffb3b8e65b20",
   "metadata": {},
   "source": [
    "For predictions made for day D + 1, all historical consumption and production data should have `data_block_id` values equal to D - 1. This is because the `data_block_id` represents the data available at a specific time. Data for day D is unavailable at the time of prediction, as it is the current day, and no historical data exists for it at this moment.\n",
    "\n",
    "Several checks need to be performed:\n",
    "1. The `data_block_id` values for each day increase sequentially without gaps, ranging from 0 to 637 (from the oldest to the most recent days).\n",
    "2. Each day should correspond to exactly one unique `data_block_id` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303e436-05aa-4ac1-8b4a-fc238aa73291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the data_block_id values have no errors, requiring\n",
    "# sorting by target_datetime and grouping by year, month, and date.\n",
    "# For this purpose, new time-related features can be created from\n",
    "# target_datetime, which can also be used later\n",
    "\n",
    "train_df[\"year\"] = train_df[\"target_datetime\"].dt.year.astype(\"uint16\")\n",
    "train_df[\"month\"] = train_df[\"target_datetime\"].dt.month.astype(\"uint8\")\n",
    "train_df[\"day\"] = train_df[\"target_datetime\"].dt.day.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cf572c-fbc0-4f08-9461-c731a76861e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort to check that data_block_id values grow\n",
    "# from the earliest to the latest.\n",
    "# Group by year, month, and date\n",
    "\n",
    "train_df = train_df.sort_values([\"target_datetime\"])\n",
    "\n",
    "# Check that there is only 1 unique data_block_id value for each day\n",
    "\n",
    "(\n",
    "    train_df.groupby([\"year\", \"month\", \"day\"], observed=True)[\n",
    "        \"data_block_id\"\n",
    "    ].nunique()\n",
    "    != 1\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce6b09c-8a34-4091-b056-0c8ac859ae7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that data_block_id values increase sequentially by 1 or\n",
    "# remain the same (difference of 0) after sorting by target_datetime\n",
    "\n",
    "train_df[\"data_block_id\"].diff().dropna().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5844145-bb47-4d99-9c87-f651c87667ee",
   "metadata": {},
   "source": [
    "- The `data_block_id` values have no errors and correctly correspond to each day and the next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eb884e-139d-45f0-b097-00b97bfd7db1",
   "metadata": {},
   "source": [
    "#### prediction_unit_id and county, product_type, is_business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abbc69f-e0a9-4365-9120-c2ea83e07d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that each combination of county, product_type, and\n",
    "# is_business corresponds to exactly one unique prediction_unit_id\n",
    "\n",
    "(\n",
    "    train_df.groupby(\n",
    "        [\n",
    "            \"county\",\n",
    "            \"product_type\",\n",
    "            \"is_business\",\n",
    "        ],\n",
    "        observed=True,\n",
    "    )[\"prediction_unit_id\"].nunique()\n",
    "    != 1\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d8fe47-e778-438d-9512-c9adfc418174",
   "metadata": {},
   "source": [
    "- All combinations of `county`, `is_business`, and `product_type` correspond to a single `prediction_unit_id`, with no errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70137672-8297-45a9-a357-3e0ff989d2ec",
   "metadata": {},
   "source": [
    "## gas_prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f2c74-d559-458c-9a78-5c9e92138fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< HEAD >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>lowest_price_per_mwh</th>\n",
       "      <th>highest_price_per_mwh</th>\n",
       "      <th>origin_date</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>45.23</td>\n",
       "      <td>46.32</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-02</td>\n",
       "      <td>45.62</td>\n",
       "      <td>46.29</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-03</td>\n",
       "      <td>45.85</td>\n",
       "      <td>46.40</td>\n",
       "      <td>2021-09-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-04</td>\n",
       "      <td>46.30</td>\n",
       "      <td>46.80</td>\n",
       "      <td>2021-09-03</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-05</td>\n",
       "      <td>46.30</td>\n",
       "      <td>46.58</td>\n",
       "      <td>2021-09-04</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  forecast_date  lowest_price_per_mwh  highest_price_per_mwh origin_date  \\\n",
       "0    2021-09-01                 45.23                  46.32  2021-08-31   \n",
       "1    2021-09-02                 45.62                  46.29  2021-09-01   \n",
       "2    2021-09-03                 45.85                  46.40  2021-09-02   \n",
       "3    2021-09-04                 46.30                  46.80  2021-09-03   \n",
       "4    2021-09-05                 46.30                  46.58  2021-09-04   \n",
       "\n",
       "   data_block_id  \n",
       "0              1  \n",
       "1              2  \n",
       "2              3  \n",
       "3              4  \n",
       "4              5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< INFO >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 637 entries, 0 to 636\n",
      "Data columns (total 5 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   forecast_date          637 non-null    object \n",
      " 1   lowest_price_per_mwh   637 non-null    float64\n",
      " 2   highest_price_per_mwh  637 non-null    float64\n",
      " 3   origin_date            637 non-null    object \n",
      " 4   data_block_id          637 non-null    int64  \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 25.0+ KB\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< DESCRIBE >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>lowest_price_per_mwh</th>\n",
       "      <th>highest_price_per_mwh</th>\n",
       "      <th>origin_date</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>637</td>\n",
       "      <td>637.00</td>\n",
       "      <td>637.00</td>\n",
       "      <td>637</td>\n",
       "      <td>637.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>95.04</td>\n",
       "      <td>107.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>319.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>47.55</td>\n",
       "      <td>54.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>184.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.10</td>\n",
       "      <td>34.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>60.00</td>\n",
       "      <td>67.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>85.21</td>\n",
       "      <td>93.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>319.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>109.00</td>\n",
       "      <td>130.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>478.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>250.00</td>\n",
       "      <td>305.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>637.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       forecast_date  lowest_price_per_mwh  highest_price_per_mwh origin_date  \\\n",
       "count            637                637.00                 637.00         637   \n",
       "unique           637                   NaN                    NaN         637   \n",
       "top       2021-09-01                   NaN                    NaN  2021-08-31   \n",
       "freq               1                   NaN                    NaN           1   \n",
       "mean             NaN                 95.04                 107.75         NaN   \n",
       "std              NaN                 47.55                  54.74         NaN   \n",
       "min              NaN                 28.10                  34.00         NaN   \n",
       "25%              NaN                 60.00                  67.53         NaN   \n",
       "50%              NaN                 85.21                  93.47         NaN   \n",
       "75%              NaN                109.00                 130.74         NaN   \n",
       "max              NaN                250.00                 305.00         NaN   \n",
       "\n",
       "        data_block_id  \n",
       "count          637.00  \n",
       "unique            NaN  \n",
       "top               NaN  \n",
       "freq              NaN  \n",
       "mean           319.00  \n",
       "std            184.03  \n",
       "min              1.00  \n",
       "25%            160.00  \n",
       "50%            319.00  \n",
       "75%            478.00  \n",
       "max            637.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< MISSING VALUES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No missing values\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< DUPLICATES >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "No duplicate rows\n"
     ]
    }
   ],
   "source": [
    "df_show_info(gas_prices_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb7db5-4144-4ba4-8124-1e8794b88c25",
   "metadata": {},
   "source": [
    "- There are no missing values or duplicates in the dataframe.\n",
    "- The `data_block_id` values start from 1, unlike the `data_block_id` values in train_df, which start from 0. This difference exists because </u>[`[lowest/highest]_price_per_mwh` are end-of-day prices and aren't available in the late morning when forecasts are made](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers/discussion/453355#2515054)</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d22ee4-948f-4d37-a90b-dfe11be0fa14",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ef5dc-7d5f-4f05-b46d-ee52791e3c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data types to reduce memory usage\n",
    "gas_prices_df = gas_prices_df.astype(\n",
    "    {\n",
    "        \"forecast_date\": \"datetime64[ns]\",\n",
    "        \"lowest_price_per_mwh\": \"float32\",\n",
    "        \"highest_price_per_mwh\": \"float32\",\n",
    "        \"origin_date\": \"datetime64[ns]\",\n",
    "        \"data_block_id\": \"uint16\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Rename to distinct from datetime-like features from other DFs\n",
    "gas_prices_df = gas_prices_df.rename(\n",
    "    columns={\n",
    "        \"forecast_date\": \"gas_forecast_date\",\n",
    "        \"origin_date\": \"gas_origin_date\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c6c68f-f43b-4457-b4b2-caf1379641bc",
   "metadata": {},
   "source": [
    "### Consistency and Relationship Validation\n",
    "#### Origin and forecast dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9254055c-50b3-4702-8057-0b5862e6b10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that all forecast dates are next to origin_date\n",
    "(gas_prices_df['gas_origin_date'] + pd.Timedelta('24h') != gas_prices_df['gas_forecast_date']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f40e67-c764-4985-b86d-904044194ddd",
   "metadata": {},
   "source": [
    "- All origin_date values are day before forecast_date values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a83fe-b2d0-4909-96ea-d77ec3d3a3d9",
   "metadata": {},
   "source": [
    "#### Origin date and data_block_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc05598f-23b8-4c4d-9348-195317dc2dba",
   "metadata": {},
   "source": [
    "## client_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de931d3-3a4d-450b-a38c-df9047d00dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_show_info(client_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed2c661-ba53-4858-b61b-fababe96d55f",
   "metadata": {},
   "source": [
    "- There are no missing values or duplicates in the dataframe.\n",
    "- The `data_block_id` values start from 2 instead of 0 or 1, as mentioned earlier."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d83cf3c-9401-442d-bae5-290c9e14e973",
   "metadata": {},
   "source": [
    "## electricity_prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c7771-33b8-4c10-b6b4-f031d455512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_show_info(electricity_prices_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e19efa-97a7-461f-a349-a1aaab1a2bc3",
   "metadata": {},
   "source": [
    "- There are no missing values or duplicates in the dataframe.\n",
    "- The `data_block_id` values start from 1.\n",
    "- The minimum value of the `euros_per_mwh` column is negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0431754-2c7e-4bb2-950e-0c784961306e",
   "metadata": {},
   "source": [
    "### Non-positive Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c2d28-1315-43e2-b010-dcda1ca0d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_prices_df[electricity_prices_df['euros_per_mwh'] <= 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e9d81-64b2-437f-8658-8d8a156a0015",
   "metadata": {},
   "source": [
    "According to the [<u>official comment</u>](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers/discussion/454932#2523730), such prices are not an error.\n",
    "\n",
    "[<u>From Wikipedia</u>](https://en.wikipedia.org/wiki/Negative_pricing): negative pricing can occur when demand for a product drops or supply increases to an extent that owners or suppliers are prepared to pay others to accept it, in effect setting the price to a negative number."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8737f2cc-ed66-4ca8-9f32-695a1f30a724",
   "metadata": {},
   "source": [
    "## forecast_weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e027ae6-fc3e-42e4-89e9-78a947cfc32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_show_info(forecast_weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b630472b-23a3-447a-8d9b-7c40cf51c0ac",
   "metadata": {},
   "source": [
    "- There are 2 missing values and zero duplicates in the dataframe.\n",
    "- Only the `surface_solar_radiation_downwards` column contains missing values. \n",
    "- The `data_block_id` values start from 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3cf0b7-9b50-47d3-9a4e-ef0874058921",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52033f48-4a41-4348-818b-5c4746715f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_weather_df[forecast_weather_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04cc04f-32d7-4bc6-85a3-33f9e8d8b0f0",
   "metadata": {},
   "source": [
    "- Since there are only two missing values, it could be due to a local issue lasting for just 2 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92af9350-9faf-43a3-8ac3-338aaae7f13f",
   "metadata": {},
   "source": [
    "## historical_weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9920a6bd-e99c-4fe1-97d7-62b6c0e66975",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_show_info(historical_weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7de862-eb2e-4746-bd1e-3c4d6957f12d",
   "metadata": {},
   "source": [
    "- The `data_block_id` column type is `float64`, unlike in other DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b3b870-e0ed-4ee2-8879-265009971f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if all values in data_block_id are \n",
    "# integers to avoid errors and allow conversion to int type\n",
    "\n",
    "print(np.unique(historical_weather_df.data_block_id.unique() %1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14a2630-f93e-4df8-8c0a-5bcfe7b072f3",
   "metadata": {},
   "source": [
    "- No anomalous values; all have a remainder of 0 and can be converted to `uint16` type (which can store values from 0 to 65535), as the minimum value is 1 and the maximum is 637."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661bf2db-f164-49f7-996a-ca11fa3ddda0",
   "metadata": {},
   "source": [
    "- There are no missing values or duplicates in the dataframe.\n",
    "- The `data_block_id` is `float64` because the data in the original file is in \"n.0\" format.\n",
    "- The `data_block_id` values start from 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6becd8-afd3-49a2-9368-12a035466c7c",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33e36aea-5480-4177-8e70-bc4f71941c19",
   "metadata": {},
   "source": [
    "- Nominal categorical features can be converted to a categorical type and renamed for better understanding (at least for EDA purposes).\n",
    "- `Datetime` can be unpacked into multiple time-based features.\n",
    "- Many numerical features can be converted to `np.float32`, `uint32`, `uint16`, or `uint8` to reduce memory consumption.\n",
    "- `[latitude/longitude]` features represent the coordinates of the weather forecast and the weather station, which may require comparison for alignment or validation.\n",
    "- Features that appear in multiple DataFrames can have different values, dtypes, and meanings (for example, `cloudcover_[low/mid/high/total]` in `forecast_weather_df` and `historical_weather_df`). It is worth renaming such features to make their differences more explicit.\n",
    "- Missing values in `target` and `surface_solar_radiation_downwards` can likely be handled using interpolation or mean imputation to ensure data consistency.\n",
    "- Non-positive prices might appear in the future, so there is no need to exclude them.\n",
    "- At first glance, the features `data_block_id`, `datetime`, and `row_id` appear to be correlated. Similarly, `prediction_unit_id` appears to correlate with `county`, `is_business`, and `product_type`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11184b72-39c8-4d78-9a17-c24c17759bd5",
   "metadata": {},
   "source": [
    "## Decoding and Data Type Conversion\n",
    "### Mapping Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8950f-0029-4a1b-b258-70055e9662ac",
   "metadata": {},
   "source": [
    "Nominal categorical features exist only in the train_df, client_df DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b5ba3d-7d7f-419a-8e1f-daa61307f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming categorical columns to improve readability\n",
    "values_mapper = {\n",
    "    \"county\": county_id_to_name_map,\n",
    "    \"is_business\": {0: \"not_business\", 1: \"business\"},\n",
    "    \"is_consumption\": {0: \"production\", 1: \"consumption\"},\n",
    "    \"product_type\": {\n",
    "        0: \"combined\",\n",
    "        1: \"fixed\",\n",
    "        2: \"general_service\",\n",
    "        3: \"spot\",\n",
    "    },\n",
    "}\n",
    "\n",
    "decoding_categorical_list = [train_df, client_df]\n",
    "\n",
    "# Iterate over DataFrames with an index for tracking\n",
    "for df_index, df in enumerate(decoding_categorical_list):\n",
    "    for column, mapping in values_mapper.items():\n",
    "        if column in df.columns:\n",
    "            # Check for unexpected values\n",
    "            unexpected_values = set(df[column].unique()) - set(mapping.keys())\n",
    "            if unexpected_values:\n",
    "                print(\n",
    "                    f\"\\\n",
    "Unexpected values in DataFrame {df_index}, column '{column}':\\\n",
    "{unexpected_values}\"\n",
    "                )\n",
    "            else:\n",
    "                # Apply mapping and convert to categorical type\n",
    "                df[column] = df[column].map(mapping).astype(\"category\")\n",
    "    display(df.dtypes)\n",
    "    display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910554b4-9983-4429-aa82-9342e00ab2de",
   "metadata": {},
   "source": [
    "### Datetime Conversion and Reducing Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf70a1-3bd1-4adc-999d-689400c3f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame with the dtypes of all features as strings for simplicity\n",
    "features_dtypes_df = (\n",
    "    pd.concat([pd.DataFrame(df.dtypes).T for df in df_list])\n",
    "    .astype(\"str\")\n",
    "    .set_index(pd.Index(names_list))\n",
    ")\n",
    "\n",
    "# Show all features\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(features_dtypes_df)\n",
    "pd.reset_option(\"display.max_columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c195d6-659a-4d7d-b07f-1706d24d7a9e",
   "metadata": {},
   "source": [
    "- Only datetime-like features have object `dtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f5ce63-1954-4aeb-8ffc-bc58242bf0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dtypes_df[features_dtypes_df == 'object'].dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62288c9c-1602-4391-8ebe-b93510632c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming datetime-like features\n",
    "train_df = train_df.rename(columns={\"datetime\": \"target_datetime\"})\n",
    "gas_prices_df = gas_prices_df.rename(\n",
    "    columns={\n",
    "        \"forecast_date\": \"gas_forecast_date\",\n",
    "        \"origin_date\": \"gas_origin_date\",\n",
    "    }\n",
    ")\n",
    "client_df = client_df.rename(columns={\"date\": \"client_date\"})\n",
    "electricity_prices_df = electricity_prices_df.rename(\n",
    "    columns={\n",
    "        \"forecast_date\": \"electricity_forecast_datetime\",\n",
    "        \"origin_date\": \"electricity_origin_date\",\n",
    "    }\n",
    ")\n",
    "forecast_weather_df = forecast_weather_df.rename(\n",
    "    columns={\n",
    "        \"origin_datetime\": \"weather_origin_datetime\",\n",
    "        \"hours_ahead\": \"weather_hours_ahead\",\n",
    "        \"forecast_datetime\": \"weather_forecast_datetime\",\n",
    "    }\n",
    ")\n",
    "historical_weather_df = historical_weather_df.rename(columns={\"datetime\": \"historical_datetime\"})\n",
    "datetime - This represents the start of the 1-hour period for which weather data are measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9a72e9-99c5-4510-926a-47503c54cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_weather_df[['origin_datetime', 'hours_ahead', 'forecast_datetime']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035799f1-bace-401d-abd5-f0f3a6c283bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_weather_df.groupby('origin_datetime')['hours_ahead'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef4f61-f048-44ed-8d0b-59f135ae8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast_weather_df[['origin_datetime', 'hours_ahead', 'forecast_datetime']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98b37ab-270e-4d00-b34e-6ae6f6744103",
   "metadata": {},
   "source": [
    "forecast_weather_df\n",
    "- origin_datetime - The timestamp of when the forecast was generated.\n",
    "- hours_ahead - The number of hours between the forecast generation and the forecast weather. Each forecast covers 48 hours in total.\n",
    "- forecast_datetime - The timestamp of the predicted weather. Generated from origin_datetime plus hours_ahead. This represents the start of the 1-hour period for which weather data are forecasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ff468f-8f8f-478a-b6b4-09a3432e4c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(features_dtypes_df[features_dtypes_df == 'object'].dropna(axis=1, how='all'))\n",
    "pd.reset_option(\"display.max_columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f33d266-1321-4ed6-9a36-57f97023cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in df_list:\n",
    "#     df['data_block_id'] = df['data_block_id'].astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f78aef-07ee-45bb-ae73-4013f3510849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(features_dtypes_df.drop(columns=['county', 'is_business', 'product_type', 'is_consumption']).values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50effe2-1a55-48ee-a766-70bddd1e8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict.fromkeys(train_df.dtypes[train_df.dtypes == 'category'].index, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6495d7e6-4436-44ae-a420-1bbddf850926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in df_list:\n",
    "#     local_mapper = {}\n",
    "#     for dtype in ['float64', 'int64', 'object']:\n",
    "#         # if dtype in df.dtypes.astype('str').values:\n",
    "#         if dtype in df.dtypes.values:\n",
    "#             local_mapper.update(dict.fromkeys(df.dtypes[df.dtypes == dtype].index, dtype))\n",
    "\n",
    "            \n",
    "#             # print(dtype)\n",
    "#             # print(df.dtypes[df.dtypes == dtype])\n",
    "#             # print(50 * '-')\n",
    "#         else:\n",
    "#             print(f'no {dtype}')\n",
    "#             print(50 * '-')\n",
    "#     print(local_mapper)\n",
    "\n",
    "#     # df = df.astype(local_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d737607-a503-411b-bb7a-ed2bec8e4e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_columns\", None)\n",
    "# display(features_dtypes_df.drop(columns=['county', 'is_business', 'product_type', 'is_consumption']))\n",
    "# pd.reset_option(\"display.max_columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66eb50-8b30-4bee-a68c-4bb0d661d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_dtypes_df[features_dtypes_df.isin(['object'])].dropna(axis=1, how='all').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690cf36-0083-4078-9cb9-056c4728e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_nominal_dtypes_mapper = {\n",
    "#     \"target\": \"float32\",\n",
    "#     # \"datetime\": \"datetime64[ns]\",\n",
    "#     \"data_block_id\": \"uint16\"\n",
    "#     \"row_id\": \"uint32\",\n",
    "#     \"prediction_unit_id\": \"uint8\",\n",
    "#     \"forecast_date\": \"datetime64[ns]\",\n",
    "#     # \"lowest_price_per_mwh\" ':'\n",
    "\n",
    "#     'datetime': \"datetime64[ns]\",\n",
    "#     'forecast_date': \"datetime64[ns]\",\n",
    "#     'origin_date': \"datetime64[ns]\",\n",
    "#     'date': \"datetime64[ns]\",\n",
    "#     'origin_datetime': \"datetime64[ns]\",\n",
    "#     'forecast_datetime': \"datetime64[ns]\",\n",
    "    \n",
    "# }\n",
    "\n",
    "train_df = train_df.astype(\n",
    "    {\n",
    "        \"target\": \"float32\",\n",
    "        \"data_block_id\": \"uint16\",\n",
    "        \"row_id\": \"uint32\",\n",
    "        \"prediction_unit_id\": \"uint8\",\n",
    "        \"datetime\": \"datetime64[ns]\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfcb926-5b3a-4e0f-bdc2-d712312dede1",
   "metadata": {},
   "source": [
    "#### train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804d2c88-90ef-4a5d-8eda-c97c9f75caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Renaming to avoid confusion and improve readability\n",
    "# values_mapper = {\n",
    "#     \"county\": county_id_to_name_map,\n",
    "#     \"is_business\": {0: \"not_business\", 1: \"business\"},\n",
    "#     \"is_consumption\": {0: \"production\", 1: \"consumption\"},\n",
    "#     \"product_type\": {\n",
    "#         0: \"combined\",\n",
    "#         1: \"fixed\",\n",
    "#         2: \"general_service\",\n",
    "#         3: \"spot\",\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# # Check for unexpected values in columns to ensure mappings are up-to-date\n",
    "# for column, mapping in values_mapper.items():\n",
    "#     unexpected_values = set(train_df[column].unique()) - set(mapping.keys())\n",
    "#     if unexpected_values:\n",
    "#         print(f\"Unexpected values in {column}: {unexpected_values}\")\n",
    "\n",
    "# for key, value in values_mapper.items():\n",
    "#     train_df[key] = train_df[key].map(value).astype(\"category\")\n",
    "\n",
    "# # Change data types to reduce memory usage\n",
    "# train_df = train_df.astype(\n",
    "#     {\n",
    "#         \"target\": \"float32\",\n",
    "#         \"data_block_id\": \"uint16\",\n",
    "#         \"row_id\": \"uint32\",\n",
    "#         \"prediction_unit_id\": \"uint8\",\n",
    "#         \"datetime\": \"datetime64[ns]\",\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a560a138-e0ed-4ac6-9d15-34ca2f8a871b",
   "metadata": {},
   "source": [
    "#### gas_prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38515c4c-bd56-48f1-b793-8d39ac64357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change data types to reduce memory usage\n",
    "# gas_prices_df = gas_prices_df.astype(\n",
    "#     {\n",
    "#         \"forecast_date\": \"datetime64[ns]\",\n",
    "#         \"lowest_price_per_mwh\": \"float32\",\n",
    "#         \"highest_price_per_mwh\": \"float32\",\n",
    "#         \"origin_date\": \"datetime64[ns]\",\n",
    "#         \"data_block_id\": \"uint16\",\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a5974b-0895-4c12-8017-9b9d01f6ae64",
   "metadata": {},
   "source": [
    "# 4. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424f14df-1624-497d-8557-5de43817f181",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7003bf43-7780-4858-b00c-fd417639482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5630cba-d558-4e04-b15e-053609da30c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b0d83-dd65-470c-bace-79be97612b50",
   "metadata": {},
   "source": [
    "- The target has missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f96f0f-8e34-44af-8171-3706103a9db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().apply(lambda x: x.apply(\"{0:.2f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15085d1f-195a-437f-9ef4-42703814843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c78a3d-03ee-4f5f-8a6d-eebb94736a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new time-related features based on datetime\n",
    "\n",
    "# df[\"hour\"] = df[\"datetime\"].dt.hour.astype(\"uint8\")\n",
    "# df[\"day_of_week\"] = df[\"datetime\"].dt.day_of_week.astype(\"uint8\")\n",
    "# df[\"day\"] = df[\"datetime\"].dt.day.astype(\"uint16\")\n",
    "# df[\"week_of_year\"] = df[\"datetime\"].dt.isocalendar().week.astype(\"int8\")\n",
    "# df[\"month\"] = df[\"datetime\"].dt.month.astype(\"int8\")\n",
    "df[\"month\"] = df[\"datetime\"].dt.month.astype(\"category\")\n",
    "# df[\"quarter\"] = df[\"datetime\"].dt.quarter.astype(\"int8\")\n",
    "# df[\"year\"] = df[\"datetime\"].dt.year.astype(\"uint16\")\n",
    "df[\"year\"] = df[\"datetime\"].dt.year.astype(\"category\")\n",
    "\n",
    "# df[\"date\"] = df[\"datetime\"].dt.date\n",
    "df[\"date\"] = df[\"datetime\"].dt.date.astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03a645b-9a1f-453d-bdd7-8b47f56a8b0e",
   "metadata": {},
   "source": [
    "### Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ae369-c0b3-4e07-b6d2-19c39f9e37cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = 30\n",
    "# plt.figure(figsize=(12, 4))\n",
    "\n",
    "\n",
    "# sns.histplot(\n",
    "#     data=df,\n",
    "#     x='target',\n",
    "#     hue='is_consumption',\n",
    "#     bins=bins,\n",
    "#     multiple=\"dodge\",\n",
    "#     linewidth=0.5\n",
    "# )\n",
    "# plt.title('Distribution of Energy Consumption (Target)')\n",
    "# plt.xlabel('Energy values')\n",
    "# # plt.ylabel('Frequency')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779643df-d453-4315-bbee-0112c335787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating target's discrete intervals\n",
    "bins = 10\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "target_bins_percentage = round(\n",
    "    pd.cut(np.array(df.target), bins, precision=0).value_counts()\n",
    "    / df.shape[0]\n",
    "    * 100,\n",
    "    2,\n",
    ")\n",
    "\n",
    "# Re-calculate first value so\n",
    "# that the sum of the percentages is equal to 100.0\n",
    "target_bins_percentage[0] = 100 - target_bins_percentage[1:].sum()\n",
    "target_bins_percentage = [f\"{i:.2f}%\" for i in target_bins_percentage]\n",
    "\n",
    "target_max = df.target.max()\n",
    "ticks = range(0, int(target_max) + 1, int(target_max / bins))\n",
    "\n",
    "ax = sns.histplot(\n",
    "    df.target,\n",
    "    bins=bins,\n",
    "    kde=True,\n",
    "    linewidth=0.5,\n",
    ")\n",
    "\n",
    "# Adding group percentage to the top of each bar\n",
    "ax.bar_label(ax.containers[0], target_bins_percentage, padding=6, fontsize=11)\n",
    "\n",
    "plt.title(\n",
    "    f\"Histogram of {bins} discrete bins of the target values with KDE-line\"\n",
    ")\n",
    "plt.xticks(ticks=ticks, rotation=0)\n",
    "plt.xlabel(\"Target values\")\n",
    "\n",
    "# Using a logarithmic scale for the y-axis for better visualization\n",
    "# of small quantities of target values\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Count, log scale\", rotation=0, labelpad=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127b5ac5-fe6d-42e8-bbbe-4912c562dacc",
   "metadata": {},
   "source": [
    "- The target distribution is non-normal, it is right-skewed.\n",
    "- There are more values in the first discrete bin than the total number in the rest; the KDE-line shows that most of the values are near zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa9a5ed-8d33-48e7-b4ee-8ad8a40aeda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = 3  # The number of boxenplot levels\n",
    "\n",
    "# list with data for additional lines and text\n",
    "# started from .25 because lower corresponding percentiles are the same\n",
    "\n",
    "levels_list = [0.25] + np.cumsum(\n",
    "    [0.5 / pow(2, i) for i in range(levels + 1)]\n",
    ").tolist()\n",
    "levels_values = df.target.describe(levels_list)[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c42b314-83d3-42dc-9d62-ce61fa2fde2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 8))\n",
    "ax = sns.boxenplot(\n",
    "    df,\n",
    "    y=\"target\",\n",
    "    linewidth=0,\n",
    "    k_depth=levels,\n",
    "    flier_kws={\n",
    "        \"marker\": \".\",\n",
    "        \"s\": 0.1,\n",
    "    },\n",
    ")\n",
    "\n",
    "ax.set_xlim(ax.get_xlim()[0], ax.get_xlim()[1])\n",
    "\n",
    "plt.hlines(\n",
    "    levels_values.values,\n",
    "    0,\n",
    "    ax.get_xlim()[1],\n",
    "    \"orange\",\n",
    "    lw=1.2,\n",
    ")\n",
    "\n",
    "for ix, l in enumerate(levels_values):\n",
    "    plt.text(\n",
    "        ax.get_xlim()[1] + 0.03,\n",
    "        levels_values.values[ix],\n",
    "        f\"{levels_values.index[ix]}: {levels_values.values[ix]:.2f}\",\n",
    "        fontsize=11,\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "    )\n",
    "\n",
    "ax.set_ylim(-0.1, 30_000)\n",
    "plt.yscale(\"symlog\", linthresh=1)\n",
    "plt.title(f\"Boxenplot of the target values with {levels} levels\")\n",
    "plt.ylabel(\"Target values, log scale\", rotation=0, labelpad=65)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df2c8d5-4405-47b7-b54f-92943f139cc0",
   "metadata": {},
   "source": [
    "- Q<sub>1</sub> ≈ 0.38\n",
    "- Q<sub>2</sub> ≈ 31.13\n",
    "- Q<sub>3</sub> ≈ 180.21\n",
    "- There are only two levels on the Q<sub>1</sub> side of the boxenplot (as opposed to three levels on the Q<sub>3</sub> side), which means that there is a huge number of identical values that cannot be separated. That is, two different percentiles (6.25% and 12.5%) have the same value, which equal to the minimum value - 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b8e51-1fbd-469e-8c2b-8b58785bba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.target.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e0b346-07d0-4a33-aa46-6a7a3f7b035d",
   "metadata": {},
   "source": [
    "- Zero values are the most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e7e79e-c01a-43de-bda8-693b7ec6b3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.target.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f8298e-0bcf-4291-9849-2d4b6dc9229d",
   "metadata": {},
   "source": [
    "- Zero values occur in more than 10% of the cases (351496 / 2017824)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36309d19-113c-4824-94a1-16cdc29ea487",
   "metadata": {},
   "source": [
    "### Add classes comparasing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf890c32-80a1-4438-9b91-994c39b5519a",
   "metadata": {},
   "source": [
    "### County, is_business, is_consumption and product_type combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3e898c-55f2-4c76-ac57-8e051635b18b",
   "metadata": {},
   "source": [
    "From the description:\n",
    "\n",
    "- target - The consumption or production amount for the relevant segment for the hour. The segments are defined by the county, is_business, and product_type.\n",
    "- prediction_unit_id - A unique identifier for the county, is_business, and product_type combination. New prediction units can appear or disappear in the test set.\n",
    "\n",
    "Therefore, each combination of the county, is_business, is_consumption, and product_type should be considered as a separate time series. New time series may appear or existing ones may disappear in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e1c29a-3867-4e45-8724-d440a0add4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of target values in each time series and map each county to\n",
    "# its corresponding identifier from county_id_to_name_map\n",
    "\n",
    "df_categories = (\n",
    "    df.groupby(\n",
    "        [\n",
    "            \"county\",\n",
    "            \"is_business\",\n",
    "            \"product_type\",\n",
    "            \"is_consumption\",\n",
    "        ],\n",
    "        observed=True,\n",
    "    )[\"target\"]\n",
    "    .count()\n",
    "    .reset_index()\n",
    ")\n",
    "df_categories[\"county_num\"] = df_categories[\"county\"].map(\n",
    "    pd.Series(county_id_to_name_map.index, county_id_to_name_map.values)\n",
    ")\n",
    "df_categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068370fd-fc11-4217-abc6-4f5049706da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dimensions for each column\n",
    "\n",
    "county_dim = go.parcats.Dimension(values=df_categories.county, label=\"County\")\n",
    "is_business_dim = go.parcats.Dimension(\n",
    "    values=df_categories.is_business, label=\"Is business?\"\n",
    ")\n",
    "product_type_dim = go.parcats.Dimension(\n",
    "    values=df_categories.product_type, label=\"Product type\"\n",
    ")\n",
    "is_consumption_dim = go.parcats.Dimension(\n",
    "    values=df_categories.is_consumption, label=\"Is consumption?\"\n",
    ")\n",
    "\n",
    "color = df_categories.county_num\n",
    "colorscale = px.colors.make_colorscale(COLORS_LIST)\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Parcats(\n",
    "            dimensions=[\n",
    "                county_dim,\n",
    "                product_type_dim,\n",
    "                is_business_dim,\n",
    "                is_consumption_dim,\n",
    "            ],\n",
    "            line={\"color\": color, \"colorscale\": colorscale},\n",
    "            hoveron=\"dimension\",\n",
    "            labelfont={\"size\": 16, \"family\": \"sans-serif\"},\n",
    "            tickfont={\"size\": 16, \"family\": \"sans-serif\", \"color\": \"blue\"},\n",
    "            arrangement=\"freeform\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    font={\"size\": 18, \"family\": \"sans-serif\"},\n",
    "    title=\"Parallel categories diagram for all observed combinations of catego\\\n",
    "rical features\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8304a0-8367-4d91-9cc9-601ad7da495d",
   "metadata": {},
   "source": [
    "- There are different combinations of county-product_type-is_business features. All these combinations have two variants for is_consumption feature. What this means is that it is possible for each timestamp there are two target values for county-product_type-is_business combinations corresponding to consumption and production.\n",
    "- Only two counties have one combiation of product_type-is_business features: Läänemaa and Unknown. Both of them have only 'spot' and 'business' values in corresponding features.\n",
    "- It is worth noting that the description of prediction_unit_id says that new combinations of county, is_business, and product_type features may appear or disappear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd327029-e702-4b6a-9594-20923358f161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the first point\n",
    "\n",
    "# There are no timestamps in the dataframe,\n",
    "# for which there are only consumption or production values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261edcdd-6bfd-4aa1-b3d3-9dde0f8f5be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prodcons_df(\n",
    "    df: pd.DataFrame,\n",
    "    compare: str,\n",
    "    # group: list[str],\n",
    ") -> pd.DataFrame:\n",
    "    df = (\n",
    "        df.loc[df[\"is_consumption\"] == compare]\n",
    "        .groupby(\n",
    "            [\"datetime\", \"county\", \"is_business\", \"product_type\"],\n",
    "            observed=True,\n",
    "        )[\"target\"]\n",
    "        .count()\n",
    "        .reset_index()\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1f7afd-d572-4898-b524-2ead1b5bce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_prodcons_df(df, \"consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06beac1a-ec6e-4d36-ae59-81742926e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_prodcons_df(df, \"consumption\").equals(\n",
    "    create_prodcons_df(df, \"production\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29dba8e-2236-4cc7-a35d-a4fb37b4cd30",
   "metadata": {},
   "source": [
    "Yes, the first point is correct.\n",
    "For each combinations of datetime-county-is_business-product_type features there are one consumption value and one production value (including nan values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ddcb3e-b4ee-4033-8e23-dde2328bdd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x=\"datetime\",\n",
    "    y=\"target\",\n",
    "    s=1,\n",
    ")\n",
    "\n",
    "plt.title(\"Target values timeline\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Target values\", rotation=0, labelpad=40)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5fcc35-e010-48b3-a398-9b9d4bac4cce",
   "metadata": {},
   "source": [
    "- Values less than 1500 are indistinguishable, the point density is too high for this plot.\n",
    "- The target variable has seasonal and weekly cycles.\n",
    "- There are 'voids' during the New Year holidays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f0a1b-8889-464c-9043-bd807d469c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumption values are multiplied by (-1) for better visualisation\n",
    "\n",
    "df[\"modified_target\"] = np.where(\n",
    "    df[\"is_consumption\"] == \"consumption\",\n",
    "    df[\"target\"].mul(-1),\n",
    "    df[\"target\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6722578-402d-46c4-919e-b044fd558418",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "sns.scatterplot(\n",
    "    df.groupby(\n",
    "        [\"date\", \"is_consumption\", \"county\", \"product_type\"], observed=True\n",
    "    )[\"modified_target\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"modified_target\"),\n",
    "    # df,\n",
    "    x=\"date\",\n",
    "    # x=\"datetime\",\n",
    "    y=\"modified_target\",\n",
    "    hue=\"county\",\n",
    "    palette=PALETTE,\n",
    "    s=10,\n",
    ")\n",
    "\n",
    "plt.title(\n",
    "    \"Average energy consumption (below 0) or production (above 0) for each \\\n",
    "day for each county\",\n",
    "    fontsize=13,\n",
    ")\n",
    "\n",
    "plt.legend(\n",
    "    title=\"County\",\n",
    "    title_fontsize=12,\n",
    "    bbox_to_anchor=(1.005, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0,\n",
    "    markerscale=3,\n",
    "    frameon=False,\n",
    "    fontsize=11,\n",
    ")\n",
    "\n",
    "months_locator = mdates.MonthLocator()\n",
    "ax.xaxis.set_major_locator(months_locator)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Modified target\", rotation=0, labelpad=50)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6bec4c-086e-4ee8-a0fa-feca8f8bbef8",
   "metadata": {},
   "source": [
    "1. Electricity consumption and production values are increasing from year to year.\n",
    "2. Energy production in winter is significantly lower than in summer.\n",
    "3. Energy consumption in winter is bigger than in summer.\n",
    "4. During the New Year holidays, there is a decrease in electricity consumption.\n",
    "5. Harjumaa county has highest average (per day) values of energy consumption (for the entire observation period) and production (for spring-autumn period). Tartumaa has second highest values for the entire observation period except last two weeks when Valgamaa get ahead in energy production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f124fe-08b2-44ea-a4a5-c1140a17e394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the first point\n",
    "\n",
    "# Electricity consumption and production values are\n",
    "# increasing from year to year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8e614-28d8-4659-ac50-4188833f5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to only one year being fully available,\n",
    "# the other two years will be compared with respective months of 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9deea5b-6ef4-45cd-a17e-691c49d1d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_target_comparison_by_year(\n",
    "#     df: pd.DataFrame,\n",
    "#     first_year: int,\n",
    "#     second_year: int,\n",
    "# ) -> pd.DataFrame:\n",
    "\n",
    "#     if df[df[\"year\"] == first_year].month.unique().size == 12:\n",
    "#         complete_year = first_year\n",
    "#         incomplete_year = second_year\n",
    "#     else:\n",
    "#         complete_year = second_year\n",
    "#         incomplete_year = first_year\n",
    "\n",
    "#     grouped = df.loc[\n",
    "#         df[\"year\"].isin([incomplete_year, complete_year])\n",
    "#         & df.month.isin(df[df[\"year\"] == incomplete_year].month.unique())\n",
    "#     ].groupby(\n",
    "#         [\n",
    "#             \"is_consumption\",\n",
    "#             \"year\",\n",
    "#         ],\n",
    "#         observed=True,\n",
    "#     )[\n",
    "#         \"target\"\n",
    "#     ]\n",
    "\n",
    "#     return (\n",
    "#         pd.merge(\n",
    "#             grouped.describe(), grouped.sum(), on=[\"is_consumption\", \"year\"]\n",
    "#         )\n",
    "#         .rename(columns={\"target\": \"sum\"})\n",
    "#         .reset_index()\n",
    "#         .melt(id_vars=[\"year\", \"is_consumption\"])\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e18b6-92dd-4702-bd1d-b3cf1310d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year in [2021, 2023]:\n",
    "#     ax = sns.catplot(\n",
    "#         create_target_comparison_by_year(df, year, 2022),\n",
    "#         kind=\"bar\",\n",
    "#         x=\"year\",\n",
    "#         y=\"value\",\n",
    "#         col=\"variable\",\n",
    "#         hue=\"is_consumption\",\n",
    "#         sharey=False,\n",
    "#         height=2.7,\n",
    "#         aspect=0.6,\n",
    "#     ).set_titles(\"{col_name}\")\n",
    "#     ax.fig.subplots_adjust(top=0.8)\n",
    "#     if year > 2022:\n",
    "#         ax.fig.suptitle(\n",
    "#             f\"Comparing descriptive statistics between 2022 and \\\n",
    "# {year}\"\n",
    "#         )\n",
    "#     else:\n",
    "#         ax.fig.suptitle(\n",
    "#             f\"Comparing descriptive statistics between {year} and \\\n",
    "# 2022\"\n",
    "#         )\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172a84d3-a9fc-4e21-b226-7b2af63ea5cf",
   "metadata": {},
   "source": [
    "Yes, the first point is correct.\n",
    "- Total sum, quartiles, means and maximum values increase from year to year. The standard deviation also increase. The minimum value does not change; it is zero. None of the descriptive statistics decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195136a2-f45d-4ff1-86d4-c18a3bc1eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the second point\n",
    "# It appears that the relative growth rate of energy production is\n",
    "# growing faster than the relative growth rate of consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c21dd-97b4-4d79-b00b-4efbee89b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_difference_percentage(\n",
    "#     base_df: pd.DataFrame,\n",
    "#     first_year: int,\n",
    "#     second_year: int,\n",
    "# ) -> pd.DataFrame:\n",
    "\n",
    "#     df = create_target_comparison_by_year(base_df, first_year, second_year)\n",
    "#     # .sort_values(by=[\"is_consumption\", \"year\" , \"variable\"])\n",
    "#     # df = df[df[\"variable\"].isin([\"50%\", \"max\", \"mean\", \"sum\"])]\n",
    "\n",
    "#     first_df = df[df[\"year\"] == first_year].reset_index(drop=True)\n",
    "#     second_df = df[df[\"year\"] == second_year].reset_index(drop=True)\n",
    "\n",
    "#     percent = (\n",
    "#         (second_df.value - first_df.value) / first_df.value * 100\n",
    "#     ).rename(\"percentage_difference\")\n",
    "#     second_df = pd.concat(\n",
    "#         [\n",
    "#             second_df.drop(columns=[\"value\"]),\n",
    "#             first_df[\"value\"].rename(\"previous_value\"),\n",
    "#             second_df.value,\n",
    "#             percent,\n",
    "#         ],\n",
    "#         axis=1,\n",
    "#     )\n",
    "\n",
    "#     return second_df\n",
    "\n",
    "    \n",
    "# calculate_difference_percentage(df, 2022, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3458f7e-d989-4ea8-9fa5-f44eabb75900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage_df = pd.concat([\n",
    "#     calculate_difference_percentage(df, 2022, 2023),\n",
    "#     calculate_difference_percentage(df, 2021, 2022),\n",
    "# ]).reset_index(drop=True)\n",
    "\n",
    "# ax = sns.catplot(\n",
    "#     percentage_df,\n",
    "#     x=\"year\",\n",
    "#     y=\"percentage_difference\",\n",
    "#     row=\"is_consumption\",\n",
    "#     col=\"variable\",\n",
    "#     kind=\"bar\",\n",
    "#     hue='is_consumption',\n",
    "#     sharey=False,\n",
    "#     height=2.5,\n",
    "#     aspect=0.6,\n",
    "#     # height=3,\n",
    "#     # aspect=1,\n",
    "#     margin_titles=True\n",
    "# )\n",
    "# ax.fig.subplots_adjust(top=0.88)\n",
    "# ax.fig.suptitle('Visualisation the difference between two years in percent')\n",
    "# # ax.tick_params(axis='x', rotation=30)\n",
    "# plt.show()\n",
    "# # The second bar of the first barplot is missing because median value for the corresponding previous year months (2021 year, months from 9 to 12) was 0 and for this case growth is uncountable in percent.\n",
    "# # Yes, the third point is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45e680-db0f-4f0e-bba1-c977719d09bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_range = pd.date_range(df.datetime.min(), df.datetime.max(), 4)\n",
    "\n",
    "# ax = sns.relplot(\n",
    "#     data=df,\n",
    "#     x=\"datetime\",\n",
    "#     y=\"modified_target\",\n",
    "#     row=\"is_business\",\n",
    "#     col=\"product_type\",\n",
    "#     hue=\"county\",\n",
    "#     palette=PALETTE,\n",
    "#     height=3,\n",
    "#     s=3,\n",
    "# )\n",
    "# ax.set_titles(\"{col_name}\")\n",
    "# ax.set(xticks=date_range)\n",
    "# ax.set_xticklabels(\n",
    "#     date_range,\n",
    "#     rotation=30,\n",
    "# )\n",
    "# ax.axes[0, 0].xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m\"))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf19bb71-b707-41a0-99e0-630ae83ade1e",
   "metadata": {},
   "source": [
    "# ?Conclusions from relplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e0275-9a31-4d11-b438-cf8b2303a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.rcParams[\"patch.edgecolor\"] = \"none\"\n",
    "\n",
    "ax = sns.histplot(\n",
    "    data=df[\n",
    "        [\n",
    "            \"county\",\n",
    "            \"product_type\",\n",
    "        ]\n",
    "    ],\n",
    "    y=\"county\",\n",
    "    hue=\"product_type\",\n",
    "    multiple=\"stack\",\n",
    "    shrink=0.75,\n",
    "    palette=\"deep\",\n",
    ")\n",
    "\n",
    "sns.move_legend(\n",
    "    ax,\n",
    "    \"upper left\",\n",
    "    bbox_to_anchor=(1, 1),\n",
    "    title=\"product_type\",\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "plt.title(\n",
    "    \"Counties by product type\",\n",
    ")\n",
    "plt.xticks(\n",
    "    ticks=range(0, int(2.5e5), int(2.5e4)),\n",
    ")\n",
    "plt.xlabel(\n",
    "    \"Number of target values\",\n",
    "    fontsize=11,\n",
    ")\n",
    "plt.ylabel(\"Estonian counties\", rotation=0, labelpad=60, fontsize=11)\n",
    "\n",
    "plt.show()\n",
    "plt.rcParams[\"patch.edgecolor\"] = \"black\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a564d5-33c8-4682-815e-d80dcc8d74ad",
   "metadata": {},
   "source": [
    "1. Counties have different numbers of total records and ratios of contract types.\n",
    "2. First place by the count of records is the 'Spot' product type, the second place is 'Fixed' product type. Third place is most likely the 'Combined' product type.\n",
    "3. It seems that for the \"spot\" product type, the number of records for all counties is approximately 60000, except for Läänemaa and Unknown counties, where the number of records is approximately 30000.\n",
    "4. Some counties don't have certain types of contracts. In the records of Läänemaa and Unknown county there is only one type of product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89947d38-d30e-4837-b9f4-f7d4368c8bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the second point\n",
    "# First place by the count of records is the 'Spot' product type,\n",
    "# the second place is 'Fixed' product type.\n",
    "# Third place is most likely the 'Combined' product type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dc6950-cd57-4c56-8d1c-65af75e47a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"product_type\"], observed=True)[[\"target\"]].count().sort_values(\n",
    "    \"target\", ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3197baf5-7743-465e-a630-12e678181bf2",
   "metadata": {},
   "source": [
    "Yes, the second point is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d664017-f755-4e08-80a6-b1545d9c83e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the third point\n",
    "# It seems that for the \"spot\" product type, the number of records\n",
    "# for all counties is approximately 60000, except for Läänemaa and\n",
    "# Unknown counties, where the number of records is approximately 30000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16365af-4401-4905-abb6-cbaddbcf4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"county\", \"product_type\"], observed=True)[\n",
    "    [\"target\"]\n",
    "].count().query('product_type == \"Spot\"').target.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68994ed-78ad-4ad5-b3f1-2b901c3fb935",
   "metadata": {},
   "source": [
    "Yes, the third point is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca785142-6b21-4e0d-998b-00c3256525b7",
   "metadata": {},
   "source": [
    "Comparing the total number of records in each subgroup (all combinations of \"county\", \"product_type\", \"is_business\", \"is_consumption\" that appear in the dataframe) due to the fact that counties have different total number of records and ratios of contract types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d3a18a-bf4c-49a9-a8a2-617a877ef4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering columns\n",
    "# df_categories = df_categories.copy()[[\n",
    "#     \"county\",\n",
    "#     \"product_type\",\n",
    "#     \"is_business\",\n",
    "#     \"is_consumption\",\n",
    "#     \"target\",\n",
    "#     \"county_num\",\n",
    "# ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98465212-bab8-4218-a03a-aa4768ee82c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories[\"subgroup\"] = (\n",
    "    df_categories[[\"county\", \"product_type\", \"is_business\", \"is_consumption\"]]\n",
    "    .astype(str)\n",
    "    .agg(\"-\".join, axis=1)\n",
    ")\n",
    "df_categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5fba42-5227-4e3d-88d3-a482b934c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_df = (\n",
    "#     df.groupby([\n",
    "#         \"county\",\n",
    "#         \"product_type\",\n",
    "#         \"is_business\",\n",
    "#         \"is_consumption\",\n",
    "#     ], observed=True,)[\"target\"].count().reset_index()\n",
    "# )\n",
    "# count_df[\"subgroup\"] = (\n",
    "#     count_df[[\"county\", \"product_type\", \"is_business\", \"is_consumption\"]]\n",
    "#     .astype(str)\n",
    "#     .agg(\"-\".join, axis=1)\n",
    "# )\n",
    "# count_df.head()\n",
    "\n",
    "# first_part_df = count_df[count_df['county'].isin(count_df.county.unique()[:int(count_df.county.nunique() / 2)])]\n",
    "# second_part_df = count_df[count_df['county'].isin(count_df.county.unique()[int(count_df.county.nunique() / 2):])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7db8eb-3893-41fd-9c4d-f4bb8d403eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f71f7-51b7-43a2-bf7d-6ee4013ffc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_part_df = df_categories[\n",
    "    df_categories[\"county\"].isin(\n",
    "        df_categories.county.unique()[\n",
    "            : int(df_categories.county.nunique() / 2)\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "second_part_df = df_categories[\n",
    "    df_categories[\"county\"].isin(\n",
    "        df_categories.county.unique()[\n",
    "            int(df_categories.county.nunique() / 2) :\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab34da-24a2-48a7-a87a-acf95470932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 1\n",
    "cols = 2\n",
    "categories = [first_part_df, second_part_df]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 14))\n",
    "plt.subplots_adjust(\n",
    "    wspace=1.1,\n",
    ")\n",
    "for ind, column in enumerate(categories):\n",
    "    plt.subplot(rows, cols, ind + 1)\n",
    "    data = categories[ind]\n",
    "    ax = sns.barplot(\n",
    "        data=data,\n",
    "        x=\"target\",\n",
    "        y=\"subgroup\",\n",
    "        hue=\"county\",\n",
    "        palette=PALETTE,\n",
    "    )\n",
    "    ax.set_yticks([i for i in range(data.subgroup.nunique())])\n",
    "    ax.set_yticklabels(\n",
    "        data.subgroup.apply(lambda x: \"-\".join(x.split(\"-\")[-3:])),\n",
    "    )\n",
    "    if ind == 0:\n",
    "        ax.legend_.remove()\n",
    "    else:\n",
    "        sns.move_legend(\n",
    "            ax,\n",
    "            \"upper left\",\n",
    "            bbox_to_anchor=(1, 1),\n",
    "            title=\"County\",\n",
    "            frameon=False,\n",
    "        )\n",
    "    plt.ylabel(\n",
    "        ylabel=\"\",\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c429c8e-f3df-4fd3-9a7d-2e8a86e1bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e9ce34-6ecf-4233-a9d9-79807054108c",
   "metadata": {},
   "source": [
    "Each combination of county, product_type, and is_business has the same number of target values for both consumption and production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cd7743-d394-4d30-bdb2-1ee9e6651c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows = 4\n",
    "# cols = 1\n",
    "# categories = [\"county\", \"is_business\", \"product_type\", \"is_consumption\"]\n",
    "\n",
    "# fig, ax = plt.subplots(\n",
    "#     nrows=rows,\n",
    "#     ncols=cols,\n",
    "#     figsize=(12, 15),\n",
    "# )\n",
    "\n",
    "# for ind, column in enumerate(categories):\n",
    "#     plt.subplot(rows, cols, ind + 1)\n",
    "#     data = (\n",
    "#         df[column]\n",
    "#         .value_counts(normalize=True)\n",
    "#         .rename(\"percentage\")\n",
    "#         .mul(100)\n",
    "#         .reset_index()\n",
    "#         .round(2)\n",
    "#     )\n",
    "\n",
    "#     # Rounding for total sum == 100.0\n",
    "#     data[\"percentage\"] = data[\"percentage\"].transform(\n",
    "#         lambda x: pd.Series(\n",
    "#             {x.index[0]: (100 - x.iloc[1:].sum())}\n",
    "#         ).combine_first(x)\n",
    "#     )\n",
    "\n",
    "#     barplot = sns.barplot(\n",
    "#         data=data,\n",
    "#         y=column,\n",
    "#         x=\"percentage\",\n",
    "#         hue=column,\n",
    "#         orient=\"h\",\n",
    "#         legend=False,\n",
    "#         # palette=PALETTE,\n",
    "#     )\n",
    "#     for container in barplot.containers:\n",
    "#         barplot.bar_label(\n",
    "#             container,\n",
    "#             fmt=f\"%.{2}f\",\n",
    "#         )\n",
    "\n",
    "#     # plt.legend('', frameon=False)\n",
    "#     plt.ylabel(\n",
    "#         column,\n",
    "#         rotation=0,\n",
    "#         labelpad=60,\n",
    "#     )\n",
    "\n",
    "# fig.align_ylabels()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f60127d-6f40-4b5a-9690-1f5e4bbed6ef",
   "metadata": {},
   "source": [
    "# ?Conclusions from barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca46a7-35f7-4a2a-a431-fe1e2e9f875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_business = sns.relplot(\n",
    "#     data=df,\n",
    "#     x=\"datetime\",\n",
    "#     y=\"modified_target\",\n",
    "#     col=\"is_business\",\n",
    "#     hue=\"county\",\n",
    "#     height = 8,\n",
    "#     # aspect = 1.6,\n",
    "#     # size=\"size\",\n",
    "#     # style=\"sex\",\n",
    "#     palette=PALETTE,\n",
    "#     s=1,\n",
    "# )\n",
    "# # l = target_business._legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43552525-82b8-46b0-bb03-877212acd715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(18, 8))\n",
    "# sns.boxenplot(\n",
    "#     data=df,\n",
    "#     x=\"county\",\n",
    "#     y=\"target\",\n",
    "#     hue=\"is_consumption\",\n",
    "#     # k_depth = 'full'\n",
    "#     # split=True,\n",
    "#     # style='is_business',\n",
    "# )\n",
    "\n",
    "# plt.title(\n",
    "#     \"Comparison of energy production and consumption in each county\"\n",
    "# )\n",
    "# # plt.legend(\n",
    "# #     bbox_to_anchor=(1.005, 1),\n",
    "# #     loc=\"upper left\",\n",
    "# #     borderaxespad=0,\n",
    "# #     # markerscale=3,\n",
    "# # )\n",
    "\n",
    "# for i in range(df.county.nunique()):\n",
    "#     ax.axvline(\n",
    "#         i -.5,\n",
    "#         color=\"black\",\n",
    "#         alpha=.2\n",
    "#     )\n",
    "\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# plt.yscale('log')\n",
    "# # plt.grid(axis='y',alpha=.2)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890aa420-aacd-4549-af3b-b9c8a0c03793",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    df.groupby([\"date\", \"product_type\", \"county\"], observed=True)[\"target\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"target\")\n",
    ")\n",
    "data = data.astype({\"date\": \"datetime64[ns]\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08353ac0-22d1-4c86-a651-715abfa5d981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of missing data and zeros using lineplot of the daily average\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "ax = sns.lineplot(\n",
    "    data=data,\n",
    "    x=\"date\",\n",
    "    y=\"target\",\n",
    "    style=\"product_type\",\n",
    "    hue=\"county\",\n",
    "    lw=1,\n",
    "    palette=PALETTE,\n",
    ")\n",
    "ax.grid()\n",
    "ax.set_yscale(\"log\")\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1.005, 1), frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab753d-b2c5-4e0c-8494-965283ddab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.query('county == \"Saaremaa\" and \"2021-02-01\" <= date <= \"2021-02-01\" ')\n",
    "# data.query(\n",
    "#     'product_type == \"general_service\" and county == \"Pärnumaa\" and (\"2021-02-01\" < date < \"2021-03-01\")'\n",
    "# )\n",
    "# data.county.unique().tolist()\n",
    "# df_for_missing = train_df.drop(columns=['data_block_id', 'row_id', 'prediction_unit_id']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f120f31-de39-41d6-b8ed-f3b3c2ae5e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Renaming to avoid confusion and improve readability\n",
    "# values_mapper = {\n",
    "#     \"county\": county_id_to_name_map,\n",
    "#     \"is_business\": {\n",
    "#         0: \"not_business\",\n",
    "#         1: \"business\"\n",
    "#     },\n",
    "#     \"is_consumption\": {\n",
    "#         0: \"production\",\n",
    "#         1: \"consumption\"\n",
    "#     },\n",
    "#     \"product_type\": {\n",
    "#         0: \"Combined\",\n",
    "#         1: \"Fixed\",\n",
    "#         2: \"General service\",\n",
    "#         3: \"Spot\",\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# for column in values_mapper:\n",
    "#     df_for_missing[column] = df_for_missing[column].map(values_mapper[column])\n",
    "\n",
    "# df_for_missing = df_for_missing.astype({\n",
    "#     \"county\": \"category\",\n",
    "#     \"is_business\": \"category\",\n",
    "#     \"product_type\": \"category\",\n",
    "#     \"is_consumption\": \"category\",\n",
    "#     \"datetime\": \"datetime64[ns]\",\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cdcc8d-17df-44b5-a2a2-0feadfd3c1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_missing = df[\n",
    "    [\n",
    "        \"county\",\n",
    "        \"is_business\",\n",
    "        \"product_type\",\n",
    "        \"target\",\n",
    "        \"is_consumption\",\n",
    "        \"datetime\",\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "df_for_missing[\"hour_stamp\"] = (\n",
    "    (df_for_missing[\"datetime\"] - df_for_missing[\"datetime\"].min())\n",
    "    / pd.Timedelta(hours=1)\n",
    ").astype(int)\n",
    "\n",
    "df_for_missing[\n",
    "    [\n",
    "        \"hour_stamp\",\n",
    "        \"datetime\",\n",
    "    ]\n",
    "].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2276ef22-f606-4a08-bfab-03aaa5b2fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_missing[\"group_index\"] = df_for_missing.groupby(\n",
    "    [\n",
    "        \"county\",\n",
    "        \"is_business\",\n",
    "        \"product_type\",\n",
    "        \"is_consumption\",\n",
    "    ],\n",
    "    observed=True,\n",
    ").ngroup()\n",
    "\n",
    "df_for_missing = df_for_missing.sort_values([\"hour_stamp\", \"group_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46573be-7862-4b82-acbf-fa8c8dbb0e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vl = df_for_missing.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270aa9f6-fb1c-41a5-80e8-2e0adb51670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb010ba8-e84d-43ac-a224-87ea38566d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a625ef-60dc-4312-be89-f626f78e9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "missmap = np.empty(\n",
    "    (\n",
    "        df_for_missing.hour_stamp.max() + 1,\n",
    "        df_for_missing[\"group_index\"].nunique(),\n",
    "    )\n",
    ")\n",
    "missmap.fill(np.nan)\n",
    "for obs in df_for_missing.values:\n",
    "    missmap[int(obs[6]), (obs[7])] = 0 if obs[3] == 0 else 1\n",
    "missmap = missmap.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9a75d0-3d75-4971-889b-2a60a7812e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(\n",
    "#     [\n",
    "#         [1, 0, 0, 0, 1],\n",
    "#         [1, np.NaN, np.NaN, np.NaN, 1],\n",
    "#         [1, 1, 1, 1, 1],\n",
    "#     ],\n",
    "#     # cmap=\"Paired\",\n",
    "#     cmap='viridis',\n",
    "#     cbar=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4954d943-8841-45d0-8bc3-a0b54cc5d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(20, 80))\n",
    "# sns.heatmap(\n",
    "#     missmap,\n",
    "#     # cmap='Paired',\n",
    "#     cmap=\"viridis\",\n",
    "#     cbar=False,\n",
    "# )\n",
    "# missmap = missmap.T\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.heatmap(\n",
    "    missmap,\n",
    "    # cmap='Paired',\n",
    "    cmap=\"viridis\",\n",
    "    cbar=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1916b2df-6920-472c-9bb7-4d202d660399",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.assign(\n",
    "    category_index=df.groupby(\n",
    "        [\n",
    "            \"county\",\n",
    "            \"is_business\",\n",
    "            \"product_type\",\n",
    "            \"is_consumption\",\n",
    "        ],\n",
    "        observed=True,\n",
    "    ).ngroup()\n",
    ")[[\"datetime\", \"target\", \"category_index\"]]\n",
    "test[\"datetime\"] = (\n",
    "    (test[\"datetime\"] - test[\"datetime\"].min()) / pd.Timedelta(hours=1)\n",
    ").astype(int)\n",
    "test = test.rename(columns={\"datetime\": \"hour_stamp\"})\n",
    "test.target = test.target.where(((test.target == 0) | (test.target.isna())), 1)\n",
    "test = test.pivot(\n",
    "    columns=\"category_index\", index=\"hour_stamp\", values=\"target\"\n",
    ")\n",
    "\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08ad6c1-caba-4c5c-85a9-a682a8fbc764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "plt.figure(figsize=(24, 8))\n",
    "\n",
    "cmap = ListedColormap([\"y\", \"forestgreen\"])\n",
    "xticks = 19  # Desired number -1\n",
    "max_hour_range = test.index[-1]\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    test.T,\n",
    "    cmap=cmap,\n",
    "    cbar_kws={\n",
    "        \"shrink\": 0.5,\n",
    "        \"pad\": 0.01,\n",
    "        \"aspect\": 25,\n",
    "        \"ticks\": [0.25, 0.75],\n",
    "    },\n",
    ")\n",
    "colorbar = ax.collections[0].colorbar\n",
    "colorbar.set_ticklabels([\"0\", \">0\"])\n",
    "\n",
    "plt.xticks(\n",
    "    ticks=range(0, max_hour_range, int(max_hour_range / xticks)),\n",
    "    labels=range(0, max_hour_range, int(max_hour_range / xticks)),\n",
    "    rotation=45,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aeb73a-1157-4150-86be-dfd17bf246eb",
   "metadata": {},
   "source": [
    "# ?Conclusions from heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f5b406-72b9-4e3b-8fae-0f383beff43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_percentage_in_subgroup(\n",
    "    df: pd.DataFrame, feature: str, broken_down_by: str, target: str\n",
    ") -> pd.DataFrame:\n",
    "    df = (\n",
    "        df.groupby([broken_down_by, feature], observed=True)[[target]]\n",
    "        .sum()\n",
    "        .groupby(level=0, observed=True)\n",
    "        .apply(lambda x: x * 100 / x.sum())\n",
    "        .reset_index(level=0, drop=True)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"target\": \"percentage\"})\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d86bc8-209c-4ab8-9bb6-1fedf70639c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_for_categorical_feature(\n",
    "    df: pd.DataFrame,\n",
    "    broken_down_by: str,\n",
    "    features_list: list[str],\n",
    "    target: str,\n",
    "):\n",
    "    length = len(features_list)\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=length,\n",
    "        ncols=1,\n",
    "        figsize=(16, 15),\n",
    "    )\n",
    "    fig.tight_layout(pad=5)\n",
    "\n",
    "    for idx, feature in enumerate(features_list):\n",
    "        plt.subplot(length, 1, 1 + idx)\n",
    "        data = target_percentage_in_subgroup(\n",
    "            df, feature, broken_down_by, target\n",
    "        )\n",
    "\n",
    "        barplot = sns.barplot(\n",
    "            data=data,\n",
    "            x=\"percentage\",\n",
    "            y=feature,\n",
    "            hue=broken_down_by,\n",
    "        )\n",
    "\n",
    "        for container in barplot.containers:\n",
    "            barplot.bar_label(\n",
    "                container,\n",
    "                fmt=\"%.2f\",\n",
    "            )\n",
    "\n",
    "        plt.title(f\"{feature} broken down by {broken_down_by}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1303764-89e7-4c93-9033-b1321388f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_for_categorical_feature(\n",
    "    df,\n",
    "    \"is_consumption\",\n",
    "    [\"county\", \"is_business\", \"product_type\"],\n",
    "    \"target\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5784fae-53c2-45c6-97c1-1243e04944cd",
   "metadata": {},
   "source": [
    "# ?Conclusions from barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063d88d-3546-4ae0-aae3-8389350b5cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abed618a-d92a-4a17-a9ac-5c8b1a68211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hours = df.copy()\n",
    "\n",
    "# hours_ago = (\n",
    "#     [i for i in range(1, 25)]\n",
    "#     + [24 * i for i in range(2, 8)]\n",
    "#     + [168 * i for i in range(2, 9)]\n",
    "#     + [672 * i for i in range(3, 13)]\n",
    "# )\n",
    "# for h in hours_ago:\n",
    "#     df_hours[f\"tm_{h}h\"] = df_hours[\"modified_target\"].shift(h)\n",
    "# df_hours.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f9b85-42e8-414a-80df-a01be08a0bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"tm_1h\"] = df[\"modified_target\"].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a35937-f580-488f-ae59-ef17e4fc5fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_lags(df):\n",
    "#     target_map = df['PJME_MW'].to_dict()\n",
    "#     df['lag1'] = (df.index - pd.Timedelta('364 days')).map(target_map)\n",
    "#     df['lag2'] = (df.index - pd.Timedelta('728 days')).map(target_map)\n",
    "#     df['lag3'] = (df.index - pd.Timedelta('1092 days')).map(target_map)\n",
    "#     return df\n",
    "# df_label = pd.get_dummies(df_label, drop_first=True)\n",
    "# df_label.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a961c50-b70a-454a-acfb-911ff580a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_label.drop(\n",
    "#     columns=[\n",
    "#         \"target\",\n",
    "#         \"data_block_id\",\n",
    "#         \"row_id\",\n",
    "#         \"prediction_unit_id\",\n",
    "#         \"modified_target\",\n",
    "#     ],\n",
    "#     axis=1,\n",
    "# )\n",
    "\n",
    "# y = df_label[\"modified_target\"].values\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.20, random_state=RAND\n",
    "# )\n",
    "\n",
    "# st = StandardScaler()\n",
    "# X_train_std = st.fit_transform(X_train)\n",
    "# X_test_std = st.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab19d1-f223-4c57-b205-fc5dc087d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def r2_adjusted(\n",
    "#     y_true: np.ndarray, y_pred: np.ndarray, X_test: np.ndarray | int\n",
    "# ) -> float:\n",
    "#     \"\"\"Коэффициент детерминации (множественная регрессия)\"\"\"\n",
    "#     N_objects = len(y_true)\n",
    "\n",
    "#     if isinstance(X_test, np.ndarray):\n",
    "#         N_features = X_test.shape[1]\n",
    "#     else:\n",
    "#         N_features = X_test\n",
    "\n",
    "#     #     N_features = X_test.shape[1]\n",
    "#     r2 = r2_score(y_true, y_pred)\n",
    "#     return 1 - (1 - r2) * (N_objects - 1) / (N_objects - N_features - 1)\n",
    "\n",
    "\n",
    "# def mpe(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "#     \"\"\"Mean percentage error\"\"\"\n",
    "#     return np.mean((y_true - y_pred) / y_true, axis=0) * 100\n",
    "\n",
    "\n",
    "# def mape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "#     \"\"\"Mean absolute percentage error\"\"\"\n",
    "#     return np.mean(np.abs((y_pred - y_true) / y_true), axis=0) * 100\n",
    "\n",
    "\n",
    "# def wape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "#     \"\"\"Weighted Absolute Percent Error\"\"\"\n",
    "#     return np.sum(np.abs(y_pred - y_true)) / np.sum(y_true) * 100\n",
    "\n",
    "\n",
    "# def huber_loss(\n",
    "#     y_true: np.ndarray | pd.DataFrame,\n",
    "#     y_pred: np.ndarray | pd.DataFrame,\n",
    "#     delta: float = 1.345,\n",
    "# ):\n",
    "#     \"\"\"Функция ошибки Хьюбера\"\"\"\n",
    "\n",
    "#     if isinstance(y_true, pd.DataFrame):\n",
    "#         y_true = y_true.squeeze().to_numpy()\n",
    "#     if isinstance(y_pred, pd.DataFrame):\n",
    "#         y_pred = y_pred.squeeze().to_numpy()\n",
    "\n",
    "#     assert len(y_true) == len(y_pred), \"Разные размеры данных\"\n",
    "#     huber_sum = 0\n",
    "#     for i in range(len(y_true)):\n",
    "#         if abs(y_true[i] - y_pred[i]) <= delta:\n",
    "#             huber_sum += 0.5 * (y_true[i] - y_pred[i]) ** 2\n",
    "#         else:\n",
    "#             huber_sum += delta * (abs(y_true[i] - y_pred[i]) - 0.5 * delta)\n",
    "#     huber_sum /= len(y_true)\n",
    "#     return huber_sum\n",
    "\n",
    "\n",
    "# def logcosh(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "#     \"\"\"функция ошибки Лог-Кош\"\"\"\n",
    "#     return np.sum(np.log(np.cosh(y_true - y_pred)))\n",
    "\n",
    "\n",
    "# def rmsle(y_true: np.ndarray, y_pred: np.ndarray) -> np.float64:\n",
    "#     \"\"\"\n",
    "#     Root Mean Squared Log Error (RMSLE) metric\n",
    "#     Логарифмическая ошибка средней квадратичной ошибки\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "#     except:\n",
    "#         return None\n",
    "\n",
    "\n",
    "# def get_metrics(\n",
    "#     y_test: np.ndarray,\n",
    "#     y_pred: np.ndarray,\n",
    "#     X_test: np.ndarray,\n",
    "#     name: str = None,\n",
    "#     delta: float = 1.345,\n",
    "# ):\n",
    "#     \"\"\"Генерация таблицы с метриками\"\"\"\n",
    "#     df_metrics = pd.DataFrame()\n",
    "#     df_metrics[\"model\"] = [name]\n",
    "\n",
    "#     df_metrics[\"MAE\"] = mean_absolute_error(y_test, y_pred)\n",
    "#     df_metrics[\"MSE\"] = mean_squared_error(y_test, y_pred)\n",
    "#     df_metrics[\"Huber_loss\"] = huber_loss(y_test, y_pred, delta)\n",
    "#     df_metrics[\"Logcosh\"] = logcosh(y_test, y_pred)\n",
    "#     df_metrics[\"RMSE\"] = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#     df_metrics[\"RMSLE\"] = rmsle(y_test, y_pred)\n",
    "#     df_metrics[\"R2 adjusted\"] = r2_adjusted(y_test, y_pred, X_test)\n",
    "#     df_metrics[\"MPE_%\"] = mpe(y_test, y_pred)\n",
    "#     df_metrics[\"MAPE_%\"] = mape(y_test, y_pred)\n",
    "#     df_metrics[\"WAPE_%\"] = wape(y_test, y_pred)\n",
    "\n",
    "#     return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c61be9d-d40b-4ef8-80dd-e3fd686d52c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_skl = LinearRegression()\n",
    "# lr_skl.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5fda38-2455-4c3f-867b-acd7c0bd950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_skl_pred = lr_skl.predict(X_test_std)\n",
    "# skl_m = get_metrics(y_test, lr_skl_pred, X_test_std, name=\"skl_lr\")\n",
    "# skl_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a3bb2f-54a6-49bd-867d-f4c4887725f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hours = df_hours[\n",
    "#     [\n",
    "#         \"county\",\n",
    "#         \"is_business\",\n",
    "#         \"product_type\",\n",
    "#         \"target\",\n",
    "#         \"is_consumption\",\n",
    "#         \"hour\",\n",
    "#         \"day_of_week\",\n",
    "#         \"day\",\n",
    "#         \"week_of_year\",\n",
    "#         \"month\",\n",
    "#         \"quarter\",\n",
    "#         \"year\",\n",
    "#         \"modified_target\",\n",
    "#         \"tm_1h\",\n",
    "#         \"tm_2h\",\n",
    "#         \"tm_3h\",\n",
    "#         \"tm_4h\",\n",
    "#         \"tm_5h\",\n",
    "#         \"tm_6h\",\n",
    "#         \"tm_7h\",\n",
    "#         \"tm_8h\",\n",
    "#         \"tm_9h\",\n",
    "#         \"tm_10h\",\n",
    "#         \"tm_11h\",\n",
    "#         \"tm_12h\",\n",
    "#         \"tm_13h\",\n",
    "#         \"tm_14h\",\n",
    "#         \"tm_15h\",\n",
    "#         \"tm_16h\",\n",
    "#         \"tm_17h\",\n",
    "#         \"tm_18h\",\n",
    "#         \"tm_19h\",\n",
    "#         \"tm_20h\",\n",
    "#         \"tm_21h\",\n",
    "#         \"tm_22h\",\n",
    "#         \"tm_23h\",\n",
    "#         \"tm_24h\",\n",
    "#         \"tm_48h\",\n",
    "#         \"tm_72h\",\n",
    "#         \"tm_96h\",\n",
    "#         \"tm_120h\",\n",
    "#         \"tm_144h\",\n",
    "#         \"tm_168h\",\n",
    "#         \"tm_336h\",\n",
    "#         \"tm_504h\",\n",
    "#         \"tm_672h\",\n",
    "#         \"tm_840h\",\n",
    "#         \"tm_1008h\",\n",
    "#         \"tm_1176h\",\n",
    "#         \"tm_1344h\",\n",
    "#         \"tm_2016h\",\n",
    "#         \"tm_2688h\",\n",
    "#         \"tm_3360h\",\n",
    "#         \"tm_4032h\",\n",
    "#         \"tm_4704h\",\n",
    "#         \"tm_5376h\",\n",
    "#         \"tm_6048h\",\n",
    "#         \"tm_6720h\",\n",
    "#         \"tm_7392h\",\n",
    "#         \"tm_8064h\",\n",
    "#     ]\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7194de-f912-4c8d-bf34-fe154b1569ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hours = df_hours.sort_index()\n",
    "# tss = TimeSeriesSplit(n_splits=3, test_size=300_000)\n",
    "\n",
    "# fold = 0\n",
    "# preds = []\n",
    "# scores = []\n",
    "# for train_idx, val_idx in tss.split(df_hours):\n",
    "#     train = df_hours.iloc[train_idx]\n",
    "#     test = df_hours.iloc[val_idx]\n",
    "\n",
    "#     reg = XGBRegressor(\n",
    "#         n_estimators=2000,\n",
    "#         early_stopping_rounds=50,\n",
    "#         objective=\"reg:squarederror\",\n",
    "#         enable_categorical=True,\n",
    "#         eval_metric=\"mae\",\n",
    "#         # max_depth=3,\n",
    "#         learning_rate=0.01,\n",
    "#         random_state=RAND,\n",
    "#     )\n",
    "#     FEATURES = [\n",
    "#         \"county\",\n",
    "#         \"is_business\",\n",
    "#         \"product_type\",\n",
    "#         \"is_consumption\",\n",
    "#         \"hour\",\n",
    "#         \"day_of_week\",\n",
    "#         \"day\",\n",
    "#         \"week_of_year\",\n",
    "#         \"month\",\n",
    "#         \"quarter\",\n",
    "#         \"year\",\n",
    "#         \"tm_1h\",\n",
    "#         \"tm_2h\",\n",
    "#         \"tm_3h\",\n",
    "#         \"tm_4h\",\n",
    "#         \"tm_5h\",\n",
    "#         \"tm_6h\",\n",
    "#         \"tm_7h\",\n",
    "#         \"tm_8h\",\n",
    "#         \"tm_9h\",\n",
    "#         \"tm_10h\",\n",
    "#         \"tm_11h\",\n",
    "#         \"tm_12h\",\n",
    "#         \"tm_13h\",\n",
    "#         \"tm_14h\",\n",
    "#         \"tm_15h\",\n",
    "#         \"tm_16h\",\n",
    "#         \"tm_17h\",\n",
    "#         \"tm_18h\",\n",
    "#         \"tm_19h\",\n",
    "#         \"tm_20h\",\n",
    "#         \"tm_21h\",\n",
    "#         \"tm_22h\",\n",
    "#         \"tm_23h\",\n",
    "#         \"tm_24h\",\n",
    "#         \"tm_48h\",\n",
    "#         \"tm_72h\",\n",
    "#         \"tm_96h\",\n",
    "#         \"tm_120h\",\n",
    "#         \"tm_144h\",\n",
    "#         \"tm_168h\",\n",
    "#         \"tm_336h\",\n",
    "#         \"tm_504h\",\n",
    "#         \"tm_672h\",\n",
    "#         \"tm_840h\",\n",
    "#         \"tm_1008h\",\n",
    "#         \"tm_1176h\",\n",
    "#         \"tm_1344h\",\n",
    "#         \"tm_2016h\",\n",
    "#         \"tm_2688h\",\n",
    "#         \"tm_3360h\",\n",
    "#         \"tm_4032h\",\n",
    "#         \"tm_4704h\",\n",
    "#         \"tm_5376h\",\n",
    "#         \"tm_6048h\",\n",
    "#         \"tm_6720h\",\n",
    "#         \"tm_7392h\",\n",
    "#         \"tm_8064h\",\n",
    "#     ]\n",
    "#     # TARGET = \"modified_target\"\n",
    "#     TARGET = \"target\"\n",
    "\n",
    "#     X_train = train[FEATURES]\n",
    "#     y_train = train[TARGET]\n",
    "\n",
    "#     X_test = test[FEATURES]\n",
    "#     y_test = test[TARGET]\n",
    "\n",
    "#     reg.fit(\n",
    "#         X_train,\n",
    "#         y_train,\n",
    "#         eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "#         verbose=20,\n",
    "#     )\n",
    "\n",
    "#     y_pred = reg.predict(X_test)\n",
    "#     preds.append(y_pred)\n",
    "#     score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#     scores.append(score)\n",
    "\n",
    "# hours_ago = (\n",
    "#     [i for i in range(1, 25)]\n",
    "#     + [24 * i for i in range(2, 8)]\n",
    "#     + [168 * i for i in range(2, 9)]\n",
    "#     + [672 * i for i in range(3, 13)]\n",
    "# )\n",
    "# for h in hours_ago:\n",
    "#     df[f\"t_{h}h\"] = df[\"target\"].shift(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a59dba-58ea-4b29-a6b0-533e7fe0be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(35, 30))\n",
    "\n",
    "# sns.heatmap(df_hours.corr(), annot=True, cmap=\"Blues\", fmt=\".1f\")\n",
    "# # plt.figure(figsize=(25, 25))\n",
    "# plt.show()\n",
    "# # numeric_only=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790fd79-1e77-4e6f-bb8d-af83f47a57cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sort_index().sort_values(\n",
    "#     [\"county\", \"is_business\", \"product_type\", \"is_consumption\"],\n",
    "#     kind=\"mergesort\",\n",
    "# )\n",
    "# df.sort_index()\n",
    "# tss = TimeSeriesSplit(n_splits=3, test_size=300_000)\n",
    "\n",
    "# a = {}\n",
    "# for i in range(1000):\n",
    "#     x = 0\n",
    "#     for j in range(20):\n",
    "#         x += np.random.choice([-1, 1])\n",
    "#     a[x] = a.get(x, 0) + 1\n",
    "\n",
    "\n",
    "# sns.barplot(x=list(a.keys()), y=list(a.values()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fc3653-4435-4e20-bee9-4da67b4ea8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min(data.keys())\n",
    "# max(data.keys())\n",
    "# len(data.keys())\n",
    "# {k: 0 for (k, 0) in range(min(data.keys()), max(data.keys())) if not in data.keys()}\n",
    "# {k: v*2 for (k,v) in dict1.items()}\n",
    "# {key:value for (key,value) in dictonary.items()}\n",
    "# zip()\n",
    "\n",
    "# for train_idx, val_idx in tss.split(df):\n",
    "# print('1 train:', train_idx)\n",
    "# display(df.iloc[train_idx].tail(5))\n",
    "# print('1 val:', val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76417d13-25db-4e88-9af6-04d9e23b6afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tss = TimeSeriesSplit(n_splits=3, test_size=300_000)\n",
    "# df = df.sort_index()\n",
    "\n",
    "# fig, axs = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "# fold = 0\n",
    "\n",
    "# for train_idx, val_idx in tss.split(df):\n",
    "#     train = df.iloc[train_idx]\n",
    "#     test = df.iloc[val_idx]\n",
    "#     train[\"modified_target\"].plot(\n",
    "#         ax=axs[fold],\n",
    "#         label=\"Training Set\",\n",
    "#         title=f\"Data Train/Test Split Fold {fold}\",\n",
    "#     )\n",
    "#     test[\"modified_target\"].plot(ax=axs[fold], label=\"Test Set\")\n",
    "#     axs[fold].axvline(test.index.min(), color=\"black\", ls=\"--\")\n",
    "#     fold += 1\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4637896-c557-496a-bad6-0f7734fa9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold = 0\n",
    "# preds = []\n",
    "# scores = []\n",
    "# for train_idx, val_idx in tss.split(df):\n",
    "#     train = df.iloc[train_idx]\n",
    "#     test = df.iloc[val_idx]\n",
    "\n",
    "#     reg = XGBRegressor(\n",
    "#         n_estimators=2000,\n",
    "#         early_stopping_rounds=50,\n",
    "#         objective=\"reg:squarederror\",\n",
    "#         enable_categorical=True,\n",
    "#         eval_metric=\"mae\",\n",
    "#         # max_depth=3,\n",
    "#         learning_rate=0.01,\n",
    "#         random_state=RAND,\n",
    "#     )\n",
    "#     FEATURES = [\n",
    "#         \"county\",\n",
    "#         \"is_business\",\n",
    "#         \"product_type\",\n",
    "#         # 'target',\n",
    "#         \"is_consumption\",\n",
    "#         # 'data_block_id',\n",
    "#         # 'row_id',\n",
    "#         # 'prediction_unit_id',\n",
    "#         \"hour\",\n",
    "#         \"day_of_week\",\n",
    "#         \"day\",\n",
    "#         \"week_of_year\",\n",
    "#         \"month\",\n",
    "#         \"quarter\",\n",
    "#         \"year\",\n",
    "#         # 'modified_target',\n",
    "#     ]\n",
    "#     TARGET = \"modified_target\"\n",
    "\n",
    "#     X_train = train[FEATURES]\n",
    "#     y_train = train[TARGET]\n",
    "\n",
    "#     X_test = test[FEATURES]\n",
    "#     y_test = test[TARGET]\n",
    "\n",
    "#     reg.fit(\n",
    "#         X_train,\n",
    "#         y_train,\n",
    "#         eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "#         verbose=20,\n",
    "#     )\n",
    "\n",
    "#     y_pred = reg.predict(X_test)\n",
    "#     preds.append(y_pred)\n",
    "#     score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#     scores.append(score)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
